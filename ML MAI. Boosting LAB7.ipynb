{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Zgoi8i6plWlO",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### О ЛР:\n",
    "\n",
    "- Coding Gradient boosting\n",
    "\n",
    "----\n",
    "\n",
    "#### Самостоятельная оценка результатов\n",
    "\n",
    "Для удобства проверки, исходя из набора решенных задач, посчитайте свою максимальную оценку (Она тут равняется 6).\n",
    "\n",
    "**Оценка**:\n",
    "\n",
    "***DeadLine - 09.01.2025 23:59***\n",
    "\n",
    "### Формат сдачи\n",
    "Задания сдаются через lms. Вы прикрепляете **ССЫЛКУ НА ПУБЛИЧНЫЙ РЕПОЗИТОРИЙ**, где выполнено ваше задание. Иначе задание не проверяется."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "1XDUNTn4lWlP",
    "pycharm": {
     "name": "#%%\n"
    },
    "ExecuteTime": {
     "end_time": "2025-01-04T21:09:11.705734800Z",
     "start_time": "2025-01-04T21:09:09.869026600Z"
    }
   },
   "outputs": [],
   "source": [
    "from warnings import filterwarnings\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "from scipy.sparse import load_npz\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "sns.set(style=\"darkgrid\")\n",
    "filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "yvolL0KvlWlQ",
    "pycharm": {
     "name": "#%%\n"
    },
    "ExecuteTime": {
     "end_time": "2025-01-04T21:09:11.714527600Z",
     "start_time": "2025-01-04T21:09:11.706735400Z"
    }
   },
   "outputs": [],
   "source": [
    "x = load_npz(\"x.npz\")\n",
    "y = np.load(\"y.npy\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PRMjj9ZslWlQ",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Разделим на обучающую, валидационную и тестовую выборки (`random_state` оставьте равным 666 для воспроизводимости)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "Hme6Cf0HlWlR",
    "pycharm": {
     "name": "#%%\n"
    },
    "ExecuteTime": {
     "end_time": "2025-01-04T21:09:11.733527900Z",
     "start_time": "2025-01-04T21:09:11.715528100Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "((18825, 169), (2354, 169), (2353, 169))"
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(\n",
    "    x, y, test_size=0.2, random_state=666\n",
    ")\n",
    "\n",
    "x_test, x_valid, y_test, y_valid = train_test_split(\n",
    "    x_test, y_test, test_size=0.5, random_state=666\n",
    ")\n",
    "\n",
    "x_train.shape, x_valid.shape, x_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tHaBuXarlWlR",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Задание 1. Реализация градиентного бустинга [2 балла]\n",
    "\n",
    "Необходимо дописать код в файле `boosting.py`. Уже создан шаблон класса `Boosting`, который можно модифицировать по своему усмотрению.\n",
    "\n",
    "### Описание функций:\n",
    "\n",
    "#### `__init__`\n",
    "\n",
    "Конструктор класса принимает следующие параметры:\n",
    "\n",
    "- `base_model_class` — класс базовой модели для бустинга.\n",
    "- `base_model_params` — словарь гиперпараметров для базовой модели.\n",
    "- `n_estimators` — количество базовых моделей для обучения.\n",
    "- `learning_rate` — темп обучения, должен быть в диапазоне (0, 1].\n",
    "- `subsample` — доля обучающей выборки для тренировки базовой модели (размер бутстрап-выборки относительно исходной).\n",
    "- `early_stopping_rounds` — число итераций без улучшения на валидационной выборке, после которых обучение прекращается.\n",
    "- `plot` — флаг для построения графика качества моделей после обучения.\n",
    "\n",
    "#### `fit`\n",
    "\n",
    "Метод `fit` принимает обучающую и валидационную выборки.\n",
    "\n",
    "1. Инициализируем нулевую модель и делаем предсказания (например, все нули) для обеих выборок.\n",
    "2. Обучаем `n_estimators` базовых моделей:\n",
    "   - Обучаем новую базовую модель на текущих остатках.\n",
    "   - Обновляем предсказания на обучающей и валидационной выборках.\n",
    "   - Рассчитываем ошибки на обеих выборках с помощью `loss_fn`.\n",
    "   - Проверяем условия для ранней остановки.\n",
    "\n",
    "3. Если флаг `plot` установлен, строим график качества после обучения всех моделей.\n",
    "\n",
    "#### `fit_new_base_model`\n",
    "\n",
    "Метод `fit_new_base_model` принимает обучающую выборку и текущие предсказания для неё.\n",
    "\n",
    "1. Генерируем бутстрап-выборку.\n",
    "2. Обучаем базовую модель на этой выборке.\n",
    "3. Оптимизируем значение гаммы.\n",
    "4. Добавляем новую базовую модель и гамму в соответствующие списки (учитывая `learning_rate`).\n",
    "\n",
    "#### `predict_proba`\n",
    "\n",
    "Метод `predict_proba` принимает выборку для предсказания вероятностей.\n",
    "\n",
    "1. Суммируем предсказания базовых моделей (учитывая гамму и `learning_rate`).\n",
    "2. Применяем сигмоидальную функцию для получения вероятностей."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "xh3nawbUlWlS",
    "pycharm": {
     "name": "#%%\n"
    },
    "ExecuteTime": {
     "end_time": "2025-01-04T21:09:11.794998300Z",
     "start_time": "2025-01-04T21:09:11.733527900Z"
    }
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "reqHbUEBlWlS",
    "pycharm": {
     "name": "#%%\n"
    },
    "ExecuteTime": {
     "end_time": "2025-01-04T21:09:12.677554300Z",
     "start_time": "2025-01-04T21:09:11.796000600Z"
    }
   },
   "outputs": [],
   "source": [
    "%autoreload 2\n",
    "\n",
    "from boosting import Boosting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "l7wWK5RplWlT",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Проверка кода\n",
    "\n",
    "У автора задания всё учится около одной секунды."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "00lZjzI3lWlT",
    "outputId": "c1aa6886-069b-433f-f0c1-5cf70bdb15cb",
    "pycharm": {
     "name": "#%%\n"
    },
    "ExecuteTime": {
     "end_time": "2025-01-04T21:09:13.971125100Z",
     "start_time": "2025-01-04T21:09:12.679554900Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1/10: Train Loss = 0.6738, Valid Loss = 0.6760\n",
      "Iteration 2/10: Train Loss = 0.6552, Valid Loss = 0.6596\n",
      "Iteration 3/10: Train Loss = 0.6376, Valid Loss = 0.6440\n",
      "Iteration 4/10: Train Loss = 0.6207, Valid Loss = 0.6288\n",
      "Iteration 5/10: Train Loss = 0.6049, Valid Loss = 0.6147\n",
      "Iteration 6/10: Train Loss = 0.5894, Valid Loss = 0.6006\n",
      "Iteration 7/10: Train Loss = 0.5748, Valid Loss = 0.5876\n",
      "Iteration 8/10: Train Loss = 0.5608, Valid Loss = 0.5755\n",
      "Iteration 9/10: Train Loss = 0.5473, Valid Loss = 0.5637\n",
      "Iteration 10/10: Train Loss = 0.5346, Valid Loss = 0.5530\n",
      "CPU times: total: 1.17 s\n",
      "Wall time: 1.2 s\n",
      "Train ROC-AUC 0.9868\n",
      "Valid ROC-AUC 0.9444\n",
      "Test ROC-AUC 0.9464\n"
     ]
    }
   ],
   "source": [
    "boosting = Boosting()\n",
    "\n",
    "%time boosting.fit(x_train, y_train, x_valid, y_valid)\n",
    "\n",
    "assert len(boosting.models) == boosting.n_estimators\n",
    "assert len(boosting.gammas) == boosting.n_estimators\n",
    "\n",
    "assert boosting.predict_proba(x_test).shape == (x_test.shape[0], 2)\n",
    "\n",
    "print(f'Train ROC-AUC {boosting.score(x_train, y_train):.4f}')\n",
    "print(f'Valid ROC-AUC {boosting.score(x_valid, y_valid):.4f}')\n",
    "print(f'Test ROC-AUC {boosting.score(x_test, y_test):.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MlU-c9CxlWlU",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Задание 2. Обучение градиентного бустинга [0.5 балла]\n",
    "\n",
    "Оцените качество вашей реализации градиентного бустинга на тестовой выборке, используя базовые модели — решающие деревья с различной максимальной глубиной. Метрикой будет ROC-AUC.\n",
    "\n",
    "**Инструкция:**\n",
    "1. Перебирайте значения максимальной глубины деревьев от 1 до 30 с шагом 2.\n",
    "2. Оставьте остальные параметры бустинга по умолчанию.\n",
    "3. Постройте график зависимости качества на обучающей и тестовой выборке от максимальной глубины деревьев."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "-IjO9FqelWlU",
    "pycharm": {
     "name": "#%%\n"
    },
    "ExecuteTime": {
     "end_time": "2025-01-04T21:34:33.331263900Z",
     "start_time": "2025-01-04T21:34:23.128040100Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1/10: Train Loss = 0.6820, Valid Loss = 0.6825\n",
      "Iteration 2/10: Train Loss = 0.6717, Valid Loss = 0.6727\n",
      "Iteration 3/10: Train Loss = 0.6614, Valid Loss = 0.6626\n",
      "Iteration 4/10: Train Loss = 0.6516, Valid Loss = 0.6531\n",
      "Iteration 5/10: Train Loss = 0.6423, Valid Loss = 0.6444\n",
      "Iteration 6/10: Train Loss = 0.6335, Valid Loss = 0.6358\n",
      "Iteration 7/10: Train Loss = 0.6252, Valid Loss = 0.6280\n",
      "Iteration 8/10: Train Loss = 0.6169, Valid Loss = 0.6200\n",
      "Iteration 9/10: Train Loss = 0.6093, Valid Loss = 0.6128\n",
      "Iteration 10/10: Train Loss = 0.6022, Valid Loss = 0.6061\n",
      "Iteration 1/10: Train Loss = 0.6784, Valid Loss = 0.6789\n",
      "Iteration 2/10: Train Loss = 0.6647, Valid Loss = 0.6655\n",
      "Iteration 3/10: Train Loss = 0.6516, Valid Loss = 0.6528\n",
      "Iteration 4/10: Train Loss = 0.6394, Valid Loss = 0.6408\n",
      "Iteration 5/10: Train Loss = 0.6275, Valid Loss = 0.6291\n",
      "Iteration 6/10: Train Loss = 0.6163, Valid Loss = 0.6183\n",
      "Iteration 7/10: Train Loss = 0.6055, Valid Loss = 0.6077\n",
      "Iteration 8/10: Train Loss = 0.5952, Valid Loss = 0.5975\n",
      "Iteration 9/10: Train Loss = 0.5853, Valid Loss = 0.5879\n",
      "Iteration 10/10: Train Loss = 0.5760, Valid Loss = 0.5788\n",
      "Iteration 1/10: Train Loss = 0.6771, Valid Loss = 0.6774\n",
      "Iteration 2/10: Train Loss = 0.6622, Valid Loss = 0.6628\n",
      "Iteration 3/10: Train Loss = 0.6477, Valid Loss = 0.6485\n",
      "Iteration 4/10: Train Loss = 0.6340, Valid Loss = 0.6350\n",
      "Iteration 5/10: Train Loss = 0.6208, Valid Loss = 0.6221\n",
      "Iteration 6/10: Train Loss = 0.6085, Valid Loss = 0.6101\n",
      "Iteration 7/10: Train Loss = 0.5965, Valid Loss = 0.5985\n",
      "Iteration 8/10: Train Loss = 0.5852, Valid Loss = 0.5875\n",
      "Iteration 9/10: Train Loss = 0.5743, Valid Loss = 0.5769\n",
      "Iteration 10/10: Train Loss = 0.5639, Valid Loss = 0.5669\n",
      "Iteration 1/10: Train Loss = 0.6763, Valid Loss = 0.6766\n",
      "Iteration 2/10: Train Loss = 0.6603, Valid Loss = 0.6611\n",
      "Iteration 3/10: Train Loss = 0.6448, Valid Loss = 0.6462\n",
      "Iteration 4/10: Train Loss = 0.6305, Valid Loss = 0.6323\n",
      "Iteration 5/10: Train Loss = 0.6165, Valid Loss = 0.6188\n",
      "Iteration 6/10: Train Loss = 0.6034, Valid Loss = 0.6060\n",
      "Iteration 7/10: Train Loss = 0.5908, Valid Loss = 0.5940\n",
      "Iteration 8/10: Train Loss = 0.5786, Valid Loss = 0.5824\n",
      "Iteration 9/10: Train Loss = 0.5672, Valid Loss = 0.5713\n",
      "Iteration 10/10: Train Loss = 0.5561, Valid Loss = 0.5607\n",
      "Iteration 1/10: Train Loss = 0.6753, Valid Loss = 0.6762\n",
      "Iteration 2/10: Train Loss = 0.6583, Valid Loss = 0.6601\n",
      "Iteration 3/10: Train Loss = 0.6426, Valid Loss = 0.6451\n",
      "Iteration 4/10: Train Loss = 0.6271, Valid Loss = 0.6305\n",
      "Iteration 5/10: Train Loss = 0.6122, Valid Loss = 0.6164\n",
      "Iteration 6/10: Train Loss = 0.5984, Valid Loss = 0.6034\n",
      "Iteration 7/10: Train Loss = 0.5853, Valid Loss = 0.5908\n",
      "Iteration 8/10: Train Loss = 0.5725, Valid Loss = 0.5785\n",
      "Iteration 9/10: Train Loss = 0.5605, Valid Loss = 0.5674\n",
      "Iteration 10/10: Train Loss = 0.5490, Valid Loss = 0.5567\n",
      "Iteration 1/10: Train Loss = 0.6749, Valid Loss = 0.6760\n",
      "Iteration 2/10: Train Loss = 0.6578, Valid Loss = 0.6600\n",
      "Iteration 3/10: Train Loss = 0.6412, Valid Loss = 0.6445\n",
      "Iteration 4/10: Train Loss = 0.6253, Valid Loss = 0.6296\n",
      "Iteration 5/10: Train Loss = 0.6105, Valid Loss = 0.6158\n",
      "Iteration 6/10: Train Loss = 0.5962, Valid Loss = 0.6024\n",
      "Iteration 7/10: Train Loss = 0.5824, Valid Loss = 0.5893\n",
      "Iteration 8/10: Train Loss = 0.5693, Valid Loss = 0.5770\n",
      "Iteration 9/10: Train Loss = 0.5569, Valid Loss = 0.5653\n",
      "Iteration 10/10: Train Loss = 0.5451, Valid Loss = 0.5549\n",
      "Iteration 1/10: Train Loss = 0.6749, Valid Loss = 0.6759\n",
      "Iteration 2/10: Train Loss = 0.6571, Valid Loss = 0.6592\n",
      "Iteration 3/10: Train Loss = 0.6401, Valid Loss = 0.6432\n",
      "Iteration 4/10: Train Loss = 0.6239, Valid Loss = 0.6283\n",
      "Iteration 5/10: Train Loss = 0.6085, Valid Loss = 0.6139\n",
      "Iteration 6/10: Train Loss = 0.5939, Valid Loss = 0.6002\n",
      "Iteration 7/10: Train Loss = 0.5798, Valid Loss = 0.5869\n",
      "Iteration 8/10: Train Loss = 0.5666, Valid Loss = 0.5749\n",
      "Iteration 9/10: Train Loss = 0.5539, Valid Loss = 0.5636\n",
      "Iteration 10/10: Train Loss = 0.5420, Valid Loss = 0.5533\n",
      "Iteration 1/10: Train Loss = 0.6741, Valid Loss = 0.6759\n",
      "Iteration 2/10: Train Loss = 0.6563, Valid Loss = 0.6591\n",
      "Iteration 3/10: Train Loss = 0.6392, Valid Loss = 0.6429\n",
      "Iteration 4/10: Train Loss = 0.6232, Valid Loss = 0.6276\n",
      "Iteration 5/10: Train Loss = 0.6076, Valid Loss = 0.6139\n",
      "Iteration 6/10: Train Loss = 0.5929, Valid Loss = 0.6000\n",
      "Iteration 7/10: Train Loss = 0.5786, Valid Loss = 0.5871\n",
      "Iteration 8/10: Train Loss = 0.5650, Valid Loss = 0.5749\n",
      "Iteration 9/10: Train Loss = 0.5519, Valid Loss = 0.5635\n",
      "Iteration 10/10: Train Loss = 0.5396, Valid Loss = 0.5525\n",
      "Iteration 1/10: Train Loss = 0.6738, Valid Loss = 0.6759\n",
      "Iteration 2/10: Train Loss = 0.6556, Valid Loss = 0.6591\n",
      "Iteration 3/10: Train Loss = 0.6382, Valid Loss = 0.6429\n",
      "Iteration 4/10: Train Loss = 0.6217, Valid Loss = 0.6276\n",
      "Iteration 5/10: Train Loss = 0.6059, Valid Loss = 0.6137\n",
      "Iteration 6/10: Train Loss = 0.5908, Valid Loss = 0.6001\n",
      "Iteration 7/10: Train Loss = 0.5764, Valid Loss = 0.5873\n",
      "Iteration 8/10: Train Loss = 0.5628, Valid Loss = 0.5752\n",
      "Iteration 9/10: Train Loss = 0.5498, Valid Loss = 0.5642\n",
      "Iteration 10/10: Train Loss = 0.5372, Valid Loss = 0.5537\n",
      "Iteration 1/10: Train Loss = 0.6739, Valid Loss = 0.6761\n",
      "Iteration 2/10: Train Loss = 0.6558, Valid Loss = 0.6593\n",
      "Iteration 3/10: Train Loss = 0.6383, Valid Loss = 0.6439\n",
      "Iteration 4/10: Train Loss = 0.6219, Valid Loss = 0.6291\n",
      "Iteration 5/10: Train Loss = 0.6058, Valid Loss = 0.6141\n",
      "Iteration 6/10: Train Loss = 0.5907, Valid Loss = 0.6004\n",
      "Iteration 7/10: Train Loss = 0.5762, Valid Loss = 0.5873\n",
      "Iteration 8/10: Train Loss = 0.5624, Valid Loss = 0.5751\n",
      "Iteration 9/10: Train Loss = 0.5492, Valid Loss = 0.5636\n",
      "Iteration 10/10: Train Loss = 0.5365, Valid Loss = 0.5526\n",
      "Iteration 1/10: Train Loss = 0.6737, Valid Loss = 0.6755\n",
      "Iteration 2/10: Train Loss = 0.6554, Valid Loss = 0.6591\n",
      "Iteration 3/10: Train Loss = 0.6376, Valid Loss = 0.6432\n",
      "Iteration 4/10: Train Loss = 0.6209, Valid Loss = 0.6283\n",
      "Iteration 5/10: Train Loss = 0.6050, Valid Loss = 0.6142\n",
      "Iteration 6/10: Train Loss = 0.5899, Valid Loss = 0.6007\n",
      "Iteration 7/10: Train Loss = 0.5753, Valid Loss = 0.5876\n",
      "Iteration 8/10: Train Loss = 0.5614, Valid Loss = 0.5754\n",
      "Iteration 9/10: Train Loss = 0.5481, Valid Loss = 0.5638\n",
      "Iteration 10/10: Train Loss = 0.5353, Valid Loss = 0.5526\n",
      "Iteration 1/10: Train Loss = 0.6742, Valid Loss = 0.6758\n",
      "Iteration 2/10: Train Loss = 0.6557, Valid Loss = 0.6595\n",
      "Iteration 3/10: Train Loss = 0.6381, Valid Loss = 0.6432\n",
      "Iteration 4/10: Train Loss = 0.6213, Valid Loss = 0.6283\n",
      "Iteration 5/10: Train Loss = 0.6054, Valid Loss = 0.6144\n",
      "Iteration 6/10: Train Loss = 0.5901, Valid Loss = 0.6008\n",
      "Iteration 7/10: Train Loss = 0.5754, Valid Loss = 0.5880\n",
      "Iteration 8/10: Train Loss = 0.5616, Valid Loss = 0.5760\n",
      "Iteration 9/10: Train Loss = 0.5481, Valid Loss = 0.5640\n",
      "Iteration 10/10: Train Loss = 0.5353, Valid Loss = 0.5526\n",
      "Iteration 1/10: Train Loss = 0.6738, Valid Loss = 0.6758\n",
      "Iteration 2/10: Train Loss = 0.6553, Valid Loss = 0.6591\n",
      "Iteration 3/10: Train Loss = 0.6374, Valid Loss = 0.6433\n",
      "Iteration 4/10: Train Loss = 0.6206, Valid Loss = 0.6284\n",
      "Iteration 5/10: Train Loss = 0.6044, Valid Loss = 0.6140\n",
      "Iteration 6/10: Train Loss = 0.5890, Valid Loss = 0.6002\n",
      "Iteration 7/10: Train Loss = 0.5745, Valid Loss = 0.5872\n",
      "Iteration 8/10: Train Loss = 0.5603, Valid Loss = 0.5747\n",
      "Iteration 9/10: Train Loss = 0.5472, Valid Loss = 0.5628\n",
      "Iteration 10/10: Train Loss = 0.5344, Valid Loss = 0.5516\n",
      "Iteration 1/10: Train Loss = 0.6739, Valid Loss = 0.6761\n",
      "Iteration 2/10: Train Loss = 0.6555, Valid Loss = 0.6591\n",
      "Iteration 3/10: Train Loss = 0.6379, Valid Loss = 0.6434\n",
      "Iteration 4/10: Train Loss = 0.6209, Valid Loss = 0.6285\n",
      "Iteration 5/10: Train Loss = 0.6050, Valid Loss = 0.6142\n",
      "Iteration 6/10: Train Loss = 0.5896, Valid Loss = 0.6006\n",
      "Iteration 7/10: Train Loss = 0.5749, Valid Loss = 0.5878\n",
      "Iteration 8/10: Train Loss = 0.5610, Valid Loss = 0.5756\n",
      "Iteration 9/10: Train Loss = 0.5476, Valid Loss = 0.5639\n",
      "Iteration 10/10: Train Loss = 0.5350, Valid Loss = 0.5532\n",
      "Iteration 1/10: Train Loss = 0.6738, Valid Loss = 0.6758\n",
      "Iteration 2/10: Train Loss = 0.6552, Valid Loss = 0.6591\n",
      "Iteration 3/10: Train Loss = 0.6375, Valid Loss = 0.6433\n",
      "Iteration 4/10: Train Loss = 0.6208, Valid Loss = 0.6286\n",
      "Iteration 5/10: Train Loss = 0.6048, Valid Loss = 0.6140\n",
      "Iteration 6/10: Train Loss = 0.5895, Valid Loss = 0.6007\n",
      "Iteration 7/10: Train Loss = 0.5748, Valid Loss = 0.5876\n",
      "Iteration 8/10: Train Loss = 0.5608, Valid Loss = 0.5757\n",
      "Iteration 9/10: Train Loss = 0.5475, Valid Loss = 0.5642\n",
      "Iteration 10/10: Train Loss = 0.5347, Valid Loss = 0.5529\n"
     ]
    },
    {
     "data": {
      "text/plain": "<Figure size 800x600 with 1 Axes>",
      "image/png": "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"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "results = {}\n",
    "\n",
    "depths = range(1, 30, 2)\n",
    "\n",
    "### ╰( ͡☉ ͜ʖ ͡☉ )つ──☆*:・ﾟ   ฅ^•ﻌ•^ฅ   ʕ•ᴥ•ʔ\n",
    "\n",
    "for d in depths:\n",
    "    boosting = Boosting(\n",
    "        base_model_params={'max_depth': d},\n",
    "        n_estimators=10,\n",
    "        learning_rate=0.1,\n",
    "        subsample=0.3,\n",
    "        early_stopping_rounds=None,\n",
    "        plot=False\n",
    "    )\n",
    "\n",
    "    boosting.fit(x_train, y_train, x_valid, y_valid)\n",
    "\n",
    "    train_roc_auc = boosting.score(x_train, y_train)\n",
    "    test_roc_auc = boosting.score(x_test, y_test)\n",
    "\n",
    "    results[d] = (train_roc_auc, test_roc_auc)\n",
    "\n",
    "train_scores = [results[d][0] for d in depths]\n",
    "test_scores = [results[d][1] for d in depths]\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.plot(depths, train_scores, marker='o', label='Train ROC-AUC')\n",
    "plt.plot(depths, test_scores, marker='o', label='Test ROC-AUC')\n",
    "plt.xlabel('Max depth')\n",
    "plt.ylabel('ROC-AUC')\n",
    "plt.title('Зависимость качества (ROC-AUC) от максимальной глубины дерева')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bshz0JV6lWlV",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "**Какая из моделей имеет лучшее качество? Как вы можете это объяснить?**\n",
    "\n",
    "╰( ͡☉ ͜ʖ ͡☉ )つ──☆*:・ﾟ   ฅ^•ﻌ•^ฅ   ʕ•ᴥ•ʔ\n",
    "\n",
    "До глубины в 11 деревья учитывают много нелинейностей и взаимодействий признаков - это хорошо. А дальше, модель будто подстраивается под обучающую выборку - оверфиттинг - это видно по тому, что на тестовой после 11 глубины качество падает."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8FwaUsmqlWlV"
   },
   "source": [
    "## Задание 3. Подбор гиперпараметров и поиск оптимальной модели [3 балла]\n",
    "\n",
    "Настройте основные гиперпараметры вашей модели градиентного бустинга, используя валидационную выборку. Подберите параметры как для самого бустинга, так и для базовых моделей.\n",
    "\n",
    "**Рекомендации:**\n",
    "- Используйте библиотеки для автоматизированного подбора гиперпараметров, такие как [Hyperopt](https://github.com/hyperopt/hyperopt) или [Optuna](https://optuna.org/).\n",
    "- Подберите все основные параметры, чтобы найти лучшую модель на валидационной выборке."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting optuna\n",
      "  Downloading optuna-4.1.0-py3-none-any.whl.metadata (16 kB)\n",
      "Collecting alembic>=1.5.0 (from optuna)\n",
      "  Downloading alembic-1.14.0-py3-none-any.whl.metadata (7.4 kB)\n",
      "Collecting colorlog (from optuna)\n",
      "  Downloading colorlog-6.9.0-py3-none-any.whl.metadata (10 kB)\n",
      "Requirement already satisfied: numpy in d:\\python\\lib\\site-packages (from optuna) (2.1.2)\n",
      "Requirement already satisfied: packaging>=20.0 in d:\\python\\lib\\site-packages (from optuna) (24.1)\n",
      "Collecting sqlalchemy>=1.4.2 (from optuna)\n",
      "  Downloading SQLAlchemy-2.0.36-cp312-cp312-win_amd64.whl.metadata (9.9 kB)\n",
      "Requirement already satisfied: tqdm in d:\\python\\lib\\site-packages (from optuna) (4.67.1)\n",
      "Requirement already satisfied: PyYAML in d:\\python\\lib\\site-packages (from optuna) (6.0.2)\n",
      "Collecting Mako (from alembic>=1.5.0->optuna)\n",
      "  Downloading Mako-1.3.8-py3-none-any.whl.metadata (2.9 kB)\n",
      "Requirement already satisfied: typing-extensions>=4 in d:\\python\\lib\\site-packages (from alembic>=1.5.0->optuna) (4.12.2)\n",
      "Collecting greenlet!=0.4.17 (from sqlalchemy>=1.4.2->optuna)\n",
      "  Downloading greenlet-3.1.1-cp312-cp312-win_amd64.whl.metadata (3.9 kB)\n",
      "Requirement already satisfied: colorama in d:\\python\\lib\\site-packages (from colorlog->optuna) (0.4.6)\n",
      "Requirement already satisfied: MarkupSafe>=0.9.2 in d:\\python\\lib\\site-packages (from Mako->alembic>=1.5.0->optuna) (2.1.5)\n",
      "Downloading optuna-4.1.0-py3-none-any.whl (364 kB)\n",
      "Downloading alembic-1.14.0-py3-none-any.whl (233 kB)\n",
      "Downloading SQLAlchemy-2.0.36-cp312-cp312-win_amd64.whl (2.1 MB)\n",
      "   ---------------------------------------- 0.0/2.1 MB ? eta -:--:--\n",
      "   ---------------------------------------- 2.1/2.1 MB 19.4 MB/s eta 0:00:00\n",
      "Downloading colorlog-6.9.0-py3-none-any.whl (11 kB)\n",
      "Downloading greenlet-3.1.1-cp312-cp312-win_amd64.whl (299 kB)\n",
      "Downloading Mako-1.3.8-py3-none-any.whl (78 kB)\n",
      "Installing collected packages: Mako, greenlet, colorlog, sqlalchemy, alembic, optuna\n",
      "Successfully installed Mako-1.3.8 alembic-1.14.0 colorlog-6.9.0 greenlet-3.1.1 optuna-4.1.0 sqlalchemy-2.0.36\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.2 -> 24.3.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!pip install optuna"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-01-04T21:47:13.705242600Z",
     "start_time": "2025-01-04T21:46:59.656752900Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "rZq0rKpWlWlV",
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    },
    "ExecuteTime": {
     "end_time": "2025-01-04T21:53:21.919317500Z",
     "start_time": "2025-01-04T21:48:22.710803600Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-05 00:48:23,085] A new study created in memory with name: no-name-6b272efa-15cd-4516-9a37-038402ab0a97\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1/100: Train Loss = 0.6613, Valid Loss = 0.6622\n",
      "Iteration 2/100: Train Loss = 0.6324, Valid Loss = 0.6340\n",
      "Iteration 3/100: Train Loss = 0.6060, Valid Loss = 0.6080\n",
      "Iteration 4/100: Train Loss = 0.5824, Valid Loss = 0.5849\n",
      "Iteration 5/100: Train Loss = 0.5606, Valid Loss = 0.5642\n",
      "Iteration 6/100: Train Loss = 0.5405, Valid Loss = 0.5448\n",
      "Iteration 7/100: Train Loss = 0.5224, Valid Loss = 0.5273\n",
      "Iteration 8/100: Train Loss = 0.5059, Valid Loss = 0.5113\n",
      "Iteration 9/100: Train Loss = 0.4908, Valid Loss = 0.4966\n",
      "Iteration 10/100: Train Loss = 0.4770, Valid Loss = 0.4832\n",
      "Iteration 11/100: Train Loss = 0.4641, Valid Loss = 0.4707\n",
      "Iteration 12/100: Train Loss = 0.4526, Valid Loss = 0.4594\n",
      "Iteration 13/100: Train Loss = 0.4414, Valid Loss = 0.4486\n",
      "Iteration 14/100: Train Loss = 0.4311, Valid Loss = 0.4385\n",
      "Iteration 15/100: Train Loss = 0.4217, Valid Loss = 0.4292\n",
      "Iteration 16/100: Train Loss = 0.4129, Valid Loss = 0.4205\n",
      "Iteration 17/100: Train Loss = 0.4047, Valid Loss = 0.4129\n",
      "Iteration 18/100: Train Loss = 0.3971, Valid Loss = 0.4055\n",
      "Iteration 19/100: Train Loss = 0.3899, Valid Loss = 0.3987\n",
      "Iteration 20/100: Train Loss = 0.3832, Valid Loss = 0.3927\n",
      "Iteration 21/100: Train Loss = 0.3769, Valid Loss = 0.3867\n",
      "Iteration 22/100: Train Loss = 0.3709, Valid Loss = 0.3812\n",
      "Iteration 23/100: Train Loss = 0.3655, Valid Loss = 0.3762\n",
      "Iteration 24/100: Train Loss = 0.3604, Valid Loss = 0.3714\n",
      "Iteration 25/100: Train Loss = 0.3555, Valid Loss = 0.3668\n",
      "Iteration 26/100: Train Loss = 0.3506, Valid Loss = 0.3621\n",
      "Iteration 27/100: Train Loss = 0.3462, Valid Loss = 0.3578\n",
      "Iteration 28/100: Train Loss = 0.3421, Valid Loss = 0.3537\n",
      "Iteration 29/100: Train Loss = 0.3379, Valid Loss = 0.3501\n",
      "Iteration 30/100: Train Loss = 0.3342, Valid Loss = 0.3465\n",
      "Iteration 31/100: Train Loss = 0.3305, Valid Loss = 0.3432\n",
      "Iteration 32/100: Train Loss = 0.3267, Valid Loss = 0.3399\n",
      "Iteration 33/100: Train Loss = 0.3233, Valid Loss = 0.3369\n",
      "Iteration 34/100: Train Loss = 0.3201, Valid Loss = 0.3340\n",
      "Iteration 35/100: Train Loss = 0.3172, Valid Loss = 0.3311\n",
      "Iteration 36/100: Train Loss = 0.3143, Valid Loss = 0.3283\n",
      "Iteration 37/100: Train Loss = 0.3115, Valid Loss = 0.3257\n",
      "Iteration 38/100: Train Loss = 0.3090, Valid Loss = 0.3233\n",
      "Iteration 39/100: Train Loss = 0.3065, Valid Loss = 0.3210\n",
      "Iteration 40/100: Train Loss = 0.3040, Valid Loss = 0.3188\n",
      "Iteration 41/100: Train Loss = 0.3018, Valid Loss = 0.3169\n",
      "Iteration 42/100: Train Loss = 0.2994, Valid Loss = 0.3149\n",
      "Iteration 43/100: Train Loss = 0.2974, Valid Loss = 0.3132\n",
      "Iteration 44/100: Train Loss = 0.2954, Valid Loss = 0.3113\n",
      "Iteration 45/100: Train Loss = 0.2935, Valid Loss = 0.3096\n",
      "Iteration 46/100: Train Loss = 0.2915, Valid Loss = 0.3079\n",
      "Iteration 47/100: Train Loss = 0.2897, Valid Loss = 0.3065\n",
      "Iteration 48/100: Train Loss = 0.2879, Valid Loss = 0.3045\n",
      "Iteration 49/100: Train Loss = 0.2861, Valid Loss = 0.3030\n",
      "Iteration 50/100: Train Loss = 0.2844, Valid Loss = 0.3015\n",
      "Iteration 51/100: Train Loss = 0.2827, Valid Loss = 0.2999\n",
      "Iteration 52/100: Train Loss = 0.2811, Valid Loss = 0.2985\n",
      "Iteration 53/100: Train Loss = 0.2796, Valid Loss = 0.2972\n",
      "Iteration 54/100: Train Loss = 0.2782, Valid Loss = 0.2959\n",
      "Iteration 55/100: Train Loss = 0.2768, Valid Loss = 0.2946\n",
      "Iteration 56/100: Train Loss = 0.2754, Valid Loss = 0.2934\n",
      "Iteration 57/100: Train Loss = 0.2742, Valid Loss = 0.2923\n",
      "Iteration 58/100: Train Loss = 0.2729, Valid Loss = 0.2912\n",
      "Iteration 59/100: Train Loss = 0.2716, Valid Loss = 0.2901\n",
      "Iteration 60/100: Train Loss = 0.2704, Valid Loss = 0.2892\n",
      "Iteration 61/100: Train Loss = 0.2692, Valid Loss = 0.2881\n",
      "Iteration 62/100: Train Loss = 0.2681, Valid Loss = 0.2874\n",
      "Iteration 63/100: Train Loss = 0.2670, Valid Loss = 0.2864\n",
      "Iteration 64/100: Train Loss = 0.2659, Valid Loss = 0.2854\n",
      "Iteration 65/100: Train Loss = 0.2647, Valid Loss = 0.2845\n",
      "Iteration 66/100: Train Loss = 0.2636, Valid Loss = 0.2835\n",
      "Iteration 67/100: Train Loss = 0.2625, Valid Loss = 0.2827\n",
      "Iteration 68/100: Train Loss = 0.2615, Valid Loss = 0.2818\n",
      "Iteration 69/100: Train Loss = 0.2606, Valid Loss = 0.2811\n",
      "Iteration 70/100: Train Loss = 0.2597, Valid Loss = 0.2804\n",
      "Iteration 71/100: Train Loss = 0.2587, Valid Loss = 0.2796\n",
      "Iteration 72/100: Train Loss = 0.2577, Valid Loss = 0.2786\n",
      "Iteration 73/100: Train Loss = 0.2569, Valid Loss = 0.2781\n",
      "Iteration 74/100: Train Loss = 0.2559, Valid Loss = 0.2773\n",
      "Iteration 75/100: Train Loss = 0.2551, Valid Loss = 0.2767\n",
      "Iteration 76/100: Train Loss = 0.2544, Valid Loss = 0.2760\n",
      "Iteration 77/100: Train Loss = 0.2535, Valid Loss = 0.2754\n",
      "Iteration 78/100: Train Loss = 0.2527, Valid Loss = 0.2747\n",
      "Iteration 79/100: Train Loss = 0.2519, Valid Loss = 0.2742\n",
      "Iteration 80/100: Train Loss = 0.2512, Valid Loss = 0.2736\n",
      "Iteration 81/100: Train Loss = 0.2505, Valid Loss = 0.2731\n",
      "Iteration 82/100: Train Loss = 0.2497, Valid Loss = 0.2724\n",
      "Iteration 83/100: Train Loss = 0.2490, Valid Loss = 0.2719\n",
      "Iteration 84/100: Train Loss = 0.2482, Valid Loss = 0.2713\n",
      "Iteration 85/100: Train Loss = 0.2475, Valid Loss = 0.2706\n",
      "Iteration 86/100: Train Loss = 0.2467, Valid Loss = 0.2701\n",
      "Iteration 87/100: Train Loss = 0.2460, Valid Loss = 0.2696\n",
      "Iteration 88/100: Train Loss = 0.2454, Valid Loss = 0.2691\n",
      "Iteration 89/100: Train Loss = 0.2448, Valid Loss = 0.2685\n",
      "Iteration 90/100: Train Loss = 0.2441, Valid Loss = 0.2681\n",
      "Iteration 91/100: Train Loss = 0.2434, Valid Loss = 0.2677\n",
      "Iteration 92/100: Train Loss = 0.2428, Valid Loss = 0.2672\n",
      "Iteration 93/100: Train Loss = 0.2422, Valid Loss = 0.2667\n",
      "Iteration 94/100: Train Loss = 0.2416, Valid Loss = 0.2664\n",
      "Iteration 95/100: Train Loss = 0.2409, Valid Loss = 0.2659\n",
      "Iteration 96/100: Train Loss = 0.2402, Valid Loss = 0.2654\n",
      "Iteration 97/100: Train Loss = 0.2397, Valid Loss = 0.2650\n",
      "Iteration 98/100: Train Loss = 0.2391, Valid Loss = 0.2645\n",
      "Iteration 99/100: Train Loss = 0.2386, Valid Loss = 0.2641\n",
      "Iteration 100/100: Train Loss = 0.2379, Valid Loss = 0.2638\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-05 00:48:28,020] Trial 0 finished with value: 0.9634116117421425 and parameters: {'max_depth': 6, 'min_samples_leaf': 15, 'n_estimators': 100, 'learning_rate': 0.1963547445574364, 'subsample': 0.891286506399722}. Best is trial 0 with value: 0.9634116117421425.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1/60: Train Loss = 0.6588, Valid Loss = 0.6592\n",
      "Iteration 2/60: Train Loss = 0.6287, Valid Loss = 0.6295\n",
      "Iteration 3/60: Train Loss = 0.6022, Valid Loss = 0.6036\n",
      "Iteration 4/60: Train Loss = 0.5785, Valid Loss = 0.5806\n",
      "Iteration 5/60: Train Loss = 0.5577, Valid Loss = 0.5600\n",
      "Iteration 6/60: Train Loss = 0.5387, Valid Loss = 0.5414\n",
      "Iteration 7/60: Train Loss = 0.5224, Valid Loss = 0.5261\n",
      "Iteration 8/60: Train Loss = 0.5078, Valid Loss = 0.5120\n",
      "Iteration 9/60: Train Loss = 0.4947, Valid Loss = 0.4994\n",
      "Iteration 10/60: Train Loss = 0.4830, Valid Loss = 0.4882\n",
      "Iteration 11/60: Train Loss = 0.4724, Valid Loss = 0.4778\n",
      "Iteration 12/60: Train Loss = 0.4628, Valid Loss = 0.4685\n",
      "Iteration 13/60: Train Loss = 0.4534, Valid Loss = 0.4596\n",
      "Iteration 14/60: Train Loss = 0.4451, Valid Loss = 0.4516\n",
      "Iteration 15/60: Train Loss = 0.4376, Valid Loss = 0.4443\n",
      "Iteration 16/60: Train Loss = 0.4308, Valid Loss = 0.4379\n",
      "Iteration 17/60: Train Loss = 0.4244, Valid Loss = 0.4316\n",
      "Iteration 18/60: Train Loss = 0.4181, Valid Loss = 0.4255\n",
      "Iteration 19/60: Train Loss = 0.4129, Valid Loss = 0.4205\n",
      "Iteration 20/60: Train Loss = 0.4076, Valid Loss = 0.4150\n",
      "Iteration 21/60: Train Loss = 0.4026, Valid Loss = 0.4100\n",
      "Iteration 22/60: Train Loss = 0.3981, Valid Loss = 0.4056\n",
      "Iteration 23/60: Train Loss = 0.3938, Valid Loss = 0.4015\n",
      "Iteration 24/60: Train Loss = 0.3899, Valid Loss = 0.3980\n",
      "Iteration 25/60: Train Loss = 0.3863, Valid Loss = 0.3945\n",
      "Iteration 26/60: Train Loss = 0.3825, Valid Loss = 0.3906\n",
      "Iteration 27/60: Train Loss = 0.3791, Valid Loss = 0.3873\n",
      "Iteration 28/60: Train Loss = 0.3759, Valid Loss = 0.3842\n",
      "Iteration 29/60: Train Loss = 0.3728, Valid Loss = 0.3811\n",
      "Iteration 30/60: Train Loss = 0.3698, Valid Loss = 0.3782\n",
      "Iteration 31/60: Train Loss = 0.3671, Valid Loss = 0.3755\n",
      "Iteration 32/60: Train Loss = 0.3645, Valid Loss = 0.3731\n",
      "Iteration 33/60: Train Loss = 0.3621, Valid Loss = 0.3710\n",
      "Iteration 34/60: Train Loss = 0.3597, Valid Loss = 0.3686\n",
      "Iteration 35/60: Train Loss = 0.3577, Valid Loss = 0.3665\n",
      "Iteration 36/60: Train Loss = 0.3554, Valid Loss = 0.3644\n",
      "Iteration 37/60: Train Loss = 0.3532, Valid Loss = 0.3624\n",
      "Iteration 38/60: Train Loss = 0.3514, Valid Loss = 0.3606\n",
      "Iteration 39/60: Train Loss = 0.3492, Valid Loss = 0.3586\n",
      "Iteration 40/60: Train Loss = 0.3473, Valid Loss = 0.3567\n",
      "Iteration 41/60: Train Loss = 0.3456, Valid Loss = 0.3551\n",
      "Iteration 42/60: Train Loss = 0.3436, Valid Loss = 0.3530\n",
      "Iteration 43/60: Train Loss = 0.3418, Valid Loss = 0.3514\n",
      "Iteration 44/60: Train Loss = 0.3402, Valid Loss = 0.3500\n",
      "Iteration 45/60: Train Loss = 0.3387, Valid Loss = 0.3485\n",
      "Iteration 46/60: Train Loss = 0.3372, Valid Loss = 0.3473\n",
      "Iteration 47/60: Train Loss = 0.3356, Valid Loss = 0.3460\n",
      "Iteration 48/60: Train Loss = 0.3342, Valid Loss = 0.3446\n",
      "Iteration 49/60: Train Loss = 0.3329, Valid Loss = 0.3432\n",
      "Iteration 50/60: Train Loss = 0.3314, Valid Loss = 0.3417\n",
      "Iteration 51/60: Train Loss = 0.3301, Valid Loss = 0.3402\n",
      "Iteration 52/60: Train Loss = 0.3287, Valid Loss = 0.3386\n",
      "Iteration 53/60: Train Loss = 0.3274, Valid Loss = 0.3372\n",
      "Iteration 54/60: Train Loss = 0.3262, Valid Loss = 0.3361\n",
      "Iteration 55/60: Train Loss = 0.3250, Valid Loss = 0.3350\n",
      "Iteration 56/60: Train Loss = 0.3239, Valid Loss = 0.3341\n",
      "Iteration 57/60: Train Loss = 0.3228, Valid Loss = 0.3330\n",
      "Iteration 58/60: Train Loss = 0.3218, Valid Loss = 0.3318\n",
      "Iteration 59/60: Train Loss = 0.3207, Valid Loss = 0.3308\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-05 00:48:29,350] Trial 1 finished with value: 0.9429677163522948 and parameters: {'max_depth': 2, 'min_samples_leaf': 3, 'n_estimators': 60, 'learning_rate': 0.2666096225887527, 'subsample': 0.3061639888130857}. Best is trial 0 with value: 0.9634116117421425.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 60/60: Train Loss = 0.3197, Valid Loss = 0.3298\n",
      "Iteration 1/90: Train Loss = 0.6855, Valid Loss = 0.6858\n",
      "Iteration 2/90: Train Loss = 0.6780, Valid Loss = 0.6785\n",
      "Iteration 3/90: Train Loss = 0.6707, Valid Loss = 0.6714\n",
      "Iteration 4/90: Train Loss = 0.6635, Valid Loss = 0.6644\n",
      "Iteration 5/90: Train Loss = 0.6565, Valid Loss = 0.6577\n",
      "Iteration 6/90: Train Loss = 0.6497, Valid Loss = 0.6512\n",
      "Iteration 7/90: Train Loss = 0.6429, Valid Loss = 0.6447\n",
      "Iteration 8/90: Train Loss = 0.6364, Valid Loss = 0.6384\n",
      "Iteration 9/90: Train Loss = 0.6300, Valid Loss = 0.6323\n",
      "Iteration 10/90: Train Loss = 0.6237, Valid Loss = 0.6262\n",
      "Iteration 11/90: Train Loss = 0.6175, Valid Loss = 0.6202\n",
      "Iteration 12/90: Train Loss = 0.6114, Valid Loss = 0.6144\n",
      "Iteration 13/90: Train Loss = 0.6054, Valid Loss = 0.6087\n",
      "Iteration 14/90: Train Loss = 0.5996, Valid Loss = 0.6032\n",
      "Iteration 15/90: Train Loss = 0.5939, Valid Loss = 0.5976\n",
      "Iteration 16/90: Train Loss = 0.5884, Valid Loss = 0.5923\n",
      "Iteration 17/90: Train Loss = 0.5830, Valid Loss = 0.5871\n",
      "Iteration 18/90: Train Loss = 0.5776, Valid Loss = 0.5820\n",
      "Iteration 19/90: Train Loss = 0.5723, Valid Loss = 0.5769\n",
      "Iteration 20/90: Train Loss = 0.5672, Valid Loss = 0.5719\n",
      "Iteration 21/90: Train Loss = 0.5621, Valid Loss = 0.5671\n",
      "Iteration 22/90: Train Loss = 0.5572, Valid Loss = 0.5624\n",
      "Iteration 23/90: Train Loss = 0.5523, Valid Loss = 0.5577\n",
      "Iteration 24/90: Train Loss = 0.5476, Valid Loss = 0.5532\n",
      "Iteration 25/90: Train Loss = 0.5429, Valid Loss = 0.5488\n",
      "Iteration 26/90: Train Loss = 0.5384, Valid Loss = 0.5444\n",
      "Iteration 27/90: Train Loss = 0.5339, Valid Loss = 0.5401\n",
      "Iteration 28/90: Train Loss = 0.5295, Valid Loss = 0.5360\n",
      "Iteration 29/90: Train Loss = 0.5252, Valid Loss = 0.5319\n",
      "Iteration 30/90: Train Loss = 0.5210, Valid Loss = 0.5279\n",
      "Iteration 31/90: Train Loss = 0.5169, Valid Loss = 0.5240\n",
      "Iteration 32/90: Train Loss = 0.5128, Valid Loss = 0.5200\n",
      "Iteration 33/90: Train Loss = 0.5088, Valid Loss = 0.5161\n",
      "Iteration 34/90: Train Loss = 0.5049, Valid Loss = 0.5125\n",
      "Iteration 35/90: Train Loss = 0.5011, Valid Loss = 0.5088\n",
      "Iteration 36/90: Train Loss = 0.4973, Valid Loss = 0.5051\n",
      "Iteration 37/90: Train Loss = 0.4937, Valid Loss = 0.5017\n",
      "Iteration 38/90: Train Loss = 0.4900, Valid Loss = 0.4981\n",
      "Iteration 39/90: Train Loss = 0.4865, Valid Loss = 0.4946\n",
      "Iteration 40/90: Train Loss = 0.4829, Valid Loss = 0.4913\n",
      "Iteration 41/90: Train Loss = 0.4795, Valid Loss = 0.4881\n",
      "Iteration 42/90: Train Loss = 0.4761, Valid Loss = 0.4848\n",
      "Iteration 43/90: Train Loss = 0.4728, Valid Loss = 0.4817\n",
      "Iteration 44/90: Train Loss = 0.4695, Valid Loss = 0.4786\n",
      "Iteration 45/90: Train Loss = 0.4663, Valid Loss = 0.4756\n",
      "Iteration 46/90: Train Loss = 0.4632, Valid Loss = 0.4726\n",
      "Iteration 47/90: Train Loss = 0.4601, Valid Loss = 0.4697\n",
      "Iteration 48/90: Train Loss = 0.4571, Valid Loss = 0.4669\n",
      "Iteration 49/90: Train Loss = 0.4542, Valid Loss = 0.4641\n",
      "Iteration 50/90: Train Loss = 0.4512, Valid Loss = 0.4613\n",
      "Iteration 51/90: Train Loss = 0.4483, Valid Loss = 0.4586\n",
      "Iteration 52/90: Train Loss = 0.4456, Valid Loss = 0.4561\n",
      "Iteration 53/90: Train Loss = 0.4428, Valid Loss = 0.4534\n",
      "Iteration 54/90: Train Loss = 0.4401, Valid Loss = 0.4509\n",
      "Iteration 55/90: Train Loss = 0.4374, Valid Loss = 0.4484\n",
      "Iteration 56/90: Train Loss = 0.4348, Valid Loss = 0.4460\n",
      "Iteration 57/90: Train Loss = 0.4322, Valid Loss = 0.4435\n",
      "Iteration 58/90: Train Loss = 0.4296, Valid Loss = 0.4411\n",
      "Iteration 59/90: Train Loss = 0.4271, Valid Loss = 0.4389\n",
      "Iteration 60/90: Train Loss = 0.4246, Valid Loss = 0.4365\n",
      "Iteration 61/90: Train Loss = 0.4222, Valid Loss = 0.4343\n",
      "Iteration 62/90: Train Loss = 0.4198, Valid Loss = 0.4321\n",
      "Iteration 63/90: Train Loss = 0.4175, Valid Loss = 0.4299\n",
      "Iteration 64/90: Train Loss = 0.4152, Valid Loss = 0.4278\n",
      "Iteration 65/90: Train Loss = 0.4129, Valid Loss = 0.4257\n",
      "Iteration 66/90: Train Loss = 0.4107, Valid Loss = 0.4236\n",
      "Iteration 67/90: Train Loss = 0.4085, Valid Loss = 0.4216\n",
      "Iteration 68/90: Train Loss = 0.4063, Valid Loss = 0.4196\n",
      "Iteration 69/90: Train Loss = 0.4041, Valid Loss = 0.4175\n",
      "Iteration 70/90: Train Loss = 0.4020, Valid Loss = 0.4156\n",
      "Iteration 71/90: Train Loss = 0.4000, Valid Loss = 0.4137\n",
      "Iteration 72/90: Train Loss = 0.3980, Valid Loss = 0.4119\n",
      "Iteration 73/90: Train Loss = 0.3960, Valid Loss = 0.4101\n",
      "Iteration 74/90: Train Loss = 0.3940, Valid Loss = 0.4082\n",
      "Iteration 75/90: Train Loss = 0.3921, Valid Loss = 0.4065\n",
      "Iteration 76/90: Train Loss = 0.3902, Valid Loss = 0.4047\n",
      "Iteration 77/90: Train Loss = 0.3883, Valid Loss = 0.4030\n",
      "Iteration 78/90: Train Loss = 0.3864, Valid Loss = 0.4013\n",
      "Iteration 79/90: Train Loss = 0.3846, Valid Loss = 0.3996\n",
      "Iteration 80/90: Train Loss = 0.3828, Valid Loss = 0.3980\n",
      "Iteration 81/90: Train Loss = 0.3810, Valid Loss = 0.3963\n",
      "Iteration 82/90: Train Loss = 0.3793, Valid Loss = 0.3947\n",
      "Iteration 83/90: Train Loss = 0.3775, Valid Loss = 0.3932\n",
      "Iteration 84/90: Train Loss = 0.3758, Valid Loss = 0.3916\n",
      "Iteration 85/90: Train Loss = 0.3742, Valid Loss = 0.3901\n",
      "Iteration 86/90: Train Loss = 0.3725, Valid Loss = 0.3887\n",
      "Iteration 87/90: Train Loss = 0.3709, Valid Loss = 0.3873\n",
      "Iteration 88/90: Train Loss = 0.3692, Valid Loss = 0.3858\n",
      "Iteration 89/90: Train Loss = 0.3677, Valid Loss = 0.3844\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-05 00:48:36,924] Trial 2 finished with value: 0.9606518498183163 and parameters: {'max_depth': 13, 'min_samples_leaf': 17, 'n_estimators': 90, 'learning_rate': 0.04367287985868966, 'subsample': 0.5617308329885593}. Best is trial 0 with value: 0.9634116117421425.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 90/90: Train Loss = 0.3661, Valid Loss = 0.3830\n",
      "Iteration 1/135: Train Loss = 0.6927, Valid Loss = 0.6927\n",
      "Iteration 2/135: Train Loss = 0.6922, Valid Loss = 0.6922\n",
      "Iteration 3/135: Train Loss = 0.6917, Valid Loss = 0.6917\n",
      "Iteration 4/135: Train Loss = 0.6912, Valid Loss = 0.6912\n",
      "Iteration 5/135: Train Loss = 0.6907, Valid Loss = 0.6908\n",
      "Iteration 6/135: Train Loss = 0.6902, Valid Loss = 0.6903\n",
      "Iteration 7/135: Train Loss = 0.6897, Valid Loss = 0.6898\n",
      "Iteration 8/135: Train Loss = 0.6892, Valid Loss = 0.6893\n",
      "Iteration 9/135: Train Loss = 0.6887, Valid Loss = 0.6888\n",
      "Iteration 10/135: Train Loss = 0.6883, Valid Loss = 0.6884\n",
      "Iteration 11/135: Train Loss = 0.6878, Valid Loss = 0.6879\n",
      "Iteration 12/135: Train Loss = 0.6873, Valid Loss = 0.6874\n",
      "Iteration 13/135: Train Loss = 0.6868, Valid Loss = 0.6869\n",
      "Iteration 14/135: Train Loss = 0.6863, Valid Loss = 0.6865\n",
      "Iteration 15/135: Train Loss = 0.6859, Valid Loss = 0.6860\n",
      "Iteration 16/135: Train Loss = 0.6854, Valid Loss = 0.6855\n",
      "Iteration 17/135: Train Loss = 0.6849, Valid Loss = 0.6851\n",
      "Iteration 18/135: Train Loss = 0.6844, Valid Loss = 0.6846\n",
      "Iteration 19/135: Train Loss = 0.6839, Valid Loss = 0.6841\n",
      "Iteration 20/135: Train Loss = 0.6835, Valid Loss = 0.6837\n",
      "Iteration 21/135: Train Loss = 0.6830, Valid Loss = 0.6832\n",
      "Iteration 22/135: Train Loss = 0.6825, Valid Loss = 0.6827\n",
      "Iteration 23/135: Train Loss = 0.6820, Valid Loss = 0.6823\n",
      "Iteration 24/135: Train Loss = 0.6816, Valid Loss = 0.6818\n",
      "Iteration 25/135: Train Loss = 0.6811, Valid Loss = 0.6813\n",
      "Iteration 26/135: Train Loss = 0.6806, Valid Loss = 0.6809\n",
      "Iteration 27/135: Train Loss = 0.6802, Valid Loss = 0.6804\n",
      "Iteration 28/135: Train Loss = 0.6797, Valid Loss = 0.6800\n",
      "Iteration 29/135: Train Loss = 0.6792, Valid Loss = 0.6795\n",
      "Iteration 30/135: Train Loss = 0.6787, Valid Loss = 0.6790\n",
      "Iteration 31/135: Train Loss = 0.6783, Valid Loss = 0.6786\n",
      "Iteration 32/135: Train Loss = 0.6778, Valid Loss = 0.6781\n",
      "Iteration 33/135: Train Loss = 0.6773, Valid Loss = 0.6777\n",
      "Iteration 34/135: Train Loss = 0.6769, Valid Loss = 0.6772\n",
      "Iteration 35/135: Train Loss = 0.6764, Valid Loss = 0.6768\n",
      "Iteration 36/135: Train Loss = 0.6760, Valid Loss = 0.6763\n",
      "Iteration 37/135: Train Loss = 0.6755, Valid Loss = 0.6759\n",
      "Iteration 38/135: Train Loss = 0.6750, Valid Loss = 0.6754\n",
      "Iteration 39/135: Train Loss = 0.6746, Valid Loss = 0.6750\n",
      "Iteration 40/135: Train Loss = 0.6741, Valid Loss = 0.6745\n",
      "Iteration 41/135: Train Loss = 0.6736, Valid Loss = 0.6741\n",
      "Iteration 42/135: Train Loss = 0.6732, Valid Loss = 0.6736\n",
      "Iteration 43/135: Train Loss = 0.6727, Valid Loss = 0.6732\n",
      "Iteration 44/135: Train Loss = 0.6723, Valid Loss = 0.6727\n",
      "Iteration 45/135: Train Loss = 0.6718, Valid Loss = 0.6723\n",
      "Iteration 46/135: Train Loss = 0.6713, Valid Loss = 0.6718\n",
      "Iteration 47/135: Train Loss = 0.6709, Valid Loss = 0.6714\n",
      "Iteration 48/135: Train Loss = 0.6704, Valid Loss = 0.6709\n",
      "Iteration 49/135: Train Loss = 0.6700, Valid Loss = 0.6705\n",
      "Iteration 50/135: Train Loss = 0.6695, Valid Loss = 0.6700\n",
      "Iteration 51/135: Train Loss = 0.6691, Valid Loss = 0.6696\n",
      "Iteration 52/135: Train Loss = 0.6686, Valid Loss = 0.6691\n",
      "Iteration 53/135: Train Loss = 0.6681, Valid Loss = 0.6687\n",
      "Iteration 54/135: Train Loss = 0.6677, Valid Loss = 0.6683\n",
      "Iteration 55/135: Train Loss = 0.6672, Valid Loss = 0.6678\n",
      "Iteration 56/135: Train Loss = 0.6668, Valid Loss = 0.6674\n",
      "Iteration 57/135: Train Loss = 0.6663, Valid Loss = 0.6669\n",
      "Iteration 58/135: Train Loss = 0.6659, Valid Loss = 0.6665\n",
      "Iteration 59/135: Train Loss = 0.6654, Valid Loss = 0.6661\n",
      "Iteration 60/135: Train Loss = 0.6650, Valid Loss = 0.6656\n",
      "Iteration 61/135: Train Loss = 0.6645, Valid Loss = 0.6652\n",
      "Iteration 62/135: Train Loss = 0.6641, Valid Loss = 0.6648\n",
      "Iteration 63/135: Train Loss = 0.6637, Valid Loss = 0.6643\n",
      "Iteration 64/135: Train Loss = 0.6632, Valid Loss = 0.6639\n",
      "Iteration 65/135: Train Loss = 0.6628, Valid Loss = 0.6634\n",
      "Iteration 66/135: Train Loss = 0.6623, Valid Loss = 0.6630\n",
      "Iteration 67/135: Train Loss = 0.6619, Valid Loss = 0.6626\n",
      "Iteration 68/135: Train Loss = 0.6614, Valid Loss = 0.6621\n",
      "Iteration 69/135: Train Loss = 0.6610, Valid Loss = 0.6617\n",
      "Iteration 70/135: Train Loss = 0.6606, Valid Loss = 0.6613\n",
      "Iteration 71/135: Train Loss = 0.6601, Valid Loss = 0.6609\n",
      "Iteration 72/135: Train Loss = 0.6597, Valid Loss = 0.6604\n",
      "Iteration 73/135: Train Loss = 0.6592, Valid Loss = 0.6600\n",
      "Iteration 74/135: Train Loss = 0.6588, Valid Loss = 0.6596\n",
      "Iteration 75/135: Train Loss = 0.6584, Valid Loss = 0.6591\n",
      "Iteration 76/135: Train Loss = 0.6579, Valid Loss = 0.6587\n",
      "Iteration 77/135: Train Loss = 0.6575, Valid Loss = 0.6583\n",
      "Iteration 78/135: Train Loss = 0.6571, Valid Loss = 0.6579\n",
      "Iteration 79/135: Train Loss = 0.6566, Valid Loss = 0.6574\n",
      "Iteration 80/135: Train Loss = 0.6562, Valid Loss = 0.6570\n",
      "Iteration 81/135: Train Loss = 0.6557, Valid Loss = 0.6566\n",
      "Iteration 82/135: Train Loss = 0.6553, Valid Loss = 0.6562\n",
      "Iteration 83/135: Train Loss = 0.6549, Valid Loss = 0.6557\n",
      "Iteration 84/135: Train Loss = 0.6544, Valid Loss = 0.6553\n",
      "Iteration 85/135: Train Loss = 0.6540, Valid Loss = 0.6549\n",
      "Iteration 86/135: Train Loss = 0.6536, Valid Loss = 0.6545\n",
      "Iteration 87/135: Train Loss = 0.6532, Valid Loss = 0.6541\n",
      "Iteration 88/135: Train Loss = 0.6527, Valid Loss = 0.6536\n",
      "Iteration 89/135: Train Loss = 0.6523, Valid Loss = 0.6532\n",
      "Iteration 90/135: Train Loss = 0.6519, Valid Loss = 0.6528\n",
      "Iteration 91/135: Train Loss = 0.6514, Valid Loss = 0.6524\n",
      "Iteration 92/135: Train Loss = 0.6510, Valid Loss = 0.6520\n",
      "Iteration 93/135: Train Loss = 0.6506, Valid Loss = 0.6515\n",
      "Iteration 94/135: Train Loss = 0.6502, Valid Loss = 0.6511\n",
      "Iteration 95/135: Train Loss = 0.6497, Valid Loss = 0.6507\n",
      "Iteration 96/135: Train Loss = 0.6493, Valid Loss = 0.6503\n",
      "Iteration 97/135: Train Loss = 0.6489, Valid Loss = 0.6499\n",
      "Iteration 98/135: Train Loss = 0.6485, Valid Loss = 0.6495\n",
      "Iteration 99/135: Train Loss = 0.6481, Valid Loss = 0.6491\n",
      "Iteration 100/135: Train Loss = 0.6476, Valid Loss = 0.6486\n",
      "Iteration 101/135: Train Loss = 0.6472, Valid Loss = 0.6482\n",
      "Iteration 102/135: Train Loss = 0.6468, Valid Loss = 0.6478\n",
      "Iteration 103/135: Train Loss = 0.6464, Valid Loss = 0.6474\n",
      "Iteration 104/135: Train Loss = 0.6460, Valid Loss = 0.6470\n",
      "Iteration 105/135: Train Loss = 0.6455, Valid Loss = 0.6466\n",
      "Iteration 106/135: Train Loss = 0.6451, Valid Loss = 0.6462\n",
      "Iteration 107/135: Train Loss = 0.6447, Valid Loss = 0.6458\n",
      "Iteration 108/135: Train Loss = 0.6443, Valid Loss = 0.6454\n",
      "Iteration 109/135: Train Loss = 0.6439, Valid Loss = 0.6450\n",
      "Iteration 110/135: Train Loss = 0.6435, Valid Loss = 0.6446\n",
      "Iteration 111/135: Train Loss = 0.6430, Valid Loss = 0.6442\n",
      "Iteration 112/135: Train Loss = 0.6426, Valid Loss = 0.6437\n",
      "Iteration 113/135: Train Loss = 0.6422, Valid Loss = 0.6433\n",
      "Iteration 114/135: Train Loss = 0.6418, Valid Loss = 0.6429\n",
      "Iteration 115/135: Train Loss = 0.6414, Valid Loss = 0.6425\n",
      "Iteration 116/135: Train Loss = 0.6410, Valid Loss = 0.6421\n",
      "Iteration 117/135: Train Loss = 0.6406, Valid Loss = 0.6417\n",
      "Iteration 118/135: Train Loss = 0.6402, Valid Loss = 0.6413\n",
      "Iteration 119/135: Train Loss = 0.6398, Valid Loss = 0.6409\n",
      "Iteration 120/135: Train Loss = 0.6394, Valid Loss = 0.6405\n",
      "Iteration 121/135: Train Loss = 0.6389, Valid Loss = 0.6401\n",
      "Iteration 122/135: Train Loss = 0.6385, Valid Loss = 0.6397\n",
      "Iteration 123/135: Train Loss = 0.6381, Valid Loss = 0.6393\n",
      "Iteration 124/135: Train Loss = 0.6377, Valid Loss = 0.6389\n",
      "Iteration 125/135: Train Loss = 0.6373, Valid Loss = 0.6385\n",
      "Iteration 126/135: Train Loss = 0.6369, Valid Loss = 0.6381\n",
      "Iteration 127/135: Train Loss = 0.6365, Valid Loss = 0.6378\n",
      "Iteration 128/135: Train Loss = 0.6361, Valid Loss = 0.6374\n",
      "Iteration 129/135: Train Loss = 0.6357, Valid Loss = 0.6370\n",
      "Iteration 130/135: Train Loss = 0.6353, Valid Loss = 0.6366\n",
      "Iteration 131/135: Train Loss = 0.6349, Valid Loss = 0.6362\n",
      "Iteration 132/135: Train Loss = 0.6345, Valid Loss = 0.6358\n",
      "Iteration 133/135: Train Loss = 0.6341, Valid Loss = 0.6354\n",
      "Iteration 134/135: Train Loss = 0.6337, Valid Loss = 0.6350\n",
      "Iteration 135/135: Train Loss = 0.6333, Valid Loss = 0.6346\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-05 00:48:41,535] Trial 3 finished with value: 0.9423801516763322 and parameters: {'max_depth': 4, 'min_samples_leaf': 9, 'n_estimators': 135, 'learning_rate': 0.0032090841107833903, 'subsample': 0.7855580070630542}. Best is trial 0 with value: 0.9634116117421425.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1/70: Train Loss = 0.6915, Valid Loss = 0.6915\n",
      "Iteration 2/70: Train Loss = 0.6899, Valid Loss = 0.6899\n",
      "Iteration 3/70: Train Loss = 0.6882, Valid Loss = 0.6883\n",
      "Iteration 4/70: Train Loss = 0.6866, Valid Loss = 0.6868\n",
      "Iteration 5/70: Train Loss = 0.6850, Valid Loss = 0.6852\n",
      "Iteration 6/70: Train Loss = 0.6833, Valid Loss = 0.6836\n",
      "Iteration 7/70: Train Loss = 0.6817, Valid Loss = 0.6820\n",
      "Iteration 8/70: Train Loss = 0.6801, Valid Loss = 0.6805\n",
      "Iteration 9/70: Train Loss = 0.6786, Valid Loss = 0.6789\n",
      "Iteration 10/70: Train Loss = 0.6770, Valid Loss = 0.6774\n",
      "Iteration 11/70: Train Loss = 0.6754, Valid Loss = 0.6758\n",
      "Iteration 12/70: Train Loss = 0.6739, Valid Loss = 0.6743\n",
      "Iteration 13/70: Train Loss = 0.6723, Valid Loss = 0.6728\n",
      "Iteration 14/70: Train Loss = 0.6708, Valid Loss = 0.6713\n",
      "Iteration 15/70: Train Loss = 0.6692, Valid Loss = 0.6698\n",
      "Iteration 16/70: Train Loss = 0.6677, Valid Loss = 0.6683\n",
      "Iteration 17/70: Train Loss = 0.6662, Valid Loss = 0.6668\n",
      "Iteration 18/70: Train Loss = 0.6647, Valid Loss = 0.6653\n",
      "Iteration 19/70: Train Loss = 0.6631, Valid Loss = 0.6639\n",
      "Iteration 20/70: Train Loss = 0.6616, Valid Loss = 0.6624\n",
      "Iteration 21/70: Train Loss = 0.6601, Valid Loss = 0.6609\n",
      "Iteration 22/70: Train Loss = 0.6586, Valid Loss = 0.6595\n",
      "Iteration 23/70: Train Loss = 0.6571, Valid Loss = 0.6580\n",
      "Iteration 24/70: Train Loss = 0.6556, Valid Loss = 0.6566\n",
      "Iteration 25/70: Train Loss = 0.6542, Valid Loss = 0.6551\n",
      "Iteration 26/70: Train Loss = 0.6527, Valid Loss = 0.6537\n",
      "Iteration 27/70: Train Loss = 0.6512, Valid Loss = 0.6522\n",
      "Iteration 28/70: Train Loss = 0.6498, Valid Loss = 0.6508\n",
      "Iteration 29/70: Train Loss = 0.6484, Valid Loss = 0.6494\n",
      "Iteration 30/70: Train Loss = 0.6469, Valid Loss = 0.6480\n",
      "Iteration 31/70: Train Loss = 0.6455, Valid Loss = 0.6466\n",
      "Iteration 32/70: Train Loss = 0.6440, Valid Loss = 0.6452\n",
      "Iteration 33/70: Train Loss = 0.6426, Valid Loss = 0.6438\n",
      "Iteration 34/70: Train Loss = 0.6412, Valid Loss = 0.6425\n",
      "Iteration 35/70: Train Loss = 0.6398, Valid Loss = 0.6411\n",
      "Iteration 36/70: Train Loss = 0.6384, Valid Loss = 0.6397\n",
      "Iteration 37/70: Train Loss = 0.6370, Valid Loss = 0.6384\n",
      "Iteration 38/70: Train Loss = 0.6356, Valid Loss = 0.6370\n",
      "Iteration 39/70: Train Loss = 0.6342, Valid Loss = 0.6357\n",
      "Iteration 40/70: Train Loss = 0.6329, Valid Loss = 0.6343\n",
      "Iteration 41/70: Train Loss = 0.6315, Valid Loss = 0.6330\n",
      "Iteration 42/70: Train Loss = 0.6302, Valid Loss = 0.6317\n",
      "Iteration 43/70: Train Loss = 0.6288, Valid Loss = 0.6304\n",
      "Iteration 44/70: Train Loss = 0.6275, Valid Loss = 0.6291\n",
      "Iteration 45/70: Train Loss = 0.6261, Valid Loss = 0.6278\n",
      "Iteration 46/70: Train Loss = 0.6248, Valid Loss = 0.6265\n",
      "Iteration 47/70: Train Loss = 0.6235, Valid Loss = 0.6252\n",
      "Iteration 48/70: Train Loss = 0.6221, Valid Loss = 0.6239\n",
      "Iteration 49/70: Train Loss = 0.6208, Valid Loss = 0.6226\n",
      "Iteration 50/70: Train Loss = 0.6195, Valid Loss = 0.6214\n",
      "Iteration 51/70: Train Loss = 0.6182, Valid Loss = 0.6201\n",
      "Iteration 52/70: Train Loss = 0.6169, Valid Loss = 0.6188\n",
      "Iteration 53/70: Train Loss = 0.6156, Valid Loss = 0.6176\n",
      "Iteration 54/70: Train Loss = 0.6143, Valid Loss = 0.6163\n",
      "Iteration 55/70: Train Loss = 0.6131, Valid Loss = 0.6151\n",
      "Iteration 56/70: Train Loss = 0.6118, Valid Loss = 0.6138\n",
      "Iteration 57/70: Train Loss = 0.6105, Valid Loss = 0.6126\n",
      "Iteration 58/70: Train Loss = 0.6093, Valid Loss = 0.6114\n",
      "Iteration 59/70: Train Loss = 0.6080, Valid Loss = 0.6102\n",
      "Iteration 60/70: Train Loss = 0.6068, Valid Loss = 0.6090\n",
      "Iteration 61/70: Train Loss = 0.6055, Valid Loss = 0.6078\n",
      "Iteration 62/70: Train Loss = 0.6043, Valid Loss = 0.6065\n",
      "Iteration 63/70: Train Loss = 0.6031, Valid Loss = 0.6053\n",
      "Iteration 64/70: Train Loss = 0.6019, Valid Loss = 0.6042\n",
      "Iteration 65/70: Train Loss = 0.6006, Valid Loss = 0.6030\n",
      "Iteration 66/70: Train Loss = 0.5994, Valid Loss = 0.6018\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-05 00:48:45,063] Trial 4 finished with value: 0.9547384555551743 and parameters: {'max_depth': 6, 'min_samples_leaf': 4, 'n_estimators': 70, 'learning_rate': 0.009898303014954486, 'subsample': 0.8056415957658534}. Best is trial 0 with value: 0.9634116117421425.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 67/70: Train Loss = 0.5982, Valid Loss = 0.6006\n",
      "Iteration 68/70: Train Loss = 0.5970, Valid Loss = 0.5994\n",
      "Iteration 69/70: Train Loss = 0.5958, Valid Loss = 0.5983\n",
      "Iteration 70/70: Train Loss = 0.5946, Valid Loss = 0.5971\n",
      "Iteration 1/40: Train Loss = 0.6806, Valid Loss = 0.6814\n",
      "Iteration 2/40: Train Loss = 0.6686, Valid Loss = 0.6700\n",
      "Iteration 3/40: Train Loss = 0.6569, Valid Loss = 0.6591\n",
      "Iteration 4/40: Train Loss = 0.6456, Valid Loss = 0.6485\n",
      "Iteration 5/40: Train Loss = 0.6346, Valid Loss = 0.6385\n",
      "Iteration 6/40: Train Loss = 0.6239, Valid Loss = 0.6285\n",
      "Iteration 7/40: Train Loss = 0.6136, Valid Loss = 0.6189\n",
      "Iteration 8/40: Train Loss = 0.6037, Valid Loss = 0.6097\n",
      "Iteration 9/40: Train Loss = 0.5940, Valid Loss = 0.6008\n",
      "Iteration 10/40: Train Loss = 0.5846, Valid Loss = 0.5920\n",
      "Iteration 11/40: Train Loss = 0.5755, Valid Loss = 0.5836\n",
      "Iteration 12/40: Train Loss = 0.5667, Valid Loss = 0.5757\n",
      "Iteration 13/40: Train Loss = 0.5582, Valid Loss = 0.5677\n",
      "Iteration 14/40: Train Loss = 0.5501, Valid Loss = 0.5600\n",
      "Iteration 15/40: Train Loss = 0.5421, Valid Loss = 0.5526\n",
      "Iteration 16/40: Train Loss = 0.5345, Valid Loss = 0.5454\n",
      "Iteration 17/40: Train Loss = 0.5269, Valid Loss = 0.5385\n",
      "Iteration 18/40: Train Loss = 0.5196, Valid Loss = 0.5318\n",
      "Iteration 19/40: Train Loss = 0.5126, Valid Loss = 0.5252\n",
      "Iteration 20/40: Train Loss = 0.5058, Valid Loss = 0.5189\n",
      "Iteration 21/40: Train Loss = 0.4992, Valid Loss = 0.5129\n",
      "Iteration 22/40: Train Loss = 0.4929, Valid Loss = 0.5072\n",
      "Iteration 23/40: Train Loss = 0.4867, Valid Loss = 0.5014\n",
      "Iteration 24/40: Train Loss = 0.4805, Valid Loss = 0.4960\n",
      "Iteration 25/40: Train Loss = 0.4745, Valid Loss = 0.4907\n",
      "Iteration 26/40: Train Loss = 0.4687, Valid Loss = 0.4856\n",
      "Iteration 27/40: Train Loss = 0.4632, Valid Loss = 0.4806\n",
      "Iteration 28/40: Train Loss = 0.4577, Valid Loss = 0.4757\n",
      "Iteration 29/40: Train Loss = 0.4523, Valid Loss = 0.4706\n",
      "Iteration 30/40: Train Loss = 0.4472, Valid Loss = 0.4660\n",
      "Iteration 31/40: Train Loss = 0.4421, Valid Loss = 0.4616\n",
      "Iteration 32/40: Train Loss = 0.4372, Valid Loss = 0.4574\n",
      "Iteration 33/40: Train Loss = 0.4324, Valid Loss = 0.4529\n",
      "Iteration 34/40: Train Loss = 0.4278, Valid Loss = 0.4486\n",
      "Iteration 35/40: Train Loss = 0.4233, Valid Loss = 0.4445\n",
      "Iteration 36/40: Train Loss = 0.4189, Valid Loss = 0.4406\n",
      "Iteration 37/40: Train Loss = 0.4146, Valid Loss = 0.4367\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-05 00:48:47,925] Trial 5 finished with value: 0.961980638199711 and parameters: {'max_depth': 11, 'min_samples_leaf': 2, 'n_estimators': 40, 'learning_rate': 0.06805801796704439, 'subsample': 0.4791400074259886}. Best is trial 0 with value: 0.9634116117421425.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 38/40: Train Loss = 0.4105, Valid Loss = 0.4331\n",
      "Iteration 39/40: Train Loss = 0.4065, Valid Loss = 0.4295\n",
      "Iteration 40/40: Train Loss = 0.4025, Valid Loss = 0.4258\n",
      "Iteration 1/130: Train Loss = 0.6467, Valid Loss = 0.6476\n",
      "Iteration 2/130: Train Loss = 0.6062, Valid Loss = 0.6085\n",
      "Iteration 3/130: Train Loss = 0.5713, Valid Loss = 0.5744\n",
      "Iteration 4/130: Train Loss = 0.5407, Valid Loss = 0.5447\n",
      "Iteration 5/130: Train Loss = 0.5145, Valid Loss = 0.5194\n",
      "Iteration 6/130: Train Loss = 0.4916, Valid Loss = 0.4971\n",
      "Iteration 7/130: Train Loss = 0.4711, Valid Loss = 0.4770\n",
      "Iteration 8/130: Train Loss = 0.4534, Valid Loss = 0.4600\n",
      "Iteration 9/130: Train Loss = 0.4375, Valid Loss = 0.4449\n",
      "Iteration 10/130: Train Loss = 0.4231, Valid Loss = 0.4310\n",
      "Iteration 11/130: Train Loss = 0.4100, Valid Loss = 0.4186\n",
      "Iteration 12/130: Train Loss = 0.3986, Valid Loss = 0.4073\n",
      "Iteration 13/130: Train Loss = 0.3883, Valid Loss = 0.3974\n",
      "Iteration 14/130: Train Loss = 0.3788, Valid Loss = 0.3880\n",
      "Iteration 15/130: Train Loss = 0.3702, Valid Loss = 0.3799\n",
      "Iteration 16/130: Train Loss = 0.3624, Valid Loss = 0.3725\n",
      "Iteration 17/130: Train Loss = 0.3551, Valid Loss = 0.3656\n",
      "Iteration 18/130: Train Loss = 0.3484, Valid Loss = 0.3594\n",
      "Iteration 19/130: Train Loss = 0.3423, Valid Loss = 0.3538\n",
      "Iteration 20/130: Train Loss = 0.3366, Valid Loss = 0.3482\n",
      "Iteration 21/130: Train Loss = 0.3312, Valid Loss = 0.3436\n",
      "Iteration 22/130: Train Loss = 0.3261, Valid Loss = 0.3395\n",
      "Iteration 23/130: Train Loss = 0.3215, Valid Loss = 0.3350\n",
      "Iteration 24/130: Train Loss = 0.3172, Valid Loss = 0.3309\n",
      "Iteration 25/130: Train Loss = 0.3132, Valid Loss = 0.3272\n",
      "Iteration 26/130: Train Loss = 0.3094, Valid Loss = 0.3237\n",
      "Iteration 27/130: Train Loss = 0.3056, Valid Loss = 0.3205\n",
      "Iteration 28/130: Train Loss = 0.3022, Valid Loss = 0.3177\n",
      "Iteration 29/130: Train Loss = 0.2992, Valid Loss = 0.3149\n",
      "Iteration 30/130: Train Loss = 0.2962, Valid Loss = 0.3121\n",
      "Iteration 31/130: Train Loss = 0.2933, Valid Loss = 0.3094\n",
      "Iteration 32/130: Train Loss = 0.2906, Valid Loss = 0.3068\n",
      "Iteration 33/130: Train Loss = 0.2880, Valid Loss = 0.3048\n",
      "Iteration 34/130: Train Loss = 0.2857, Valid Loss = 0.3026\n",
      "Iteration 35/130: Train Loss = 0.2831, Valid Loss = 0.3004\n",
      "Iteration 36/130: Train Loss = 0.2807, Valid Loss = 0.2984\n",
      "Iteration 37/130: Train Loss = 0.2786, Valid Loss = 0.2965\n",
      "Iteration 38/130: Train Loss = 0.2766, Valid Loss = 0.2946\n",
      "Iteration 39/130: Train Loss = 0.2747, Valid Loss = 0.2928\n",
      "Iteration 40/130: Train Loss = 0.2729, Valid Loss = 0.2914\n",
      "Iteration 41/130: Train Loss = 0.2712, Valid Loss = 0.2898\n",
      "Iteration 42/130: Train Loss = 0.2691, Valid Loss = 0.2879\n",
      "Iteration 43/130: Train Loss = 0.2675, Valid Loss = 0.2863\n",
      "Iteration 44/130: Train Loss = 0.2660, Valid Loss = 0.2851\n",
      "Iteration 45/130: Train Loss = 0.2644, Valid Loss = 0.2837\n",
      "Iteration 46/130: Train Loss = 0.2630, Valid Loss = 0.2827\n",
      "Iteration 47/130: Train Loss = 0.2616, Valid Loss = 0.2815\n",
      "Iteration 48/130: Train Loss = 0.2604, Valid Loss = 0.2805\n",
      "Iteration 49/130: Train Loss = 0.2591, Valid Loss = 0.2793\n",
      "Iteration 50/130: Train Loss = 0.2578, Valid Loss = 0.2785\n",
      "Iteration 51/130: Train Loss = 0.2566, Valid Loss = 0.2774\n",
      "Iteration 52/130: Train Loss = 0.2552, Valid Loss = 0.2764\n",
      "Iteration 53/130: Train Loss = 0.2541, Valid Loss = 0.2753\n",
      "Iteration 54/130: Train Loss = 0.2530, Valid Loss = 0.2745\n",
      "Iteration 55/130: Train Loss = 0.2520, Valid Loss = 0.2737\n",
      "Iteration 56/130: Train Loss = 0.2510, Valid Loss = 0.2729\n",
      "Iteration 57/130: Train Loss = 0.2500, Valid Loss = 0.2719\n",
      "Iteration 58/130: Train Loss = 0.2489, Valid Loss = 0.2712\n",
      "Iteration 59/130: Train Loss = 0.2480, Valid Loss = 0.2704\n",
      "Iteration 60/130: Train Loss = 0.2471, Valid Loss = 0.2699\n",
      "Iteration 61/130: Train Loss = 0.2463, Valid Loss = 0.2692\n",
      "Iteration 62/130: Train Loss = 0.2452, Valid Loss = 0.2684\n",
      "Iteration 63/130: Train Loss = 0.2444, Valid Loss = 0.2677\n",
      "Iteration 64/130: Train Loss = 0.2435, Valid Loss = 0.2670\n",
      "Iteration 65/130: Train Loss = 0.2427, Valid Loss = 0.2663\n",
      "Iteration 66/130: Train Loss = 0.2418, Valid Loss = 0.2654\n",
      "Iteration 67/130: Train Loss = 0.2410, Valid Loss = 0.2646\n",
      "Iteration 68/130: Train Loss = 0.2401, Valid Loss = 0.2639\n",
      "Iteration 69/130: Train Loss = 0.2394, Valid Loss = 0.2634\n",
      "Iteration 70/130: Train Loss = 0.2386, Valid Loss = 0.2628\n",
      "Iteration 71/130: Train Loss = 0.2378, Valid Loss = 0.2622\n",
      "Iteration 72/130: Train Loss = 0.2372, Valid Loss = 0.2619\n",
      "Iteration 73/130: Train Loss = 0.2366, Valid Loss = 0.2615\n",
      "Iteration 74/130: Train Loss = 0.2359, Valid Loss = 0.2613\n",
      "Iteration 75/130: Train Loss = 0.2353, Valid Loss = 0.2609\n",
      "Iteration 76/130: Train Loss = 0.2346, Valid Loss = 0.2605\n",
      "Iteration 77/130: Train Loss = 0.2340, Valid Loss = 0.2599\n",
      "Iteration 78/130: Train Loss = 0.2333, Valid Loss = 0.2596\n",
      "Iteration 79/130: Train Loss = 0.2327, Valid Loss = 0.2591\n",
      "Iteration 80/130: Train Loss = 0.2322, Valid Loss = 0.2586\n",
      "Iteration 81/130: Train Loss = 0.2316, Valid Loss = 0.2582\n",
      "Iteration 82/130: Train Loss = 0.2310, Valid Loss = 0.2576\n",
      "Iteration 83/130: Train Loss = 0.2305, Valid Loss = 0.2571\n",
      "Iteration 84/130: Train Loss = 0.2300, Valid Loss = 0.2569\n",
      "Iteration 85/130: Train Loss = 0.2295, Valid Loss = 0.2566\n",
      "Iteration 86/130: Train Loss = 0.2288, Valid Loss = 0.2561\n",
      "Iteration 87/130: Train Loss = 0.2283, Valid Loss = 0.2560\n",
      "Iteration 88/130: Train Loss = 0.2279, Valid Loss = 0.2555\n",
      "Iteration 89/130: Train Loss = 0.2273, Valid Loss = 0.2552\n",
      "Iteration 90/130: Train Loss = 0.2268, Valid Loss = 0.2548\n",
      "Iteration 91/130: Train Loss = 0.2262, Valid Loss = 0.2544\n",
      "Iteration 92/130: Train Loss = 0.2257, Valid Loss = 0.2540\n",
      "Iteration 93/130: Train Loss = 0.2252, Valid Loss = 0.2536\n",
      "Iteration 94/130: Train Loss = 0.2248, Valid Loss = 0.2533\n",
      "Iteration 95/130: Train Loss = 0.2244, Valid Loss = 0.2531\n",
      "Iteration 96/130: Train Loss = 0.2239, Valid Loss = 0.2526\n",
      "Iteration 97/130: Train Loss = 0.2235, Valid Loss = 0.2523\n",
      "Iteration 98/130: Train Loss = 0.2231, Valid Loss = 0.2521\n",
      "Iteration 99/130: Train Loss = 0.2227, Valid Loss = 0.2516\n",
      "Iteration 100/130: Train Loss = 0.2223, Valid Loss = 0.2511\n",
      "Iteration 101/130: Train Loss = 0.2220, Valid Loss = 0.2509\n",
      "Iteration 102/130: Train Loss = 0.2215, Valid Loss = 0.2505\n",
      "Iteration 103/130: Train Loss = 0.2211, Valid Loss = 0.2501\n",
      "Iteration 104/130: Train Loss = 0.2207, Valid Loss = 0.2500\n",
      "Iteration 105/130: Train Loss = 0.2203, Valid Loss = 0.2498\n",
      "Iteration 106/130: Train Loss = 0.2199, Valid Loss = 0.2496\n",
      "Iteration 107/130: Train Loss = 0.2195, Valid Loss = 0.2493\n",
      "Iteration 108/130: Train Loss = 0.2191, Valid Loss = 0.2492\n",
      "Iteration 109/130: Train Loss = 0.2188, Valid Loss = 0.2488\n",
      "Iteration 110/130: Train Loss = 0.2184, Valid Loss = 0.2484\n",
      "Iteration 111/130: Train Loss = 0.2180, Valid Loss = 0.2483\n",
      "Iteration 112/130: Train Loss = 0.2176, Valid Loss = 0.2479\n",
      "Iteration 113/130: Train Loss = 0.2173, Valid Loss = 0.2477\n",
      "Iteration 114/130: Train Loss = 0.2170, Valid Loss = 0.2476\n",
      "Iteration 115/130: Train Loss = 0.2167, Valid Loss = 0.2475\n",
      "Iteration 116/130: Train Loss = 0.2164, Valid Loss = 0.2473\n",
      "Iteration 117/130: Train Loss = 0.2161, Valid Loss = 0.2470\n",
      "Iteration 118/130: Train Loss = 0.2157, Valid Loss = 0.2468\n",
      "Iteration 119/130: Train Loss = 0.2154, Valid Loss = 0.2466\n",
      "Iteration 120/130: Train Loss = 0.2151, Valid Loss = 0.2464\n",
      "Iteration 121/130: Train Loss = 0.2148, Valid Loss = 0.2462\n",
      "Iteration 122/130: Train Loss = 0.2144, Valid Loss = 0.2460\n",
      "Iteration 123/130: Train Loss = 0.2142, Valid Loss = 0.2459\n",
      "Iteration 124/130: Train Loss = 0.2140, Valid Loss = 0.2457\n",
      "Iteration 125/130: Train Loss = 0.2136, Valid Loss = 0.2454\n",
      "Iteration 126/130: Train Loss = 0.2134, Valid Loss = 0.2453\n",
      "Iteration 127/130: Train Loss = 0.2131, Valid Loss = 0.2452\n",
      "Iteration 128/130: Train Loss = 0.2128, Valid Loss = 0.2449\n",
      "Iteration 129/130: Train Loss = 0.2126, Valid Loss = 0.2448\n",
      "Iteration 130/130: Train Loss = 0.2124, Valid Loss = 0.2446\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-05 00:48:54,434] Trial 6 finished with value: 0.965235693124235 and parameters: {'max_depth': 6, 'min_samples_leaf': 20, 'n_estimators': 130, 'learning_rate': 0.2923279505403704, 'subsample': 0.8205317126256255}. Best is trial 6 with value: 0.965235693124235.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1/15: Train Loss = 0.6499, Valid Loss = 0.6506\n",
      "Iteration 2/15: Train Loss = 0.6117, Valid Loss = 0.6132\n",
      "Iteration 3/15: Train Loss = 0.5788, Valid Loss = 0.5814\n",
      "Iteration 4/15: Train Loss = 0.5495, Valid Loss = 0.5528\n",
      "Iteration 5/15: Train Loss = 0.5241, Valid Loss = 0.5281\n",
      "Iteration 6/15: Train Loss = 0.5018, Valid Loss = 0.5064\n",
      "Iteration 7/15: Train Loss = 0.4820, Valid Loss = 0.4870\n",
      "Iteration 8/15: Train Loss = 0.4645, Valid Loss = 0.4703\n",
      "Iteration 9/15: Train Loss = 0.4491, Valid Loss = 0.4553\n",
      "Iteration 10/15: Train Loss = 0.4350, Valid Loss = 0.4421\n",
      "Iteration 11/15: Train Loss = 0.4226, Valid Loss = 0.4304\n",
      "Iteration 12/15: Train Loss = 0.4111, Valid Loss = 0.4193\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-05 00:48:54,994] Trial 7 finished with value: 0.9531583984382447 and parameters: {'max_depth': 5, 'min_samples_leaf': 2, 'n_estimators': 15, 'learning_rate': 0.28060934083460354, 'subsample': 0.6232983217747247}. Best is trial 6 with value: 0.965235693124235.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 13/15: Train Loss = 0.4007, Valid Loss = 0.4090\n",
      "Iteration 14/15: Train Loss = 0.3912, Valid Loss = 0.3999\n",
      "Iteration 15/15: Train Loss = 0.3825, Valid Loss = 0.3919\n",
      "Iteration 1/25: Train Loss = 0.6924, Valid Loss = 0.6924\n",
      "Iteration 2/25: Train Loss = 0.6916, Valid Loss = 0.6916\n",
      "Iteration 3/25: Train Loss = 0.6908, Valid Loss = 0.6909\n",
      "Iteration 4/25: Train Loss = 0.6901, Valid Loss = 0.6901\n",
      "Iteration 5/25: Train Loss = 0.6893, Valid Loss = 0.6894\n",
      "Iteration 6/25: Train Loss = 0.6886, Valid Loss = 0.6887\n",
      "Iteration 7/25: Train Loss = 0.6878, Valid Loss = 0.6879\n",
      "Iteration 8/25: Train Loss = 0.6870, Valid Loss = 0.6872\n",
      "Iteration 9/25: Train Loss = 0.6863, Valid Loss = 0.6864\n",
      "Iteration 10/25: Train Loss = 0.6855, Valid Loss = 0.6857\n",
      "Iteration 11/25: Train Loss = 0.6848, Valid Loss = 0.6850\n",
      "Iteration 12/25: Train Loss = 0.6840, Valid Loss = 0.6842\n",
      "Iteration 13/25: Train Loss = 0.6833, Valid Loss = 0.6835\n",
      "Iteration 14/25: Train Loss = 0.6825, Valid Loss = 0.6828\n",
      "Iteration 15/25: Train Loss = 0.6818, Valid Loss = 0.6820\n",
      "Iteration 16/25: Train Loss = 0.6810, Valid Loss = 0.6813\n",
      "Iteration 17/25: Train Loss = 0.6803, Valid Loss = 0.6806\n",
      "Iteration 18/25: Train Loss = 0.6796, Valid Loss = 0.6799\n",
      "Iteration 19/25: Train Loss = 0.6788, Valid Loss = 0.6791\n",
      "Iteration 20/25: Train Loss = 0.6781, Valid Loss = 0.6784\n",
      "Iteration 21/25: Train Loss = 0.6774, Valid Loss = 0.6777\n",
      "Iteration 22/25: Train Loss = 0.6767, Valid Loss = 0.6770\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-05 00:48:55,859] Trial 8 finished with value: 0.9522135669865673 and parameters: {'max_depth': 6, 'min_samples_leaf': 15, 'n_estimators': 25, 'learning_rate': 0.004664387916906928, 'subsample': 0.35150799819676903}. Best is trial 6 with value: 0.965235693124235.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 23/25: Train Loss = 0.6759, Valid Loss = 0.6763\n",
      "Iteration 24/25: Train Loss = 0.6752, Valid Loss = 0.6756\n",
      "Iteration 25/25: Train Loss = 0.6745, Valid Loss = 0.6748\n",
      "Iteration 1/135: Train Loss = 0.6836, Valid Loss = 0.6842\n",
      "Iteration 2/135: Train Loss = 0.6743, Valid Loss = 0.6755\n",
      "Iteration 3/135: Train Loss = 0.6653, Valid Loss = 0.6670\n",
      "Iteration 4/135: Train Loss = 0.6564, Valid Loss = 0.6586\n",
      "Iteration 5/135: Train Loss = 0.6478, Valid Loss = 0.6504\n",
      "Iteration 6/135: Train Loss = 0.6394, Valid Loss = 0.6425\n",
      "Iteration 7/135: Train Loss = 0.6313, Valid Loss = 0.6348\n",
      "Iteration 8/135: Train Loss = 0.6232, Valid Loss = 0.6272\n",
      "Iteration 9/135: Train Loss = 0.6155, Valid Loss = 0.6199\n",
      "Iteration 10/135: Train Loss = 0.6079, Valid Loss = 0.6128\n",
      "Iteration 11/135: Train Loss = 0.6005, Valid Loss = 0.6060\n",
      "Iteration 12/135: Train Loss = 0.5934, Valid Loss = 0.5993\n",
      "Iteration 13/135: Train Loss = 0.5863, Valid Loss = 0.5926\n",
      "Iteration 14/135: Train Loss = 0.5794, Valid Loss = 0.5861\n",
      "Iteration 15/135: Train Loss = 0.5727, Valid Loss = 0.5799\n",
      "Iteration 16/135: Train Loss = 0.5661, Valid Loss = 0.5737\n",
      "Iteration 17/135: Train Loss = 0.5597, Valid Loss = 0.5676\n",
      "Iteration 18/135: Train Loss = 0.5534, Valid Loss = 0.5618\n",
      "Iteration 19/135: Train Loss = 0.5473, Valid Loss = 0.5562\n",
      "Iteration 20/135: Train Loss = 0.5412, Valid Loss = 0.5506\n",
      "Iteration 21/135: Train Loss = 0.5353, Valid Loss = 0.5453\n",
      "Iteration 22/135: Train Loss = 0.5297, Valid Loss = 0.5400\n",
      "Iteration 23/135: Train Loss = 0.5241, Valid Loss = 0.5349\n",
      "Iteration 24/135: Train Loss = 0.5186, Valid Loss = 0.5299\n",
      "Iteration 25/135: Train Loss = 0.5132, Valid Loss = 0.5249\n",
      "Iteration 26/135: Train Loss = 0.5080, Valid Loss = 0.5202\n",
      "Iteration 27/135: Train Loss = 0.5029, Valid Loss = 0.5154\n",
      "Iteration 28/135: Train Loss = 0.4980, Valid Loss = 0.5108\n",
      "Iteration 29/135: Train Loss = 0.4931, Valid Loss = 0.5062\n",
      "Iteration 30/135: Train Loss = 0.4883, Valid Loss = 0.5019\n",
      "Iteration 31/135: Train Loss = 0.4836, Valid Loss = 0.4975\n",
      "Iteration 32/135: Train Loss = 0.4791, Valid Loss = 0.4933\n",
      "Iteration 33/135: Train Loss = 0.4746, Valid Loss = 0.4893\n",
      "Iteration 34/135: Train Loss = 0.4702, Valid Loss = 0.4853\n",
      "Iteration 35/135: Train Loss = 0.4659, Valid Loss = 0.4813\n",
      "Iteration 36/135: Train Loss = 0.4618, Valid Loss = 0.4776\n",
      "Iteration 37/135: Train Loss = 0.4577, Valid Loss = 0.4739\n",
      "Iteration 38/135: Train Loss = 0.4537, Valid Loss = 0.4703\n",
      "Iteration 39/135: Train Loss = 0.4498, Valid Loss = 0.4670\n",
      "Iteration 40/135: Train Loss = 0.4460, Valid Loss = 0.4636\n",
      "Iteration 41/135: Train Loss = 0.4421, Valid Loss = 0.4602\n",
      "Iteration 42/135: Train Loss = 0.4384, Valid Loss = 0.4568\n",
      "Iteration 43/135: Train Loss = 0.4348, Valid Loss = 0.4536\n",
      "Iteration 44/135: Train Loss = 0.4313, Valid Loss = 0.4504\n",
      "Iteration 45/135: Train Loss = 0.4278, Valid Loss = 0.4474\n",
      "Iteration 46/135: Train Loss = 0.4244, Valid Loss = 0.4444\n",
      "Iteration 47/135: Train Loss = 0.4211, Valid Loss = 0.4413\n",
      "Iteration 48/135: Train Loss = 0.4178, Valid Loss = 0.4385\n",
      "Iteration 49/135: Train Loss = 0.4147, Valid Loss = 0.4356\n",
      "Iteration 50/135: Train Loss = 0.4116, Valid Loss = 0.4328\n",
      "Iteration 51/135: Train Loss = 0.4085, Valid Loss = 0.4301\n",
      "Iteration 52/135: Train Loss = 0.4055, Valid Loss = 0.4275\n",
      "Iteration 53/135: Train Loss = 0.4026, Valid Loss = 0.4248\n",
      "Iteration 54/135: Train Loss = 0.3997, Valid Loss = 0.4222\n",
      "Iteration 55/135: Train Loss = 0.3968, Valid Loss = 0.4196\n",
      "Iteration 56/135: Train Loss = 0.3941, Valid Loss = 0.4171\n",
      "Iteration 57/135: Train Loss = 0.3913, Valid Loss = 0.4146\n",
      "Iteration 58/135: Train Loss = 0.3886, Valid Loss = 0.4122\n",
      "Iteration 59/135: Train Loss = 0.3860, Valid Loss = 0.4100\n",
      "Iteration 60/135: Train Loss = 0.3834, Valid Loss = 0.4078\n",
      "Iteration 61/135: Train Loss = 0.3808, Valid Loss = 0.4056\n",
      "Iteration 62/135: Train Loss = 0.3783, Valid Loss = 0.4035\n",
      "Iteration 63/135: Train Loss = 0.3759, Valid Loss = 0.4013\n",
      "Iteration 64/135: Train Loss = 0.3735, Valid Loss = 0.3993\n",
      "Iteration 65/135: Train Loss = 0.3711, Valid Loss = 0.3972\n",
      "Iteration 66/135: Train Loss = 0.3688, Valid Loss = 0.3951\n",
      "Iteration 67/135: Train Loss = 0.3665, Valid Loss = 0.3932\n",
      "Iteration 68/135: Train Loss = 0.3643, Valid Loss = 0.3912\n",
      "Iteration 69/135: Train Loss = 0.3620, Valid Loss = 0.3893\n",
      "Iteration 70/135: Train Loss = 0.3599, Valid Loss = 0.3873\n",
      "Iteration 71/135: Train Loss = 0.3577, Valid Loss = 0.3855\n",
      "Iteration 72/135: Train Loss = 0.3556, Valid Loss = 0.3837\n",
      "Iteration 73/135: Train Loss = 0.3535, Valid Loss = 0.3820\n",
      "Iteration 74/135: Train Loss = 0.3515, Valid Loss = 0.3801\n",
      "Iteration 75/135: Train Loss = 0.3495, Valid Loss = 0.3784\n",
      "Iteration 76/135: Train Loss = 0.3475, Valid Loss = 0.3767\n",
      "Iteration 77/135: Train Loss = 0.3456, Valid Loss = 0.3751\n",
      "Iteration 78/135: Train Loss = 0.3437, Valid Loss = 0.3735\n",
      "Iteration 79/135: Train Loss = 0.3418, Valid Loss = 0.3719\n",
      "Iteration 80/135: Train Loss = 0.3399, Valid Loss = 0.3703\n",
      "Iteration 81/135: Train Loss = 0.3381, Valid Loss = 0.3688\n",
      "Iteration 82/135: Train Loss = 0.3364, Valid Loss = 0.3673\n",
      "Iteration 83/135: Train Loss = 0.3345, Valid Loss = 0.3658\n",
      "Iteration 84/135: Train Loss = 0.3328, Valid Loss = 0.3643\n",
      "Iteration 85/135: Train Loss = 0.3311, Valid Loss = 0.3628\n",
      "Iteration 86/135: Train Loss = 0.3294, Valid Loss = 0.3615\n",
      "Iteration 87/135: Train Loss = 0.3278, Valid Loss = 0.3601\n",
      "Iteration 88/135: Train Loss = 0.3262, Valid Loss = 0.3588\n",
      "Iteration 89/135: Train Loss = 0.3246, Valid Loss = 0.3575\n",
      "Iteration 90/135: Train Loss = 0.3230, Valid Loss = 0.3562\n",
      "Iteration 91/135: Train Loss = 0.3214, Valid Loss = 0.3549\n",
      "Iteration 92/135: Train Loss = 0.3198, Valid Loss = 0.3537\n",
      "Iteration 93/135: Train Loss = 0.3183, Valid Loss = 0.3524\n",
      "Iteration 94/135: Train Loss = 0.3167, Valid Loss = 0.3511\n",
      "Iteration 95/135: Train Loss = 0.3153, Valid Loss = 0.3499\n",
      "Iteration 96/135: Train Loss = 0.3138, Valid Loss = 0.3488\n",
      "Iteration 97/135: Train Loss = 0.3124, Valid Loss = 0.3476\n",
      "Iteration 98/135: Train Loss = 0.3109, Valid Loss = 0.3464\n",
      "Iteration 99/135: Train Loss = 0.3095, Valid Loss = 0.3452\n",
      "Iteration 100/135: Train Loss = 0.3081, Valid Loss = 0.3441\n",
      "Iteration 101/135: Train Loss = 0.3067, Valid Loss = 0.3431\n",
      "Iteration 102/135: Train Loss = 0.3053, Valid Loss = 0.3420\n",
      "Iteration 103/135: Train Loss = 0.3040, Valid Loss = 0.3410\n",
      "Iteration 104/135: Train Loss = 0.3026, Valid Loss = 0.3399\n",
      "Iteration 105/135: Train Loss = 0.3014, Valid Loss = 0.3387\n",
      "Iteration 106/135: Train Loss = 0.3001, Valid Loss = 0.3377\n",
      "Iteration 107/135: Train Loss = 0.2988, Valid Loss = 0.3367\n",
      "Iteration 108/135: Train Loss = 0.2976, Valid Loss = 0.3357\n",
      "Iteration 109/135: Train Loss = 0.2964, Valid Loss = 0.3348\n",
      "Iteration 110/135: Train Loss = 0.2952, Valid Loss = 0.3339\n",
      "Iteration 111/135: Train Loss = 0.2940, Valid Loss = 0.3329\n",
      "Iteration 112/135: Train Loss = 0.2928, Valid Loss = 0.3321\n",
      "Iteration 113/135: Train Loss = 0.2916, Valid Loss = 0.3312\n",
      "Iteration 114/135: Train Loss = 0.2905, Valid Loss = 0.3305\n",
      "Iteration 115/135: Train Loss = 0.2893, Valid Loss = 0.3296\n",
      "Iteration 116/135: Train Loss = 0.2882, Valid Loss = 0.3287\n",
      "Iteration 117/135: Train Loss = 0.2871, Valid Loss = 0.3278\n",
      "Iteration 118/135: Train Loss = 0.2860, Valid Loss = 0.3269\n",
      "Iteration 119/135: Train Loss = 0.2849, Valid Loss = 0.3260\n",
      "Iteration 120/135: Train Loss = 0.2838, Valid Loss = 0.3252\n",
      "Iteration 121/135: Train Loss = 0.2827, Valid Loss = 0.3243\n",
      "Iteration 122/135: Train Loss = 0.2817, Valid Loss = 0.3235\n",
      "Iteration 123/135: Train Loss = 0.2807, Valid Loss = 0.3227\n",
      "Iteration 124/135: Train Loss = 0.2796, Valid Loss = 0.3219\n",
      "Iteration 125/135: Train Loss = 0.2787, Valid Loss = 0.3211\n",
      "Iteration 126/135: Train Loss = 0.2777, Valid Loss = 0.3205\n",
      "Iteration 127/135: Train Loss = 0.2767, Valid Loss = 0.3198\n",
      "Iteration 128/135: Train Loss = 0.2758, Valid Loss = 0.3190\n",
      "Iteration 129/135: Train Loss = 0.2748, Valid Loss = 0.3183\n",
      "Iteration 130/135: Train Loss = 0.2738, Valid Loss = 0.3175\n",
      "Iteration 131/135: Train Loss = 0.2728, Valid Loss = 0.3168\n",
      "Iteration 132/135: Train Loss = 0.2719, Valid Loss = 0.3161\n",
      "Iteration 133/135: Train Loss = 0.2710, Valid Loss = 0.3154\n",
      "Iteration 134/135: Train Loss = 0.2701, Valid Loss = 0.3147\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-05 00:49:14,916] Trial 9 finished with value: 0.9624156877099466 and parameters: {'max_depth': 14, 'min_samples_leaf': 10, 'n_estimators': 135, 'learning_rate': 0.05174124324522668, 'subsample': 0.8661324243377773}. Best is trial 6 with value: 0.965235693124235.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 135/135: Train Loss = 0.2692, Valid Loss = 0.3140\n",
      "Iteration 1/150: Train Loss = 0.5633, Valid Loss = 0.5678\n",
      "Iteration 2/150: Train Loss = 0.4780, Valid Loss = 0.4858\n",
      "Iteration 3/150: Train Loss = 0.4206, Valid Loss = 0.4323\n",
      "Iteration 4/150: Train Loss = 0.3804, Valid Loss = 0.3953\n",
      "Iteration 5/150: Train Loss = 0.3505, Valid Loss = 0.3683\n",
      "Iteration 6/150: Train Loss = 0.3280, Valid Loss = 0.3488\n",
      "Iteration 7/150: Train Loss = 0.3102, Valid Loss = 0.3335\n",
      "Iteration 8/150: Train Loss = 0.2956, Valid Loss = 0.3210\n",
      "Iteration 9/150: Train Loss = 0.2834, Valid Loss = 0.3103\n",
      "Iteration 10/150: Train Loss = 0.2731, Valid Loss = 0.3013\n",
      "Iteration 11/150: Train Loss = 0.2645, Valid Loss = 0.2941\n",
      "Iteration 12/150: Train Loss = 0.2575, Valid Loss = 0.2894\n",
      "Iteration 13/150: Train Loss = 0.2510, Valid Loss = 0.2843\n",
      "Iteration 14/150: Train Loss = 0.2453, Valid Loss = 0.2795\n",
      "Iteration 15/150: Train Loss = 0.2399, Valid Loss = 0.2755\n",
      "Iteration 16/150: Train Loss = 0.2352, Valid Loss = 0.2719\n",
      "Iteration 17/150: Train Loss = 0.2307, Valid Loss = 0.2694\n",
      "Iteration 18/150: Train Loss = 0.2269, Valid Loss = 0.2670\n",
      "Iteration 19/150: Train Loss = 0.2233, Valid Loss = 0.2645\n",
      "Iteration 20/150: Train Loss = 0.2201, Valid Loss = 0.2630\n",
      "Iteration 21/150: Train Loss = 0.2171, Valid Loss = 0.2607\n",
      "Iteration 22/150: Train Loss = 0.2145, Valid Loss = 0.2591\n",
      "Iteration 23/150: Train Loss = 0.2116, Valid Loss = 0.2575\n",
      "Iteration 24/150: Train Loss = 0.2095, Valid Loss = 0.2563\n",
      "Iteration 25/150: Train Loss = 0.2074, Valid Loss = 0.2547\n",
      "Iteration 26/150: Train Loss = 0.2053, Valid Loss = 0.2538\n",
      "Iteration 27/150: Train Loss = 0.2033, Valid Loss = 0.2528\n",
      "Iteration 28/150: Train Loss = 0.2010, Valid Loss = 0.2521\n",
      "Iteration 29/150: Train Loss = 0.1995, Valid Loss = 0.2516\n",
      "Iteration 30/150: Train Loss = 0.1977, Valid Loss = 0.2505\n",
      "Iteration 31/150: Train Loss = 0.1964, Valid Loss = 0.2497\n",
      "Iteration 32/150: Train Loss = 0.1949, Valid Loss = 0.2493\n",
      "Iteration 33/150: Train Loss = 0.1933, Valid Loss = 0.2483\n",
      "Iteration 34/150: Train Loss = 0.1917, Valid Loss = 0.2473\n",
      "Iteration 35/150: Train Loss = 0.1904, Valid Loss = 0.2472\n",
      "Iteration 36/150: Train Loss = 0.1892, Valid Loss = 0.2471\n",
      "Iteration 37/150: Train Loss = 0.1879, Valid Loss = 0.2473\n",
      "Iteration 38/150: Train Loss = 0.1868, Valid Loss = 0.2470\n",
      "Iteration 39/150: Train Loss = 0.1855, Valid Loss = 0.2468\n",
      "Iteration 40/150: Train Loss = 0.1844, Valid Loss = 0.2461\n",
      "Iteration 41/150: Train Loss = 0.1833, Valid Loss = 0.2456\n",
      "Iteration 42/150: Train Loss = 0.1822, Valid Loss = 0.2451\n",
      "Iteration 43/150: Train Loss = 0.1813, Valid Loss = 0.2450\n",
      "Iteration 44/150: Train Loss = 0.1806, Valid Loss = 0.2448\n",
      "Iteration 45/150: Train Loss = 0.1797, Valid Loss = 0.2446\n",
      "Iteration 46/150: Train Loss = 0.1790, Valid Loss = 0.2447\n",
      "Iteration 47/150: Train Loss = 0.1781, Valid Loss = 0.2447\n",
      "Iteration 48/150: Train Loss = 0.1773, Valid Loss = 0.2446\n",
      "Iteration 49/150: Train Loss = 0.1764, Valid Loss = 0.2443\n",
      "Iteration 50/150: Train Loss = 0.1758, Valid Loss = 0.2440\n",
      "Iteration 51/150: Train Loss = 0.1748, Valid Loss = 0.2437\n",
      "Iteration 52/150: Train Loss = 0.1739, Valid Loss = 0.2432\n",
      "Iteration 53/150: Train Loss = 0.1732, Valid Loss = 0.2426\n",
      "Iteration 54/150: Train Loss = 0.1726, Valid Loss = 0.2429\n",
      "Iteration 55/150: Train Loss = 0.1718, Valid Loss = 0.2430\n",
      "Iteration 56/150: Train Loss = 0.1712, Valid Loss = 0.2423\n",
      "Iteration 57/150: Train Loss = 0.1708, Valid Loss = 0.2419\n",
      "Iteration 58/150: Train Loss = 0.1701, Valid Loss = 0.2422\n",
      "Iteration 59/150: Train Loss = 0.1695, Valid Loss = 0.2421\n",
      "Iteration 60/150: Train Loss = 0.1687, Valid Loss = 0.2418\n",
      "Iteration 61/150: Train Loss = 0.1683, Valid Loss = 0.2412\n",
      "Iteration 62/150: Train Loss = 0.1677, Valid Loss = 0.2411\n",
      "Iteration 63/150: Train Loss = 0.1669, Valid Loss = 0.2412\n",
      "Iteration 64/150: Train Loss = 0.1662, Valid Loss = 0.2413\n",
      "Iteration 65/150: Train Loss = 0.1656, Valid Loss = 0.2413\n",
      "Iteration 66/150: Train Loss = 0.1651, Valid Loss = 0.2412\n",
      "Iteration 67/150: Train Loss = 0.1646, Valid Loss = 0.2413\n",
      "Iteration 68/150: Train Loss = 0.1640, Valid Loss = 0.2411\n",
      "Iteration 69/150: Train Loss = 0.1634, Valid Loss = 0.2414\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-05 00:49:20,869] Trial 10 finished with value: 0.964195158406064 and parameters: {'max_depth': 10, 'min_samples_leaf': 20, 'n_estimators': 150, 'learning_rate': 0.8208343171870824, 'subsample': 0.9668398938364334}. Best is trial 6 with value: 0.965235693124235.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 70/150: Train Loss = 0.1629, Valid Loss = 0.2411\n",
      "Iteration 71/150: Train Loss = 0.1622, Valid Loss = 0.2417\n",
      "Early stopping triggered.\n",
      "Iteration 1/150: Train Loss = 0.5504, Valid Loss = 0.5565\n",
      "Iteration 2/150: Train Loss = 0.4612, Valid Loss = 0.4719\n",
      "Iteration 3/150: Train Loss = 0.4033, Valid Loss = 0.4176\n",
      "Iteration 4/150: Train Loss = 0.3638, Valid Loss = 0.3815\n",
      "Iteration 5/150: Train Loss = 0.3357, Valid Loss = 0.3553\n",
      "Iteration 6/150: Train Loss = 0.3142, Valid Loss = 0.3369\n",
      "Iteration 7/150: Train Loss = 0.2977, Valid Loss = 0.3228\n",
      "Iteration 8/150: Train Loss = 0.2841, Valid Loss = 0.3117\n",
      "Iteration 9/150: Train Loss = 0.2719, Valid Loss = 0.3027\n",
      "Iteration 10/150: Train Loss = 0.2626, Valid Loss = 0.2948\n",
      "Iteration 11/150: Train Loss = 0.2547, Valid Loss = 0.2891\n",
      "Iteration 12/150: Train Loss = 0.2479, Valid Loss = 0.2843\n",
      "Iteration 13/150: Train Loss = 0.2419, Valid Loss = 0.2801\n",
      "Iteration 14/150: Train Loss = 0.2369, Valid Loss = 0.2759\n",
      "Iteration 15/150: Train Loss = 0.2319, Valid Loss = 0.2728\n",
      "Iteration 16/150: Train Loss = 0.2282, Valid Loss = 0.2696\n",
      "Iteration 17/150: Train Loss = 0.2246, Valid Loss = 0.2668\n",
      "Iteration 18/150: Train Loss = 0.2206, Valid Loss = 0.2647\n",
      "Iteration 19/150: Train Loss = 0.2173, Valid Loss = 0.2629\n",
      "Iteration 20/150: Train Loss = 0.2139, Valid Loss = 0.2608\n",
      "Iteration 21/150: Train Loss = 0.2110, Valid Loss = 0.2596\n",
      "Iteration 22/150: Train Loss = 0.2083, Valid Loss = 0.2586\n",
      "Iteration 23/150: Train Loss = 0.2059, Valid Loss = 0.2571\n",
      "Iteration 24/150: Train Loss = 0.2036, Valid Loss = 0.2559\n",
      "Iteration 25/150: Train Loss = 0.2018, Valid Loss = 0.2556\n",
      "Iteration 26/150: Train Loss = 0.2003, Valid Loss = 0.2547\n",
      "Iteration 27/150: Train Loss = 0.1986, Valid Loss = 0.2547\n",
      "Iteration 28/150: Train Loss = 0.1970, Valid Loss = 0.2546\n",
      "Iteration 29/150: Train Loss = 0.1956, Valid Loss = 0.2539\n",
      "Iteration 30/150: Train Loss = 0.1940, Valid Loss = 0.2535\n",
      "Iteration 31/150: Train Loss = 0.1927, Valid Loss = 0.2530\n",
      "Iteration 32/150: Train Loss = 0.1908, Valid Loss = 0.2529\n",
      "Iteration 33/150: Train Loss = 0.1896, Valid Loss = 0.2527\n",
      "Iteration 34/150: Train Loss = 0.1884, Valid Loss = 0.2523\n",
      "Iteration 35/150: Train Loss = 0.1872, Valid Loss = 0.2516\n",
      "Iteration 36/150: Train Loss = 0.1857, Valid Loss = 0.2514\n",
      "Iteration 37/150: Train Loss = 0.1845, Valid Loss = 0.2511\n",
      "Iteration 38/150: Train Loss = 0.1833, Valid Loss = 0.2507\n",
      "Iteration 39/150: Train Loss = 0.1820, Valid Loss = 0.2511\n",
      "Iteration 40/150: Train Loss = 0.1808, Valid Loss = 0.2513\n",
      "Iteration 41/150: Train Loss = 0.1801, Valid Loss = 0.2508\n",
      "Iteration 42/150: Train Loss = 0.1792, Valid Loss = 0.2503\n",
      "Iteration 43/150: Train Loss = 0.1783, Valid Loss = 0.2501\n",
      "Iteration 44/150: Train Loss = 0.1774, Valid Loss = 0.2492\n",
      "Iteration 45/150: Train Loss = 0.1763, Valid Loss = 0.2497\n",
      "Iteration 46/150: Train Loss = 0.1752, Valid Loss = 0.2489\n",
      "Iteration 47/150: Train Loss = 0.1746, Valid Loss = 0.2490\n",
      "Iteration 48/150: Train Loss = 0.1739, Valid Loss = 0.2487\n",
      "Iteration 49/150: Train Loss = 0.1730, Valid Loss = 0.2484\n",
      "Iteration 50/150: Train Loss = 0.1718, Valid Loss = 0.2483\n",
      "Iteration 51/150: Train Loss = 0.1711, Valid Loss = 0.2487\n",
      "Iteration 52/150: Train Loss = 0.1707, Valid Loss = 0.2487\n",
      "Iteration 53/150: Train Loss = 0.1699, Valid Loss = 0.2484\n",
      "Iteration 54/150: Train Loss = 0.1691, Valid Loss = 0.2480\n",
      "Iteration 55/150: Train Loss = 0.1685, Valid Loss = 0.2477\n",
      "Iteration 56/150: Train Loss = 0.1675, Valid Loss = 0.2471\n",
      "Iteration 57/150: Train Loss = 0.1668, Valid Loss = 0.2469\n",
      "Iteration 58/150: Train Loss = 0.1659, Valid Loss = 0.2463\n",
      "Iteration 59/150: Train Loss = 0.1652, Valid Loss = 0.2464\n",
      "Iteration 60/150: Train Loss = 0.1646, Valid Loss = 0.2467\n",
      "Iteration 61/150: Train Loss = 0.1643, Valid Loss = 0.2470\n",
      "Iteration 62/150: Train Loss = 0.1635, Valid Loss = 0.2469\n",
      "Iteration 63/150: Train Loss = 0.1628, Valid Loss = 0.2473\n",
      "Iteration 64/150: Train Loss = 0.1623, Valid Loss = 0.2474\n",
      "Iteration 65/150: Train Loss = 0.1617, Valid Loss = 0.2473\n",
      "Iteration 66/150: Train Loss = 0.1611, Valid Loss = 0.2470\n",
      "Iteration 67/150: Train Loss = 0.1606, Valid Loss = 0.2471\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-05 00:49:26,647] Trial 11 finished with value: 0.962629208941964 and parameters: {'max_depth': 10, 'min_samples_leaf': 20, 'n_estimators': 150, 'learning_rate': 0.9231962103991376, 'subsample': 0.9793108424646119}. Best is trial 6 with value: 0.965235693124235.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 68/150: Train Loss = 0.1601, Valid Loss = 0.2474\n",
      "Early stopping triggered.\n",
      "Iteration 1/115: Train Loss = 0.5416, Valid Loss = 0.5466\n",
      "Iteration 2/115: Train Loss = 0.4509, Valid Loss = 0.4609\n",
      "Iteration 3/115: Train Loss = 0.3945, Valid Loss = 0.4074\n",
      "Iteration 4/115: Train Loss = 0.3561, Valid Loss = 0.3714\n",
      "Iteration 5/115: Train Loss = 0.3280, Valid Loss = 0.3464\n",
      "Iteration 6/115: Train Loss = 0.3085, Valid Loss = 0.3281\n",
      "Iteration 7/115: Train Loss = 0.2919, Valid Loss = 0.3146\n",
      "Iteration 8/115: Train Loss = 0.2802, Valid Loss = 0.3058\n",
      "Iteration 9/115: Train Loss = 0.2692, Valid Loss = 0.2979\n",
      "Iteration 10/115: Train Loss = 0.2604, Valid Loss = 0.2899\n",
      "Iteration 11/115: Train Loss = 0.2529, Valid Loss = 0.2836\n",
      "Iteration 12/115: Train Loss = 0.2465, Valid Loss = 0.2799\n",
      "Iteration 13/115: Train Loss = 0.2409, Valid Loss = 0.2758\n",
      "Iteration 14/115: Train Loss = 0.2356, Valid Loss = 0.2722\n",
      "Iteration 15/115: Train Loss = 0.2312, Valid Loss = 0.2700\n",
      "Iteration 16/115: Train Loss = 0.2274, Valid Loss = 0.2682\n",
      "Iteration 17/115: Train Loss = 0.2242, Valid Loss = 0.2657\n",
      "Iteration 18/115: Train Loss = 0.2210, Valid Loss = 0.2646\n",
      "Iteration 19/115: Train Loss = 0.2178, Valid Loss = 0.2627\n",
      "Iteration 20/115: Train Loss = 0.2148, Valid Loss = 0.2609\n",
      "Iteration 21/115: Train Loss = 0.2123, Valid Loss = 0.2601\n",
      "Iteration 22/115: Train Loss = 0.2095, Valid Loss = 0.2588\n",
      "Iteration 23/115: Train Loss = 0.2072, Valid Loss = 0.2575\n",
      "Iteration 24/115: Train Loss = 0.2049, Valid Loss = 0.2564\n",
      "Iteration 25/115: Train Loss = 0.2031, Valid Loss = 0.2557\n",
      "Iteration 26/115: Train Loss = 0.2016, Valid Loss = 0.2545\n",
      "Iteration 27/115: Train Loss = 0.1998, Valid Loss = 0.2534\n",
      "Iteration 28/115: Train Loss = 0.1983, Valid Loss = 0.2528\n",
      "Iteration 29/115: Train Loss = 0.1971, Valid Loss = 0.2526\n",
      "Iteration 30/115: Train Loss = 0.1956, Valid Loss = 0.2517\n",
      "Iteration 31/115: Train Loss = 0.1945, Valid Loss = 0.2508\n",
      "Iteration 32/115: Train Loss = 0.1933, Valid Loss = 0.2495\n",
      "Iteration 33/115: Train Loss = 0.1922, Valid Loss = 0.2496\n",
      "Iteration 34/115: Train Loss = 0.1911, Valid Loss = 0.2495\n",
      "Iteration 35/115: Train Loss = 0.1900, Valid Loss = 0.2491\n",
      "Iteration 36/115: Train Loss = 0.1887, Valid Loss = 0.2489\n",
      "Iteration 37/115: Train Loss = 0.1876, Valid Loss = 0.2483\n",
      "Iteration 38/115: Train Loss = 0.1867, Valid Loss = 0.2488\n",
      "Iteration 39/115: Train Loss = 0.1860, Valid Loss = 0.2483\n",
      "Iteration 40/115: Train Loss = 0.1852, Valid Loss = 0.2477\n",
      "Iteration 41/115: Train Loss = 0.1843, Valid Loss = 0.2478\n",
      "Iteration 42/115: Train Loss = 0.1834, Valid Loss = 0.2475\n",
      "Iteration 43/115: Train Loss = 0.1825, Valid Loss = 0.2476\n",
      "Iteration 44/115: Train Loss = 0.1816, Valid Loss = 0.2471\n",
      "Iteration 45/115: Train Loss = 0.1805, Valid Loss = 0.2471\n",
      "Iteration 46/115: Train Loss = 0.1796, Valid Loss = 0.2470\n",
      "Iteration 47/115: Train Loss = 0.1791, Valid Loss = 0.2471\n",
      "Iteration 48/115: Train Loss = 0.1782, Valid Loss = 0.2466\n",
      "Iteration 49/115: Train Loss = 0.1774, Valid Loss = 0.2465\n",
      "Iteration 50/115: Train Loss = 0.1766, Valid Loss = 0.2462\n",
      "Iteration 51/115: Train Loss = 0.1760, Valid Loss = 0.2463\n",
      "Iteration 52/115: Train Loss = 0.1748, Valid Loss = 0.2466\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-05 00:49:31,044] Trial 12 finished with value: 0.962553332647015 and parameters: {'max_depth': 9, 'min_samples_leaf': 20, 'n_estimators': 115, 'learning_rate': 0.9941715670538087, 'subsample': 0.9929793647270659}. Best is trial 6 with value: 0.965235693124235.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 53/115: Train Loss = 0.1743, Valid Loss = 0.2464\n",
      "Iteration 54/115: Train Loss = 0.1736, Valid Loss = 0.2472\n",
      "Early stopping triggered.\n",
      "Iteration 1/120: Train Loss = 0.6174, Valid Loss = 0.6197\n",
      "Iteration 2/120: Train Loss = 0.5567, Valid Loss = 0.5617\n",
      "Iteration 3/120: Train Loss = 0.5079, Valid Loss = 0.5145\n",
      "Iteration 4/120: Train Loss = 0.4693, Valid Loss = 0.4771\n",
      "Iteration 5/120: Train Loss = 0.4386, Valid Loss = 0.4482\n",
      "Iteration 6/120: Train Loss = 0.4129, Valid Loss = 0.4242\n",
      "Iteration 7/120: Train Loss = 0.3916, Valid Loss = 0.4046\n",
      "Iteration 8/120: Train Loss = 0.3740, Valid Loss = 0.3881\n",
      "Iteration 9/120: Train Loss = 0.3586, Valid Loss = 0.3736\n",
      "Iteration 10/120: Train Loss = 0.3450, Valid Loss = 0.3612\n",
      "Iteration 11/120: Train Loss = 0.3337, Valid Loss = 0.3504\n",
      "Iteration 12/120: Train Loss = 0.3235, Valid Loss = 0.3413\n",
      "Iteration 13/120: Train Loss = 0.3146, Valid Loss = 0.3331\n",
      "Iteration 14/120: Train Loss = 0.3064, Valid Loss = 0.3253\n",
      "Iteration 15/120: Train Loss = 0.2993, Valid Loss = 0.3190\n",
      "Iteration 16/120: Train Loss = 0.2930, Valid Loss = 0.3130\n",
      "Iteration 17/120: Train Loss = 0.2874, Valid Loss = 0.3084\n",
      "Iteration 18/120: Train Loss = 0.2821, Valid Loss = 0.3037\n",
      "Iteration 19/120: Train Loss = 0.2768, Valid Loss = 0.2999\n",
      "Iteration 20/120: Train Loss = 0.2724, Valid Loss = 0.2964\n",
      "Iteration 21/120: Train Loss = 0.2685, Valid Loss = 0.2934\n",
      "Iteration 22/120: Train Loss = 0.2646, Valid Loss = 0.2904\n",
      "Iteration 23/120: Train Loss = 0.2612, Valid Loss = 0.2876\n",
      "Iteration 24/120: Train Loss = 0.2580, Valid Loss = 0.2845\n",
      "Iteration 25/120: Train Loss = 0.2547, Valid Loss = 0.2820\n",
      "Iteration 26/120: Train Loss = 0.2519, Valid Loss = 0.2796\n",
      "Iteration 27/120: Train Loss = 0.2495, Valid Loss = 0.2773\n",
      "Iteration 28/120: Train Loss = 0.2469, Valid Loss = 0.2752\n",
      "Iteration 29/120: Train Loss = 0.2446, Valid Loss = 0.2733\n",
      "Iteration 30/120: Train Loss = 0.2422, Valid Loss = 0.2719\n",
      "Iteration 31/120: Train Loss = 0.2400, Valid Loss = 0.2705\n",
      "Iteration 32/120: Train Loss = 0.2379, Valid Loss = 0.2690\n",
      "Iteration 33/120: Train Loss = 0.2359, Valid Loss = 0.2677\n",
      "Iteration 34/120: Train Loss = 0.2342, Valid Loss = 0.2663\n",
      "Iteration 35/120: Train Loss = 0.2325, Valid Loss = 0.2650\n",
      "Iteration 36/120: Train Loss = 0.2307, Valid Loss = 0.2636\n",
      "Iteration 37/120: Train Loss = 0.2291, Valid Loss = 0.2629\n",
      "Iteration 38/120: Train Loss = 0.2277, Valid Loss = 0.2620\n",
      "Iteration 39/120: Train Loss = 0.2264, Valid Loss = 0.2612\n",
      "Iteration 40/120: Train Loss = 0.2251, Valid Loss = 0.2601\n",
      "Iteration 41/120: Train Loss = 0.2240, Valid Loss = 0.2588\n",
      "Iteration 42/120: Train Loss = 0.2226, Valid Loss = 0.2583\n",
      "Iteration 43/120: Train Loss = 0.2215, Valid Loss = 0.2576\n",
      "Iteration 44/120: Train Loss = 0.2203, Valid Loss = 0.2565\n",
      "Iteration 45/120: Train Loss = 0.2191, Valid Loss = 0.2560\n",
      "Iteration 46/120: Train Loss = 0.2179, Valid Loss = 0.2554\n",
      "Iteration 47/120: Train Loss = 0.2168, Valid Loss = 0.2546\n",
      "Iteration 48/120: Train Loss = 0.2158, Valid Loss = 0.2540\n",
      "Iteration 49/120: Train Loss = 0.2149, Valid Loss = 0.2532\n",
      "Iteration 50/120: Train Loss = 0.2140, Valid Loss = 0.2528\n",
      "Iteration 51/120: Train Loss = 0.2131, Valid Loss = 0.2522\n",
      "Iteration 52/120: Train Loss = 0.2121, Valid Loss = 0.2513\n",
      "Iteration 53/120: Train Loss = 0.2113, Valid Loss = 0.2508\n",
      "Iteration 54/120: Train Loss = 0.2103, Valid Loss = 0.2504\n",
      "Iteration 55/120: Train Loss = 0.2095, Valid Loss = 0.2502\n",
      "Iteration 56/120: Train Loss = 0.2087, Valid Loss = 0.2499\n",
      "Iteration 57/120: Train Loss = 0.2080, Valid Loss = 0.2494\n",
      "Iteration 58/120: Train Loss = 0.2073, Valid Loss = 0.2486\n",
      "Iteration 59/120: Train Loss = 0.2064, Valid Loss = 0.2481\n",
      "Iteration 60/120: Train Loss = 0.2056, Valid Loss = 0.2478\n",
      "Iteration 61/120: Train Loss = 0.2050, Valid Loss = 0.2476\n",
      "Iteration 62/120: Train Loss = 0.2044, Valid Loss = 0.2472\n",
      "Iteration 63/120: Train Loss = 0.2038, Valid Loss = 0.2468\n",
      "Iteration 64/120: Train Loss = 0.2032, Valid Loss = 0.2465\n",
      "Iteration 65/120: Train Loss = 0.2023, Valid Loss = 0.2463\n",
      "Iteration 66/120: Train Loss = 0.2018, Valid Loss = 0.2458\n",
      "Iteration 67/120: Train Loss = 0.2011, Valid Loss = 0.2452\n",
      "Iteration 68/120: Train Loss = 0.2006, Valid Loss = 0.2450\n",
      "Iteration 69/120: Train Loss = 0.2002, Valid Loss = 0.2449\n",
      "Iteration 70/120: Train Loss = 0.1996, Valid Loss = 0.2445\n",
      "Iteration 71/120: Train Loss = 0.1990, Valid Loss = 0.2440\n",
      "Iteration 72/120: Train Loss = 0.1985, Valid Loss = 0.2437\n",
      "Iteration 73/120: Train Loss = 0.1981, Valid Loss = 0.2437\n",
      "Iteration 74/120: Train Loss = 0.1974, Valid Loss = 0.2435\n",
      "Iteration 75/120: Train Loss = 0.1969, Valid Loss = 0.2432\n",
      "Iteration 76/120: Train Loss = 0.1964, Valid Loss = 0.2429\n",
      "Iteration 77/120: Train Loss = 0.1961, Valid Loss = 0.2428\n",
      "Iteration 78/120: Train Loss = 0.1956, Valid Loss = 0.2426\n",
      "Iteration 79/120: Train Loss = 0.1952, Valid Loss = 0.2428\n",
      "Iteration 80/120: Train Loss = 0.1947, Valid Loss = 0.2430\n",
      "Iteration 81/120: Train Loss = 0.1943, Valid Loss = 0.2428\n",
      "Iteration 82/120: Train Loss = 0.1937, Valid Loss = 0.2430\n",
      "Iteration 83/120: Train Loss = 0.1931, Valid Loss = 0.2431\n",
      "Iteration 84/120: Train Loss = 0.1927, Valid Loss = 0.2430\n",
      "Iteration 85/120: Train Loss = 0.1923, Valid Loss = 0.2427\n",
      "Iteration 86/120: Train Loss = 0.1919, Valid Loss = 0.2428\n",
      "Iteration 87/120: Train Loss = 0.1915, Valid Loss = 0.2428\n",
      "Iteration 88/120: Train Loss = 0.1911, Valid Loss = 0.2427\n",
      "Iteration 89/120: Train Loss = 0.1908, Valid Loss = 0.2425\n",
      "Iteration 90/120: Train Loss = 0.1904, Valid Loss = 0.2424\n",
      "Iteration 91/120: Train Loss = 0.1899, Valid Loss = 0.2423\n",
      "Iteration 92/120: Train Loss = 0.1895, Valid Loss = 0.2420\n",
      "Iteration 93/120: Train Loss = 0.1893, Valid Loss = 0.2417\n",
      "Iteration 94/120: Train Loss = 0.1889, Valid Loss = 0.2416\n",
      "Iteration 95/120: Train Loss = 0.1886, Valid Loss = 0.2414\n",
      "Iteration 96/120: Train Loss = 0.1884, Valid Loss = 0.2413\n",
      "Iteration 97/120: Train Loss = 0.1881, Valid Loss = 0.2412\n",
      "Iteration 98/120: Train Loss = 0.1878, Valid Loss = 0.2413\n",
      "Iteration 99/120: Train Loss = 0.1874, Valid Loss = 0.2413\n",
      "Iteration 100/120: Train Loss = 0.1871, Valid Loss = 0.2411\n",
      "Iteration 101/120: Train Loss = 0.1867, Valid Loss = 0.2411\n",
      "Iteration 102/120: Train Loss = 0.1862, Valid Loss = 0.2409\n",
      "Iteration 103/120: Train Loss = 0.1858, Valid Loss = 0.2411\n",
      "Iteration 104/120: Train Loss = 0.1854, Valid Loss = 0.2412\n",
      "Iteration 105/120: Train Loss = 0.1851, Valid Loss = 0.2412\n",
      "Iteration 106/120: Train Loss = 0.1846, Valid Loss = 0.2411\n",
      "Iteration 107/120: Train Loss = 0.1843, Valid Loss = 0.2409\n",
      "Iteration 108/120: Train Loss = 0.1839, Valid Loss = 0.2411\n",
      "Iteration 109/120: Train Loss = 0.1837, Valid Loss = 0.2407\n",
      "Iteration 110/120: Train Loss = 0.1835, Valid Loss = 0.2406\n",
      "Iteration 111/120: Train Loss = 0.1832, Valid Loss = 0.2408\n",
      "Iteration 112/120: Train Loss = 0.1829, Valid Loss = 0.2404\n",
      "Iteration 113/120: Train Loss = 0.1826, Valid Loss = 0.2404\n",
      "Iteration 114/120: Train Loss = 0.1822, Valid Loss = 0.2404\n",
      "Iteration 115/120: Train Loss = 0.1819, Valid Loss = 0.2403\n",
      "Iteration 116/120: Train Loss = 0.1817, Valid Loss = 0.2404\n",
      "Iteration 117/120: Train Loss = 0.1814, Valid Loss = 0.2402\n",
      "Iteration 118/120: Train Loss = 0.1811, Valid Loss = 0.2401\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-05 00:49:37,888] Trial 13 finished with value: 0.9651003359146524 and parameters: {'max_depth': 8, 'min_samples_leaf': 16, 'n_estimators': 120, 'learning_rate': 0.4730918224161353, 'subsample': 0.7348167539791466}. Best is trial 6 with value: 0.965235693124235.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 119/120: Train Loss = 0.1809, Valid Loss = 0.2404\n",
      "Iteration 120/120: Train Loss = 0.1805, Valid Loss = 0.2407\n",
      "Iteration 1/115: Train Loss = 0.6800, Valid Loss = 0.6804\n",
      "Iteration 2/115: Train Loss = 0.6675, Valid Loss = 0.6683\n",
      "Iteration 3/115: Train Loss = 0.6557, Valid Loss = 0.6570\n",
      "Iteration 4/115: Train Loss = 0.6445, Valid Loss = 0.6461\n",
      "Iteration 5/115: Train Loss = 0.6340, Valid Loss = 0.6361\n",
      "Iteration 6/115: Train Loss = 0.6241, Valid Loss = 0.6265\n",
      "Iteration 7/115: Train Loss = 0.6146, Valid Loss = 0.6175\n",
      "Iteration 8/115: Train Loss = 0.6059, Valid Loss = 0.6092\n",
      "Iteration 9/115: Train Loss = 0.5974, Valid Loss = 0.6010\n",
      "Iteration 10/115: Train Loss = 0.5895, Valid Loss = 0.5934\n",
      "Iteration 11/115: Train Loss = 0.5821, Valid Loss = 0.5864\n",
      "Iteration 12/115: Train Loss = 0.5749, Valid Loss = 0.5795\n",
      "Iteration 13/115: Train Loss = 0.5681, Valid Loss = 0.5730\n",
      "Iteration 14/115: Train Loss = 0.5617, Valid Loss = 0.5668\n",
      "Iteration 15/115: Train Loss = 0.5555, Valid Loss = 0.5608\n",
      "Iteration 16/115: Train Loss = 0.5498, Valid Loss = 0.5553\n",
      "Iteration 17/115: Train Loss = 0.5444, Valid Loss = 0.5501\n",
      "Iteration 18/115: Train Loss = 0.5391, Valid Loss = 0.5452\n",
      "Iteration 19/115: Train Loss = 0.5342, Valid Loss = 0.5404\n",
      "Iteration 20/115: Train Loss = 0.5295, Valid Loss = 0.5357\n",
      "Iteration 21/115: Train Loss = 0.5249, Valid Loss = 0.5313\n",
      "Iteration 22/115: Train Loss = 0.5205, Valid Loss = 0.5271\n",
      "Iteration 23/115: Train Loss = 0.5163, Valid Loss = 0.5233\n",
      "Iteration 24/115: Train Loss = 0.5124, Valid Loss = 0.5194\n",
      "Iteration 25/115: Train Loss = 0.5087, Valid Loss = 0.5157\n",
      "Iteration 26/115: Train Loss = 0.5051, Valid Loss = 0.5122\n",
      "Iteration 27/115: Train Loss = 0.5017, Valid Loss = 0.5088\n",
      "Iteration 28/115: Train Loss = 0.4983, Valid Loss = 0.5057\n",
      "Iteration 29/115: Train Loss = 0.4951, Valid Loss = 0.5026\n",
      "Iteration 30/115: Train Loss = 0.4920, Valid Loss = 0.4997\n",
      "Iteration 31/115: Train Loss = 0.4890, Valid Loss = 0.4971\n",
      "Iteration 32/115: Train Loss = 0.4861, Valid Loss = 0.4941\n",
      "Iteration 33/115: Train Loss = 0.4833, Valid Loss = 0.4916\n",
      "Iteration 34/115: Train Loss = 0.4806, Valid Loss = 0.4889\n",
      "Iteration 35/115: Train Loss = 0.4779, Valid Loss = 0.4863\n",
      "Iteration 36/115: Train Loss = 0.4754, Valid Loss = 0.4839\n",
      "Iteration 37/115: Train Loss = 0.4728, Valid Loss = 0.4814\n",
      "Iteration 38/115: Train Loss = 0.4703, Valid Loss = 0.4790\n",
      "Iteration 39/115: Train Loss = 0.4679, Valid Loss = 0.4768\n",
      "Iteration 40/115: Train Loss = 0.4656, Valid Loss = 0.4744\n",
      "Iteration 41/115: Train Loss = 0.4633, Valid Loss = 0.4723\n",
      "Iteration 42/115: Train Loss = 0.4611, Valid Loss = 0.4703\n",
      "Iteration 43/115: Train Loss = 0.4590, Valid Loss = 0.4681\n",
      "Iteration 44/115: Train Loss = 0.4569, Valid Loss = 0.4660\n",
      "Iteration 45/115: Train Loss = 0.4548, Valid Loss = 0.4641\n",
      "Iteration 46/115: Train Loss = 0.4528, Valid Loss = 0.4621\n",
      "Iteration 47/115: Train Loss = 0.4509, Valid Loss = 0.4602\n",
      "Iteration 48/115: Train Loss = 0.4489, Valid Loss = 0.4585\n",
      "Iteration 49/115: Train Loss = 0.4470, Valid Loss = 0.4568\n",
      "Iteration 50/115: Train Loss = 0.4452, Valid Loss = 0.4551\n",
      "Iteration 51/115: Train Loss = 0.4435, Valid Loss = 0.4533\n",
      "Iteration 52/115: Train Loss = 0.4417, Valid Loss = 0.4518\n",
      "Iteration 53/115: Train Loss = 0.4400, Valid Loss = 0.4499\n",
      "Iteration 54/115: Train Loss = 0.4383, Valid Loss = 0.4484\n",
      "Iteration 55/115: Train Loss = 0.4367, Valid Loss = 0.4470\n",
      "Iteration 56/115: Train Loss = 0.4351, Valid Loss = 0.4454\n",
      "Iteration 57/115: Train Loss = 0.4335, Valid Loss = 0.4438\n",
      "Iteration 58/115: Train Loss = 0.4320, Valid Loss = 0.4425\n",
      "Iteration 59/115: Train Loss = 0.4305, Valid Loss = 0.4409\n",
      "Iteration 60/115: Train Loss = 0.4290, Valid Loss = 0.4393\n",
      "Iteration 61/115: Train Loss = 0.4276, Valid Loss = 0.4380\n",
      "Iteration 62/115: Train Loss = 0.4262, Valid Loss = 0.4366\n",
      "Iteration 63/115: Train Loss = 0.4248, Valid Loss = 0.4353\n",
      "Iteration 64/115: Train Loss = 0.4235, Valid Loss = 0.4341\n",
      "Iteration 65/115: Train Loss = 0.4222, Valid Loss = 0.4327\n",
      "Iteration 66/115: Train Loss = 0.4209, Valid Loss = 0.4312\n",
      "Iteration 67/115: Train Loss = 0.4196, Valid Loss = 0.4301\n",
      "Iteration 68/115: Train Loss = 0.4184, Valid Loss = 0.4290\n",
      "Iteration 69/115: Train Loss = 0.4171, Valid Loss = 0.4278\n",
      "Iteration 70/115: Train Loss = 0.4160, Valid Loss = 0.4267\n",
      "Iteration 71/115: Train Loss = 0.4148, Valid Loss = 0.4254\n",
      "Iteration 72/115: Train Loss = 0.4136, Valid Loss = 0.4243\n",
      "Iteration 73/115: Train Loss = 0.4125, Valid Loss = 0.4233\n",
      "Iteration 74/115: Train Loss = 0.4114, Valid Loss = 0.4222\n",
      "Iteration 75/115: Train Loss = 0.4103, Valid Loss = 0.4210\n",
      "Iteration 76/115: Train Loss = 0.4092, Valid Loss = 0.4198\n",
      "Iteration 77/115: Train Loss = 0.4082, Valid Loss = 0.4189\n",
      "Iteration 78/115: Train Loss = 0.4072, Valid Loss = 0.4179\n",
      "Iteration 79/115: Train Loss = 0.4062, Valid Loss = 0.4168\n",
      "Iteration 80/115: Train Loss = 0.4052, Valid Loss = 0.4159\n",
      "Iteration 81/115: Train Loss = 0.4042, Valid Loss = 0.4150\n",
      "Iteration 82/115: Train Loss = 0.4032, Valid Loss = 0.4140\n",
      "Iteration 83/115: Train Loss = 0.4023, Valid Loss = 0.4132\n",
      "Iteration 84/115: Train Loss = 0.4014, Valid Loss = 0.4123\n",
      "Iteration 85/115: Train Loss = 0.4005, Valid Loss = 0.4114\n",
      "Iteration 86/115: Train Loss = 0.3996, Valid Loss = 0.4106\n",
      "Iteration 87/115: Train Loss = 0.3988, Valid Loss = 0.4098\n",
      "Iteration 88/115: Train Loss = 0.3979, Valid Loss = 0.4089\n",
      "Iteration 89/115: Train Loss = 0.3970, Valid Loss = 0.4081\n",
      "Iteration 90/115: Train Loss = 0.3962, Valid Loss = 0.4073\n",
      "Iteration 91/115: Train Loss = 0.3953, Valid Loss = 0.4063\n",
      "Iteration 92/115: Train Loss = 0.3945, Valid Loss = 0.4056\n",
      "Iteration 93/115: Train Loss = 0.3937, Valid Loss = 0.4049\n",
      "Iteration 94/115: Train Loss = 0.3929, Valid Loss = 0.4040\n",
      "Iteration 95/115: Train Loss = 0.3921, Valid Loss = 0.4032\n",
      "Iteration 96/115: Train Loss = 0.3914, Valid Loss = 0.4026\n",
      "Iteration 97/115: Train Loss = 0.3906, Valid Loss = 0.4019\n",
      "Iteration 98/115: Train Loss = 0.3898, Valid Loss = 0.4011\n",
      "Iteration 99/115: Train Loss = 0.3891, Valid Loss = 0.4004\n",
      "Iteration 100/115: Train Loss = 0.3883, Valid Loss = 0.3997\n",
      "Iteration 101/115: Train Loss = 0.3876, Valid Loss = 0.3990\n",
      "Iteration 102/115: Train Loss = 0.3869, Valid Loss = 0.3983\n",
      "Iteration 103/115: Train Loss = 0.3862, Valid Loss = 0.3976\n",
      "Iteration 104/115: Train Loss = 0.3855, Valid Loss = 0.3970\n",
      "Iteration 105/115: Train Loss = 0.3848, Valid Loss = 0.3962\n",
      "Iteration 106/115: Train Loss = 0.3841, Valid Loss = 0.3956\n",
      "Iteration 107/115: Train Loss = 0.3834, Valid Loss = 0.3949\n",
      "Iteration 108/115: Train Loss = 0.3827, Valid Loss = 0.3942\n",
      "Iteration 109/115: Train Loss = 0.3821, Valid Loss = 0.3936\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-05 00:49:40,537] Trial 14 finished with value: 0.924732240562171 and parameters: {'max_depth': 1, 'min_samples_leaf': 13, 'n_estimators': 115, 'learning_rate': 0.11831499299537956, 'subsample': 0.7238635172477894}. Best is trial 6 with value: 0.965235693124235.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 110/115: Train Loss = 0.3814, Valid Loss = 0.3928\n",
      "Iteration 111/115: Train Loss = 0.3808, Valid Loss = 0.3922\n",
      "Iteration 112/115: Train Loss = 0.3801, Valid Loss = 0.3916\n",
      "Iteration 113/115: Train Loss = 0.3795, Valid Loss = 0.3908\n",
      "Iteration 114/115: Train Loss = 0.3788, Valid Loss = 0.3902\n",
      "Iteration 115/115: Train Loss = 0.3782, Valid Loss = 0.3895\n",
      "Iteration 1/115: Train Loss = 0.6896, Valid Loss = 0.6897\n",
      "Iteration 2/115: Train Loss = 0.6860, Valid Loss = 0.6863\n",
      "Iteration 3/115: Train Loss = 0.6825, Valid Loss = 0.6829\n",
      "Iteration 4/115: Train Loss = 0.6791, Valid Loss = 0.6795\n",
      "Iteration 5/115: Train Loss = 0.6756, Valid Loss = 0.6762\n",
      "Iteration 6/115: Train Loss = 0.6722, Valid Loss = 0.6728\n",
      "Iteration 7/115: Train Loss = 0.6689, Valid Loss = 0.6696\n",
      "Iteration 8/115: Train Loss = 0.6655, Valid Loss = 0.6663\n",
      "Iteration 9/115: Train Loss = 0.6622, Valid Loss = 0.6631\n",
      "Iteration 10/115: Train Loss = 0.6589, Valid Loss = 0.6599\n",
      "Iteration 11/115: Train Loss = 0.6557, Valid Loss = 0.6567\n",
      "Iteration 12/115: Train Loss = 0.6525, Valid Loss = 0.6536\n",
      "Iteration 13/115: Train Loss = 0.6493, Valid Loss = 0.6506\n",
      "Iteration 14/115: Train Loss = 0.6462, Valid Loss = 0.6475\n",
      "Iteration 15/115: Train Loss = 0.6431, Valid Loss = 0.6445\n",
      "Iteration 16/115: Train Loss = 0.6400, Valid Loss = 0.6415\n",
      "Iteration 17/115: Train Loss = 0.6369, Valid Loss = 0.6386\n",
      "Iteration 18/115: Train Loss = 0.6339, Valid Loss = 0.6356\n",
      "Iteration 19/115: Train Loss = 0.6309, Valid Loss = 0.6327\n",
      "Iteration 20/115: Train Loss = 0.6280, Valid Loss = 0.6298\n",
      "Iteration 21/115: Train Loss = 0.6251, Valid Loss = 0.6270\n",
      "Iteration 22/115: Train Loss = 0.6222, Valid Loss = 0.6242\n",
      "Iteration 23/115: Train Loss = 0.6193, Valid Loss = 0.6214\n",
      "Iteration 24/115: Train Loss = 0.6165, Valid Loss = 0.6186\n",
      "Iteration 25/115: Train Loss = 0.6137, Valid Loss = 0.6159\n",
      "Iteration 26/115: Train Loss = 0.6108, Valid Loss = 0.6131\n",
      "Iteration 27/115: Train Loss = 0.6080, Valid Loss = 0.6104\n",
      "Iteration 28/115: Train Loss = 0.6053, Valid Loss = 0.6078\n",
      "Iteration 29/115: Train Loss = 0.6026, Valid Loss = 0.6052\n",
      "Iteration 30/115: Train Loss = 0.5999, Valid Loss = 0.6026\n",
      "Iteration 31/115: Train Loss = 0.5973, Valid Loss = 0.6000\n",
      "Iteration 32/115: Train Loss = 0.5947, Valid Loss = 0.5975\n",
      "Iteration 33/115: Train Loss = 0.5921, Valid Loss = 0.5950\n",
      "Iteration 34/115: Train Loss = 0.5895, Valid Loss = 0.5925\n",
      "Iteration 35/115: Train Loss = 0.5870, Valid Loss = 0.5900\n",
      "Iteration 36/115: Train Loss = 0.5844, Valid Loss = 0.5876\n",
      "Iteration 37/115: Train Loss = 0.5819, Valid Loss = 0.5852\n",
      "Iteration 38/115: Train Loss = 0.5795, Valid Loss = 0.5828\n",
      "Iteration 39/115: Train Loss = 0.5770, Valid Loss = 0.5805\n",
      "Iteration 40/115: Train Loss = 0.5746, Valid Loss = 0.5781\n",
      "Iteration 41/115: Train Loss = 0.5722, Valid Loss = 0.5758\n",
      "Iteration 42/115: Train Loss = 0.5698, Valid Loss = 0.5735\n",
      "Iteration 43/115: Train Loss = 0.5675, Valid Loss = 0.5713\n",
      "Iteration 44/115: Train Loss = 0.5651, Valid Loss = 0.5690\n",
      "Iteration 45/115: Train Loss = 0.5628, Valid Loss = 0.5668\n",
      "Iteration 46/115: Train Loss = 0.5605, Valid Loss = 0.5645\n",
      "Iteration 47/115: Train Loss = 0.5583, Valid Loss = 0.5623\n",
      "Iteration 48/115: Train Loss = 0.5560, Valid Loss = 0.5601\n",
      "Iteration 49/115: Train Loss = 0.5538, Valid Loss = 0.5580\n",
      "Iteration 50/115: Train Loss = 0.5516, Valid Loss = 0.5558\n",
      "Iteration 51/115: Train Loss = 0.5494, Valid Loss = 0.5538\n",
      "Iteration 52/115: Train Loss = 0.5472, Valid Loss = 0.5516\n",
      "Iteration 53/115: Train Loss = 0.5451, Valid Loss = 0.5496\n",
      "Iteration 54/115: Train Loss = 0.5430, Valid Loss = 0.5475\n",
      "Iteration 55/115: Train Loss = 0.5409, Valid Loss = 0.5455\n",
      "Iteration 56/115: Train Loss = 0.5388, Valid Loss = 0.5435\n",
      "Iteration 57/115: Train Loss = 0.5367, Valid Loss = 0.5416\n",
      "Iteration 58/115: Train Loss = 0.5347, Valid Loss = 0.5396\n",
      "Iteration 59/115: Train Loss = 0.5326, Valid Loss = 0.5376\n",
      "Iteration 60/115: Train Loss = 0.5307, Valid Loss = 0.5357\n",
      "Iteration 61/115: Train Loss = 0.5287, Valid Loss = 0.5338\n",
      "Iteration 62/115: Train Loss = 0.5267, Valid Loss = 0.5319\n",
      "Iteration 63/115: Train Loss = 0.5248, Valid Loss = 0.5300\n",
      "Iteration 64/115: Train Loss = 0.5228, Valid Loss = 0.5281\n",
      "Iteration 65/115: Train Loss = 0.5209, Valid Loss = 0.5263\n",
      "Iteration 66/115: Train Loss = 0.5190, Valid Loss = 0.5245\n",
      "Iteration 67/115: Train Loss = 0.5171, Valid Loss = 0.5227\n",
      "Iteration 68/115: Train Loss = 0.5152, Valid Loss = 0.5208\n",
      "Iteration 69/115: Train Loss = 0.5134, Valid Loss = 0.5190\n",
      "Iteration 70/115: Train Loss = 0.5116, Valid Loss = 0.5173\n",
      "Iteration 71/115: Train Loss = 0.5098, Valid Loss = 0.5155\n",
      "Iteration 72/115: Train Loss = 0.5080, Valid Loss = 0.5138\n",
      "Iteration 73/115: Train Loss = 0.5062, Valid Loss = 0.5121\n",
      "Iteration 74/115: Train Loss = 0.5044, Valid Loss = 0.5104\n",
      "Iteration 75/115: Train Loss = 0.5026, Valid Loss = 0.5087\n",
      "Iteration 76/115: Train Loss = 0.5009, Valid Loss = 0.5071\n",
      "Iteration 77/115: Train Loss = 0.4992, Valid Loss = 0.5054\n",
      "Iteration 78/115: Train Loss = 0.4975, Valid Loss = 0.5038\n",
      "Iteration 79/115: Train Loss = 0.4958, Valid Loss = 0.5022\n",
      "Iteration 80/115: Train Loss = 0.4941, Valid Loss = 0.5006\n",
      "Iteration 81/115: Train Loss = 0.4925, Valid Loss = 0.4990\n",
      "Iteration 82/115: Train Loss = 0.4909, Valid Loss = 0.4975\n",
      "Iteration 83/115: Train Loss = 0.4892, Valid Loss = 0.4959\n",
      "Iteration 84/115: Train Loss = 0.4876, Valid Loss = 0.4943\n",
      "Iteration 85/115: Train Loss = 0.4860, Valid Loss = 0.4928\n",
      "Iteration 86/115: Train Loss = 0.4844, Valid Loss = 0.4913\n",
      "Iteration 87/115: Train Loss = 0.4829, Valid Loss = 0.4898\n",
      "Iteration 88/115: Train Loss = 0.4813, Valid Loss = 0.4883\n",
      "Iteration 89/115: Train Loss = 0.4798, Valid Loss = 0.4868\n",
      "Iteration 90/115: Train Loss = 0.4782, Valid Loss = 0.4853\n",
      "Iteration 91/115: Train Loss = 0.4768, Valid Loss = 0.4839\n",
      "Iteration 92/115: Train Loss = 0.4753, Valid Loss = 0.4824\n",
      "Iteration 93/115: Train Loss = 0.4738, Valid Loss = 0.4810\n",
      "Iteration 94/115: Train Loss = 0.4723, Valid Loss = 0.4796\n",
      "Iteration 95/115: Train Loss = 0.4708, Valid Loss = 0.4782\n",
      "Iteration 96/115: Train Loss = 0.4694, Valid Loss = 0.4768\n",
      "Iteration 97/115: Train Loss = 0.4680, Valid Loss = 0.4754\n",
      "Iteration 98/115: Train Loss = 0.4665, Valid Loss = 0.4741\n",
      "Iteration 99/115: Train Loss = 0.4651, Valid Loss = 0.4727\n",
      "Iteration 100/115: Train Loss = 0.4637, Valid Loss = 0.4714\n",
      "Iteration 101/115: Train Loss = 0.4623, Valid Loss = 0.4700\n",
      "Iteration 102/115: Train Loss = 0.4609, Valid Loss = 0.4687\n",
      "Iteration 103/115: Train Loss = 0.4595, Valid Loss = 0.4674\n",
      "Iteration 104/115: Train Loss = 0.4582, Valid Loss = 0.4662\n",
      "Iteration 105/115: Train Loss = 0.4568, Valid Loss = 0.4649\n",
      "Iteration 106/115: Train Loss = 0.4555, Valid Loss = 0.4636\n",
      "Iteration 107/115: Train Loss = 0.4542, Valid Loss = 0.4624\n",
      "Iteration 108/115: Train Loss = 0.4529, Valid Loss = 0.4612\n",
      "Iteration 109/115: Train Loss = 0.4516, Valid Loss = 0.4600\n",
      "Iteration 110/115: Train Loss = 0.4503, Valid Loss = 0.4587\n",
      "Iteration 111/115: Train Loss = 0.4490, Valid Loss = 0.4575\n",
      "Iteration 112/115: Train Loss = 0.4478, Valid Loss = 0.4563\n",
      "Iteration 113/115: Train Loss = 0.4465, Valid Loss = 0.4551\n",
      "Iteration 114/115: Train Loss = 0.4453, Valid Loss = 0.4540\n",
      "Iteration 115/115: Train Loss = 0.4440, Valid Loss = 0.4528\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-05 00:49:48,105] Trial 15 finished with value: 0.958800315706393 and parameters: {'max_depth': 8, 'min_samples_leaf': 17, 'n_estimators': 115, 'learning_rate': 0.020860412871374332, 'subsample': 0.7088780128535194}. Best is trial 6 with value: 0.965235693124235.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1/100: Train Loss = 0.6929, Valid Loss = 0.6929\n",
      "Iteration 2/100: Train Loss = 0.6927, Valid Loss = 0.6927\n",
      "Iteration 3/100: Train Loss = 0.6925, Valid Loss = 0.6925\n",
      "Iteration 4/100: Train Loss = 0.6923, Valid Loss = 0.6923\n",
      "Iteration 5/100: Train Loss = 0.6920, Valid Loss = 0.6921\n",
      "Iteration 6/100: Train Loss = 0.6918, Valid Loss = 0.6919\n",
      "Iteration 7/100: Train Loss = 0.6916, Valid Loss = 0.6916\n",
      "Iteration 8/100: Train Loss = 0.6914, Valid Loss = 0.6914\n",
      "Iteration 9/100: Train Loss = 0.6911, Valid Loss = 0.6912\n",
      "Iteration 10/100: Train Loss = 0.6909, Valid Loss = 0.6910\n",
      "Iteration 11/100: Train Loss = 0.6907, Valid Loss = 0.6908\n",
      "Iteration 12/100: Train Loss = 0.6905, Valid Loss = 0.6906\n",
      "Iteration 13/100: Train Loss = 0.6903, Valid Loss = 0.6904\n",
      "Iteration 14/100: Train Loss = 0.6900, Valid Loss = 0.6901\n",
      "Iteration 15/100: Train Loss = 0.6898, Valid Loss = 0.6899\n",
      "Iteration 16/100: Train Loss = 0.6896, Valid Loss = 0.6897\n",
      "Iteration 17/100: Train Loss = 0.6894, Valid Loss = 0.6895\n",
      "Iteration 18/100: Train Loss = 0.6891, Valid Loss = 0.6893\n",
      "Iteration 19/100: Train Loss = 0.6889, Valid Loss = 0.6891\n",
      "Iteration 20/100: Train Loss = 0.6887, Valid Loss = 0.6889\n",
      "Iteration 21/100: Train Loss = 0.6885, Valid Loss = 0.6886\n",
      "Iteration 22/100: Train Loss = 0.6883, Valid Loss = 0.6884\n",
      "Iteration 23/100: Train Loss = 0.6880, Valid Loss = 0.6882\n",
      "Iteration 24/100: Train Loss = 0.6878, Valid Loss = 0.6880\n",
      "Iteration 25/100: Train Loss = 0.6876, Valid Loss = 0.6878\n",
      "Iteration 26/100: Train Loss = 0.6874, Valid Loss = 0.6876\n",
      "Iteration 27/100: Train Loss = 0.6872, Valid Loss = 0.6874\n",
      "Iteration 28/100: Train Loss = 0.6869, Valid Loss = 0.6871\n",
      "Iteration 29/100: Train Loss = 0.6867, Valid Loss = 0.6869\n",
      "Iteration 30/100: Train Loss = 0.6865, Valid Loss = 0.6867\n",
      "Iteration 31/100: Train Loss = 0.6863, Valid Loss = 0.6865\n",
      "Iteration 32/100: Train Loss = 0.6861, Valid Loss = 0.6863\n",
      "Iteration 33/100: Train Loss = 0.6858, Valid Loss = 0.6861\n",
      "Iteration 34/100: Train Loss = 0.6856, Valid Loss = 0.6859\n",
      "Iteration 35/100: Train Loss = 0.6854, Valid Loss = 0.6857\n",
      "Iteration 36/100: Train Loss = 0.6852, Valid Loss = 0.6854\n",
      "Iteration 37/100: Train Loss = 0.6850, Valid Loss = 0.6852\n",
      "Iteration 38/100: Train Loss = 0.6847, Valid Loss = 0.6850\n",
      "Iteration 39/100: Train Loss = 0.6845, Valid Loss = 0.6848\n",
      "Iteration 40/100: Train Loss = 0.6843, Valid Loss = 0.6846\n",
      "Iteration 41/100: Train Loss = 0.6841, Valid Loss = 0.6844\n",
      "Iteration 42/100: Train Loss = 0.6839, Valid Loss = 0.6842\n",
      "Iteration 43/100: Train Loss = 0.6837, Valid Loss = 0.6840\n",
      "Iteration 44/100: Train Loss = 0.6834, Valid Loss = 0.6838\n",
      "Iteration 45/100: Train Loss = 0.6832, Valid Loss = 0.6836\n",
      "Iteration 46/100: Train Loss = 0.6830, Valid Loss = 0.6834\n",
      "Iteration 47/100: Train Loss = 0.6828, Valid Loss = 0.6831\n",
      "Iteration 48/100: Train Loss = 0.6826, Valid Loss = 0.6829\n",
      "Iteration 49/100: Train Loss = 0.6824, Valid Loss = 0.6827\n",
      "Iteration 50/100: Train Loss = 0.6821, Valid Loss = 0.6825\n",
      "Iteration 51/100: Train Loss = 0.6819, Valid Loss = 0.6823\n",
      "Iteration 52/100: Train Loss = 0.6817, Valid Loss = 0.6821\n",
      "Iteration 53/100: Train Loss = 0.6815, Valid Loss = 0.6819\n",
      "Iteration 54/100: Train Loss = 0.6813, Valid Loss = 0.6817\n",
      "Iteration 55/100: Train Loss = 0.6811, Valid Loss = 0.6815\n",
      "Iteration 56/100: Train Loss = 0.6808, Valid Loss = 0.6813\n",
      "Iteration 57/100: Train Loss = 0.6806, Valid Loss = 0.6810\n",
      "Iteration 58/100: Train Loss = 0.6804, Valid Loss = 0.6808\n",
      "Iteration 59/100: Train Loss = 0.6802, Valid Loss = 0.6806\n",
      "Iteration 60/100: Train Loss = 0.6800, Valid Loss = 0.6804\n",
      "Iteration 61/100: Train Loss = 0.6798, Valid Loss = 0.6802\n",
      "Iteration 62/100: Train Loss = 0.6796, Valid Loss = 0.6800\n",
      "Iteration 63/100: Train Loss = 0.6793, Valid Loss = 0.6798\n",
      "Iteration 64/100: Train Loss = 0.6791, Valid Loss = 0.6796\n",
      "Iteration 65/100: Train Loss = 0.6789, Valid Loss = 0.6794\n",
      "Iteration 66/100: Train Loss = 0.6787, Valid Loss = 0.6792\n",
      "Iteration 67/100: Train Loss = 0.6785, Valid Loss = 0.6790\n",
      "Iteration 68/100: Train Loss = 0.6783, Valid Loss = 0.6788\n",
      "Iteration 69/100: Train Loss = 0.6781, Valid Loss = 0.6786\n",
      "Iteration 70/100: Train Loss = 0.6778, Valid Loss = 0.6784\n",
      "Iteration 71/100: Train Loss = 0.6776, Valid Loss = 0.6782\n",
      "Iteration 72/100: Train Loss = 0.6774, Valid Loss = 0.6779\n",
      "Iteration 73/100: Train Loss = 0.6772, Valid Loss = 0.6777\n",
      "Iteration 74/100: Train Loss = 0.6770, Valid Loss = 0.6775\n",
      "Iteration 75/100: Train Loss = 0.6768, Valid Loss = 0.6773\n",
      "Iteration 76/100: Train Loss = 0.6766, Valid Loss = 0.6771\n",
      "Iteration 77/100: Train Loss = 0.6764, Valid Loss = 0.6769\n",
      "Iteration 78/100: Train Loss = 0.6761, Valid Loss = 0.6767\n",
      "Iteration 79/100: Train Loss = 0.6759, Valid Loss = 0.6765\n",
      "Iteration 80/100: Train Loss = 0.6757, Valid Loss = 0.6763\n",
      "Iteration 81/100: Train Loss = 0.6755, Valid Loss = 0.6761\n",
      "Iteration 82/100: Train Loss = 0.6753, Valid Loss = 0.6759\n",
      "Iteration 83/100: Train Loss = 0.6751, Valid Loss = 0.6757\n",
      "Iteration 84/100: Train Loss = 0.6749, Valid Loss = 0.6755\n",
      "Iteration 85/100: Train Loss = 0.6747, Valid Loss = 0.6753\n",
      "Iteration 86/100: Train Loss = 0.6744, Valid Loss = 0.6751\n",
      "Iteration 87/100: Train Loss = 0.6742, Valid Loss = 0.6749\n",
      "Iteration 88/100: Train Loss = 0.6740, Valid Loss = 0.6747\n",
      "Iteration 89/100: Train Loss = 0.6738, Valid Loss = 0.6745\n",
      "Iteration 90/100: Train Loss = 0.6736, Valid Loss = 0.6743\n",
      "Iteration 91/100: Train Loss = 0.6734, Valid Loss = 0.6741\n",
      "Iteration 92/100: Train Loss = 0.6732, Valid Loss = 0.6739\n",
      "Iteration 93/100: Train Loss = 0.6730, Valid Loss = 0.6736\n",
      "Iteration 94/100: Train Loss = 0.6728, Valid Loss = 0.6734\n",
      "Iteration 95/100: Train Loss = 0.6726, Valid Loss = 0.6732\n",
      "Iteration 96/100: Train Loss = 0.6723, Valid Loss = 0.6730\n",
      "Iteration 97/100: Train Loss = 0.6721, Valid Loss = 0.6728\n",
      "Iteration 98/100: Train Loss = 0.6719, Valid Loss = 0.6726\n",
      "Iteration 99/100: Train Loss = 0.6717, Valid Loss = 0.6724\n",
      "Iteration 100/100: Train Loss = 0.6715, Valid Loss = 0.6722\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-05 00:49:54,385] Trial 16 finished with value: 0.958767906233676 and parameters: {'max_depth': 8, 'min_samples_leaf': 7, 'n_estimators': 100, 'learning_rate': 0.0012796368307581559, 'subsample': 0.6345180478300262}. Best is trial 6 with value: 0.965235693124235.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1/130: Train Loss = 0.6370, Valid Loss = 0.6380\n",
      "Iteration 2/130: Train Loss = 0.5903, Valid Loss = 0.5923\n",
      "Iteration 3/130: Train Loss = 0.5516, Valid Loss = 0.5547\n",
      "Iteration 4/130: Train Loss = 0.5199, Valid Loss = 0.5244\n",
      "Iteration 5/130: Train Loss = 0.4936, Valid Loss = 0.4989\n",
      "Iteration 6/130: Train Loss = 0.4712, Valid Loss = 0.4767\n",
      "Iteration 7/130: Train Loss = 0.4528, Valid Loss = 0.4589\n",
      "Iteration 8/130: Train Loss = 0.4364, Valid Loss = 0.4429\n",
      "Iteration 9/130: Train Loss = 0.4223, Valid Loss = 0.4288\n",
      "Iteration 10/130: Train Loss = 0.4101, Valid Loss = 0.4171\n",
      "Iteration 11/130: Train Loss = 0.3995, Valid Loss = 0.4070\n",
      "Iteration 12/130: Train Loss = 0.3905, Valid Loss = 0.3982\n",
      "Iteration 13/130: Train Loss = 0.3823, Valid Loss = 0.3901\n",
      "Iteration 14/130: Train Loss = 0.3743, Valid Loss = 0.3821\n",
      "Iteration 15/130: Train Loss = 0.3679, Valid Loss = 0.3761\n",
      "Iteration 16/130: Train Loss = 0.3610, Valid Loss = 0.3695\n",
      "Iteration 17/130: Train Loss = 0.3554, Valid Loss = 0.3641\n",
      "Iteration 18/130: Train Loss = 0.3506, Valid Loss = 0.3596\n",
      "Iteration 19/130: Train Loss = 0.3462, Valid Loss = 0.3554\n",
      "Iteration 20/130: Train Loss = 0.3416, Valid Loss = 0.3512\n",
      "Iteration 21/130: Train Loss = 0.3373, Valid Loss = 0.3471\n",
      "Iteration 22/130: Train Loss = 0.3335, Valid Loss = 0.3435\n",
      "Iteration 23/130: Train Loss = 0.3301, Valid Loss = 0.3405\n",
      "Iteration 24/130: Train Loss = 0.3270, Valid Loss = 0.3374\n",
      "Iteration 25/130: Train Loss = 0.3238, Valid Loss = 0.3345\n",
      "Iteration 26/130: Train Loss = 0.3207, Valid Loss = 0.3314\n",
      "Iteration 27/130: Train Loss = 0.3177, Valid Loss = 0.3286\n",
      "Iteration 28/130: Train Loss = 0.3152, Valid Loss = 0.3261\n",
      "Iteration 29/130: Train Loss = 0.3129, Valid Loss = 0.3238\n",
      "Iteration 30/130: Train Loss = 0.3107, Valid Loss = 0.3219\n",
      "Iteration 31/130: Train Loss = 0.3088, Valid Loss = 0.3200\n",
      "Iteration 32/130: Train Loss = 0.3070, Valid Loss = 0.3182\n",
      "Iteration 33/130: Train Loss = 0.3053, Valid Loss = 0.3165\n",
      "Iteration 34/130: Train Loss = 0.3034, Valid Loss = 0.3145\n",
      "Iteration 35/130: Train Loss = 0.3015, Valid Loss = 0.3126\n",
      "Iteration 36/130: Train Loss = 0.2997, Valid Loss = 0.3108\n",
      "Iteration 37/130: Train Loss = 0.2978, Valid Loss = 0.3094\n",
      "Iteration 38/130: Train Loss = 0.2963, Valid Loss = 0.3082\n",
      "Iteration 39/130: Train Loss = 0.2945, Valid Loss = 0.3064\n",
      "Iteration 40/130: Train Loss = 0.2929, Valid Loss = 0.3048\n",
      "Iteration 41/130: Train Loss = 0.2914, Valid Loss = 0.3035\n",
      "Iteration 42/130: Train Loss = 0.2900, Valid Loss = 0.3019\n",
      "Iteration 43/130: Train Loss = 0.2886, Valid Loss = 0.3004\n",
      "Iteration 44/130: Train Loss = 0.2872, Valid Loss = 0.2991\n",
      "Iteration 45/130: Train Loss = 0.2860, Valid Loss = 0.2978\n",
      "Iteration 46/130: Train Loss = 0.2848, Valid Loss = 0.2968\n",
      "Iteration 47/130: Train Loss = 0.2837, Valid Loss = 0.2953\n",
      "Iteration 48/130: Train Loss = 0.2824, Valid Loss = 0.2942\n",
      "Iteration 49/130: Train Loss = 0.2812, Valid Loss = 0.2928\n",
      "Iteration 50/130: Train Loss = 0.2801, Valid Loss = 0.2917\n",
      "Iteration 51/130: Train Loss = 0.2790, Valid Loss = 0.2907\n",
      "Iteration 52/130: Train Loss = 0.2780, Valid Loss = 0.2894\n",
      "Iteration 53/130: Train Loss = 0.2772, Valid Loss = 0.2887\n",
      "Iteration 54/130: Train Loss = 0.2762, Valid Loss = 0.2878\n",
      "Iteration 55/130: Train Loss = 0.2752, Valid Loss = 0.2869\n",
      "Iteration 56/130: Train Loss = 0.2744, Valid Loss = 0.2860\n",
      "Iteration 57/130: Train Loss = 0.2735, Valid Loss = 0.2851\n",
      "Iteration 58/130: Train Loss = 0.2727, Valid Loss = 0.2842\n",
      "Iteration 59/130: Train Loss = 0.2719, Valid Loss = 0.2836\n",
      "Iteration 60/130: Train Loss = 0.2711, Valid Loss = 0.2827\n",
      "Iteration 61/130: Train Loss = 0.2703, Valid Loss = 0.2818\n",
      "Iteration 62/130: Train Loss = 0.2695, Valid Loss = 0.2811\n",
      "Iteration 63/130: Train Loss = 0.2689, Valid Loss = 0.2805\n",
      "Iteration 64/130: Train Loss = 0.2682, Valid Loss = 0.2797\n",
      "Iteration 65/130: Train Loss = 0.2675, Valid Loss = 0.2790\n",
      "Iteration 66/130: Train Loss = 0.2670, Valid Loss = 0.2785\n",
      "Iteration 67/130: Train Loss = 0.2662, Valid Loss = 0.2778\n",
      "Iteration 68/130: Train Loss = 0.2656, Valid Loss = 0.2772\n",
      "Iteration 69/130: Train Loss = 0.2650, Valid Loss = 0.2765\n",
      "Iteration 70/130: Train Loss = 0.2644, Valid Loss = 0.2759\n",
      "Iteration 71/130: Train Loss = 0.2638, Valid Loss = 0.2756\n",
      "Iteration 72/130: Train Loss = 0.2630, Valid Loss = 0.2749\n",
      "Iteration 73/130: Train Loss = 0.2625, Valid Loss = 0.2743\n",
      "Iteration 74/130: Train Loss = 0.2619, Valid Loss = 0.2736\n",
      "Iteration 75/130: Train Loss = 0.2614, Valid Loss = 0.2733\n",
      "Iteration 76/130: Train Loss = 0.2608, Valid Loss = 0.2727\n",
      "Iteration 77/130: Train Loss = 0.2603, Valid Loss = 0.2720\n",
      "Iteration 78/130: Train Loss = 0.2598, Valid Loss = 0.2717\n",
      "Iteration 79/130: Train Loss = 0.2593, Valid Loss = 0.2713\n",
      "Iteration 80/130: Train Loss = 0.2588, Valid Loss = 0.2709\n",
      "Iteration 81/130: Train Loss = 0.2583, Valid Loss = 0.2704\n",
      "Iteration 82/130: Train Loss = 0.2578, Valid Loss = 0.2699\n",
      "Iteration 83/130: Train Loss = 0.2574, Valid Loss = 0.2696\n",
      "Iteration 84/130: Train Loss = 0.2570, Valid Loss = 0.2691\n",
      "Iteration 85/130: Train Loss = 0.2564, Valid Loss = 0.2685\n",
      "Iteration 86/130: Train Loss = 0.2559, Valid Loss = 0.2679\n",
      "Iteration 87/130: Train Loss = 0.2553, Valid Loss = 0.2673\n",
      "Iteration 88/130: Train Loss = 0.2550, Valid Loss = 0.2672\n",
      "Iteration 89/130: Train Loss = 0.2545, Valid Loss = 0.2664\n",
      "Iteration 90/130: Train Loss = 0.2542, Valid Loss = 0.2661\n",
      "Iteration 91/130: Train Loss = 0.2538, Valid Loss = 0.2660\n",
      "Iteration 92/130: Train Loss = 0.2533, Valid Loss = 0.2656\n",
      "Iteration 93/130: Train Loss = 0.2528, Valid Loss = 0.2652\n",
      "Iteration 94/130: Train Loss = 0.2525, Valid Loss = 0.2649\n",
      "Iteration 95/130: Train Loss = 0.2520, Valid Loss = 0.2645\n",
      "Iteration 96/130: Train Loss = 0.2516, Valid Loss = 0.2644\n",
      "Iteration 97/130: Train Loss = 0.2513, Valid Loss = 0.2642\n",
      "Iteration 98/130: Train Loss = 0.2509, Valid Loss = 0.2639\n",
      "Iteration 99/130: Train Loss = 0.2506, Valid Loss = 0.2634\n",
      "Iteration 100/130: Train Loss = 0.2502, Valid Loss = 0.2631\n",
      "Iteration 101/130: Train Loss = 0.2499, Valid Loss = 0.2627\n",
      "Iteration 102/130: Train Loss = 0.2494, Valid Loss = 0.2625\n",
      "Iteration 103/130: Train Loss = 0.2490, Valid Loss = 0.2625\n",
      "Iteration 104/130: Train Loss = 0.2486, Valid Loss = 0.2621\n",
      "Iteration 105/130: Train Loss = 0.2483, Valid Loss = 0.2619\n",
      "Iteration 106/130: Train Loss = 0.2480, Valid Loss = 0.2617\n",
      "Iteration 107/130: Train Loss = 0.2476, Valid Loss = 0.2613\n",
      "Iteration 108/130: Train Loss = 0.2472, Valid Loss = 0.2610\n",
      "Iteration 109/130: Train Loss = 0.2469, Valid Loss = 0.2606\n",
      "Iteration 110/130: Train Loss = 0.2466, Valid Loss = 0.2602\n",
      "Iteration 111/130: Train Loss = 0.2463, Valid Loss = 0.2600\n",
      "Iteration 112/130: Train Loss = 0.2459, Valid Loss = 0.2598\n",
      "Iteration 113/130: Train Loss = 0.2455, Valid Loss = 0.2596\n",
      "Iteration 114/130: Train Loss = 0.2452, Valid Loss = 0.2594\n",
      "Iteration 115/130: Train Loss = 0.2449, Valid Loss = 0.2591\n",
      "Iteration 116/130: Train Loss = 0.2446, Valid Loss = 0.2589\n",
      "Iteration 117/130: Train Loss = 0.2443, Valid Loss = 0.2583\n",
      "Iteration 118/130: Train Loss = 0.2440, Valid Loss = 0.2581\n",
      "Iteration 119/130: Train Loss = 0.2436, Valid Loss = 0.2575\n",
      "Iteration 120/130: Train Loss = 0.2433, Valid Loss = 0.2573\n",
      "Iteration 121/130: Train Loss = 0.2430, Valid Loss = 0.2569\n",
      "Iteration 122/130: Train Loss = 0.2428, Valid Loss = 0.2566\n",
      "Iteration 123/130: Train Loss = 0.2425, Valid Loss = 0.2564\n",
      "Iteration 124/130: Train Loss = 0.2423, Valid Loss = 0.2562\n",
      "Iteration 125/130: Train Loss = 0.2420, Valid Loss = 0.2561\n",
      "Iteration 126/130: Train Loss = 0.2418, Valid Loss = 0.2560\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-05 00:49:58,298] Trial 17 finished with value: 0.9617812246205233 and parameters: {'max_depth': 3, 'min_samples_leaf': 13, 'n_estimators': 130, 'learning_rate': 0.412176276269258, 'subsample': 0.4866367765057925}. Best is trial 6 with value: 0.965235693124235.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 127/130: Train Loss = 0.2417, Valid Loss = 0.2559\n",
      "Iteration 128/130: Train Loss = 0.2414, Valid Loss = 0.2558\n",
      "Iteration 129/130: Train Loss = 0.2412, Valid Loss = 0.2556\n",
      "Iteration 130/130: Train Loss = 0.2408, Valid Loss = 0.2555\n",
      "Iteration 1/80: Train Loss = 0.6743, Valid Loss = 0.6748\n",
      "Iteration 2/80: Train Loss = 0.6563, Valid Loss = 0.6574\n",
      "Iteration 3/80: Train Loss = 0.6393, Valid Loss = 0.6410\n",
      "Iteration 4/80: Train Loss = 0.6231, Valid Loss = 0.6255\n",
      "Iteration 5/80: Train Loss = 0.6079, Valid Loss = 0.6110\n",
      "Iteration 6/80: Train Loss = 0.5934, Valid Loss = 0.5970\n",
      "Iteration 7/80: Train Loss = 0.5798, Valid Loss = 0.5838\n",
      "Iteration 8/80: Train Loss = 0.5666, Valid Loss = 0.5715\n",
      "Iteration 9/80: Train Loss = 0.5539, Valid Loss = 0.5597\n",
      "Iteration 10/80: Train Loss = 0.5420, Valid Loss = 0.5483\n",
      "Iteration 11/80: Train Loss = 0.5307, Valid Loss = 0.5375\n",
      "Iteration 12/80: Train Loss = 0.5199, Valid Loss = 0.5271\n",
      "Iteration 13/80: Train Loss = 0.5097, Valid Loss = 0.5175\n",
      "Iteration 14/80: Train Loss = 0.4999, Valid Loss = 0.5080\n",
      "Iteration 15/80: Train Loss = 0.4906, Valid Loss = 0.4992\n",
      "Iteration 16/80: Train Loss = 0.4816, Valid Loss = 0.4907\n",
      "Iteration 17/80: Train Loss = 0.4731, Valid Loss = 0.4825\n",
      "Iteration 18/80: Train Loss = 0.4650, Valid Loss = 0.4749\n",
      "Iteration 19/80: Train Loss = 0.4572, Valid Loss = 0.4676\n",
      "Iteration 20/80: Train Loss = 0.4498, Valid Loss = 0.4605\n",
      "Iteration 21/80: Train Loss = 0.4426, Valid Loss = 0.4537\n",
      "Iteration 22/80: Train Loss = 0.4359, Valid Loss = 0.4473\n",
      "Iteration 23/80: Train Loss = 0.4294, Valid Loss = 0.4413\n",
      "Iteration 24/80: Train Loss = 0.4232, Valid Loss = 0.4354\n",
      "Iteration 25/80: Train Loss = 0.4173, Valid Loss = 0.4301\n",
      "Iteration 26/80: Train Loss = 0.4116, Valid Loss = 0.4251\n",
      "Iteration 27/80: Train Loss = 0.4060, Valid Loss = 0.4201\n",
      "Iteration 28/80: Train Loss = 0.4007, Valid Loss = 0.4153\n",
      "Iteration 29/80: Train Loss = 0.3955, Valid Loss = 0.4105\n",
      "Iteration 30/80: Train Loss = 0.3907, Valid Loss = 0.4061\n",
      "Iteration 31/80: Train Loss = 0.3858, Valid Loss = 0.4017\n",
      "Iteration 32/80: Train Loss = 0.3813, Valid Loss = 0.3976\n",
      "Iteration 33/80: Train Loss = 0.3769, Valid Loss = 0.3935\n",
      "Iteration 34/80: Train Loss = 0.3726, Valid Loss = 0.3898\n",
      "Iteration 35/80: Train Loss = 0.3684, Valid Loss = 0.3860\n",
      "Iteration 36/80: Train Loss = 0.3645, Valid Loss = 0.3825\n",
      "Iteration 37/80: Train Loss = 0.3607, Valid Loss = 0.3790\n",
      "Iteration 38/80: Train Loss = 0.3570, Valid Loss = 0.3756\n",
      "Iteration 39/80: Train Loss = 0.3534, Valid Loss = 0.3724\n",
      "Iteration 40/80: Train Loss = 0.3499, Valid Loss = 0.3693\n",
      "Iteration 41/80: Train Loss = 0.3465, Valid Loss = 0.3663\n",
      "Iteration 42/80: Train Loss = 0.3433, Valid Loss = 0.3633\n",
      "Iteration 43/80: Train Loss = 0.3401, Valid Loss = 0.3607\n",
      "Iteration 44/80: Train Loss = 0.3369, Valid Loss = 0.3581\n",
      "Iteration 45/80: Train Loss = 0.3340, Valid Loss = 0.3554\n",
      "Iteration 46/80: Train Loss = 0.3311, Valid Loss = 0.3529\n",
      "Iteration 47/80: Train Loss = 0.3283, Valid Loss = 0.3504\n",
      "Iteration 48/80: Train Loss = 0.3257, Valid Loss = 0.3479\n",
      "Iteration 49/80: Train Loss = 0.3230, Valid Loss = 0.3458\n",
      "Iteration 50/80: Train Loss = 0.3205, Valid Loss = 0.3434\n",
      "Iteration 51/80: Train Loss = 0.3179, Valid Loss = 0.3412\n",
      "Iteration 52/80: Train Loss = 0.3155, Valid Loss = 0.3390\n",
      "Iteration 53/80: Train Loss = 0.3132, Valid Loss = 0.3371\n",
      "Iteration 54/80: Train Loss = 0.3108, Valid Loss = 0.3350\n",
      "Iteration 55/80: Train Loss = 0.3086, Valid Loss = 0.3331\n",
      "Iteration 56/80: Train Loss = 0.3064, Valid Loss = 0.3313\n",
      "Iteration 57/80: Train Loss = 0.3044, Valid Loss = 0.3295\n",
      "Iteration 58/80: Train Loss = 0.3023, Valid Loss = 0.3278\n",
      "Iteration 59/80: Train Loss = 0.3002, Valid Loss = 0.3260\n",
      "Iteration 60/80: Train Loss = 0.2983, Valid Loss = 0.3243\n",
      "Iteration 61/80: Train Loss = 0.2964, Valid Loss = 0.3228\n",
      "Iteration 62/80: Train Loss = 0.2945, Valid Loss = 0.3214\n",
      "Iteration 63/80: Train Loss = 0.2927, Valid Loss = 0.3199\n",
      "Iteration 64/80: Train Loss = 0.2909, Valid Loss = 0.3185\n",
      "Iteration 65/80: Train Loss = 0.2892, Valid Loss = 0.3170\n",
      "Iteration 66/80: Train Loss = 0.2875, Valid Loss = 0.3157\n",
      "Iteration 67/80: Train Loss = 0.2859, Valid Loss = 0.3142\n",
      "Iteration 68/80: Train Loss = 0.2842, Valid Loss = 0.3130\n",
      "Iteration 69/80: Train Loss = 0.2826, Valid Loss = 0.3118\n",
      "Iteration 70/80: Train Loss = 0.2811, Valid Loss = 0.3106\n",
      "Iteration 71/80: Train Loss = 0.2795, Valid Loss = 0.3093\n",
      "Iteration 72/80: Train Loss = 0.2780, Valid Loss = 0.3081\n",
      "Iteration 73/80: Train Loss = 0.2765, Valid Loss = 0.3071\n",
      "Iteration 74/80: Train Loss = 0.2751, Valid Loss = 0.3058\n",
      "Iteration 75/80: Train Loss = 0.2738, Valid Loss = 0.3048\n",
      "Iteration 76/80: Train Loss = 0.2724, Valid Loss = 0.3038\n",
      "Iteration 77/80: Train Loss = 0.2711, Valid Loss = 0.3028\n",
      "Iteration 78/80: Train Loss = 0.2698, Valid Loss = 0.3018\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-05 00:50:06,018] Trial 18 finished with value: 0.9629967704913658 and parameters: {'max_depth': 12, 'min_samples_leaf': 18, 'n_estimators': 80, 'learning_rate': 0.1080243913996377, 'subsample': 0.7377507909474819}. Best is trial 6 with value: 0.965235693124235.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 79/80: Train Loss = 0.2686, Valid Loss = 0.3008\n",
      "Iteration 80/80: Train Loss = 0.2673, Valid Loss = 0.2998\n",
      "Iteration 1/120: Train Loss = 0.6900, Valid Loss = 0.6901\n",
      "Iteration 2/120: Train Loss = 0.6868, Valid Loss = 0.6871\n",
      "Iteration 3/120: Train Loss = 0.6837, Valid Loss = 0.6841\n",
      "Iteration 4/120: Train Loss = 0.6806, Valid Loss = 0.6812\n",
      "Iteration 5/120: Train Loss = 0.6775, Valid Loss = 0.6782\n",
      "Iteration 6/120: Train Loss = 0.6744, Valid Loss = 0.6753\n",
      "Iteration 7/120: Train Loss = 0.6714, Valid Loss = 0.6724\n",
      "Iteration 8/120: Train Loss = 0.6684, Valid Loss = 0.6696\n",
      "Iteration 9/120: Train Loss = 0.6654, Valid Loss = 0.6668\n",
      "Iteration 10/120: Train Loss = 0.6625, Valid Loss = 0.6640\n",
      "Iteration 11/120: Train Loss = 0.6596, Valid Loss = 0.6612\n",
      "Iteration 12/120: Train Loss = 0.6566, Valid Loss = 0.6585\n",
      "Iteration 13/120: Train Loss = 0.6538, Valid Loss = 0.6557\n",
      "Iteration 14/120: Train Loss = 0.6509, Valid Loss = 0.6530\n",
      "Iteration 15/120: Train Loss = 0.6481, Valid Loss = 0.6504\n",
      "Iteration 16/120: Train Loss = 0.6453, Valid Loss = 0.6477\n",
      "Iteration 17/120: Train Loss = 0.6425, Valid Loss = 0.6451\n",
      "Iteration 18/120: Train Loss = 0.6397, Valid Loss = 0.6424\n",
      "Iteration 19/120: Train Loss = 0.6370, Valid Loss = 0.6398\n",
      "Iteration 20/120: Train Loss = 0.6343, Valid Loss = 0.6373\n",
      "Iteration 21/120: Train Loss = 0.6316, Valid Loss = 0.6347\n",
      "Iteration 22/120: Train Loss = 0.6289, Valid Loss = 0.6322\n",
      "Iteration 23/120: Train Loss = 0.6263, Valid Loss = 0.6297\n",
      "Iteration 24/120: Train Loss = 0.6236, Valid Loss = 0.6272\n",
      "Iteration 25/120: Train Loss = 0.6210, Valid Loss = 0.6247\n",
      "Iteration 26/120: Train Loss = 0.6184, Valid Loss = 0.6223\n",
      "Iteration 27/120: Train Loss = 0.6158, Valid Loss = 0.6198\n",
      "Iteration 28/120: Train Loss = 0.6133, Valid Loss = 0.6174\n",
      "Iteration 29/120: Train Loss = 0.6108, Valid Loss = 0.6151\n",
      "Iteration 30/120: Train Loss = 0.6083, Valid Loss = 0.6127\n",
      "Iteration 31/120: Train Loss = 0.6058, Valid Loss = 0.6104\n",
      "Iteration 32/120: Train Loss = 0.6033, Valid Loss = 0.6081\n",
      "Iteration 33/120: Train Loss = 0.6009, Valid Loss = 0.6058\n",
      "Iteration 34/120: Train Loss = 0.5984, Valid Loss = 0.6035\n",
      "Iteration 35/120: Train Loss = 0.5960, Valid Loss = 0.6012\n",
      "Iteration 36/120: Train Loss = 0.5937, Valid Loss = 0.5989\n",
      "Iteration 37/120: Train Loss = 0.5913, Valid Loss = 0.5967\n",
      "Iteration 38/120: Train Loss = 0.5889, Valid Loss = 0.5945\n",
      "Iteration 39/120: Train Loss = 0.5866, Valid Loss = 0.5924\n",
      "Iteration 40/120: Train Loss = 0.5843, Valid Loss = 0.5902\n",
      "Iteration 41/120: Train Loss = 0.5820, Valid Loss = 0.5880\n",
      "Iteration 42/120: Train Loss = 0.5797, Valid Loss = 0.5859\n",
      "Iteration 43/120: Train Loss = 0.5775, Valid Loss = 0.5838\n",
      "Iteration 44/120: Train Loss = 0.5752, Valid Loss = 0.5816\n",
      "Iteration 45/120: Train Loss = 0.5730, Valid Loss = 0.5795\n",
      "Iteration 46/120: Train Loss = 0.5708, Valid Loss = 0.5775\n",
      "Iteration 47/120: Train Loss = 0.5686, Valid Loss = 0.5754\n",
      "Iteration 48/120: Train Loss = 0.5664, Valid Loss = 0.5734\n",
      "Iteration 49/120: Train Loss = 0.5643, Valid Loss = 0.5714\n",
      "Iteration 50/120: Train Loss = 0.5621, Valid Loss = 0.5694\n",
      "Iteration 51/120: Train Loss = 0.5600, Valid Loss = 0.5675\n",
      "Iteration 52/120: Train Loss = 0.5579, Valid Loss = 0.5655\n",
      "Iteration 53/120: Train Loss = 0.5558, Valid Loss = 0.5635\n",
      "Iteration 54/120: Train Loss = 0.5538, Valid Loss = 0.5616\n",
      "Iteration 55/120: Train Loss = 0.5517, Valid Loss = 0.5596\n",
      "Iteration 56/120: Train Loss = 0.5497, Valid Loss = 0.5577\n",
      "Iteration 57/120: Train Loss = 0.5477, Valid Loss = 0.5558\n",
      "Iteration 58/120: Train Loss = 0.5457, Valid Loss = 0.5540\n",
      "Iteration 59/120: Train Loss = 0.5437, Valid Loss = 0.5521\n",
      "Iteration 60/120: Train Loss = 0.5417, Valid Loss = 0.5503\n",
      "Iteration 61/120: Train Loss = 0.5398, Valid Loss = 0.5485\n",
      "Iteration 62/120: Train Loss = 0.5378, Valid Loss = 0.5467\n",
      "Iteration 63/120: Train Loss = 0.5359, Valid Loss = 0.5448\n",
      "Iteration 64/120: Train Loss = 0.5340, Valid Loss = 0.5431\n",
      "Iteration 65/120: Train Loss = 0.5321, Valid Loss = 0.5413\n",
      "Iteration 66/120: Train Loss = 0.5302, Valid Loss = 0.5395\n",
      "Iteration 67/120: Train Loss = 0.5283, Valid Loss = 0.5378\n",
      "Iteration 68/120: Train Loss = 0.5265, Valid Loss = 0.5360\n",
      "Iteration 69/120: Train Loss = 0.5247, Valid Loss = 0.5343\n",
      "Iteration 70/120: Train Loss = 0.5229, Valid Loss = 0.5327\n",
      "Iteration 71/120: Train Loss = 0.5210, Valid Loss = 0.5310\n",
      "Iteration 72/120: Train Loss = 0.5192, Valid Loss = 0.5293\n",
      "Iteration 73/120: Train Loss = 0.5175, Valid Loss = 0.5277\n",
      "Iteration 74/120: Train Loss = 0.5157, Valid Loss = 0.5261\n",
      "Iteration 75/120: Train Loss = 0.5139, Valid Loss = 0.5245\n",
      "Iteration 76/120: Train Loss = 0.5122, Valid Loss = 0.5229\n",
      "Iteration 77/120: Train Loss = 0.5105, Valid Loss = 0.5213\n",
      "Iteration 78/120: Train Loss = 0.5088, Valid Loss = 0.5197\n",
      "Iteration 79/120: Train Loss = 0.5071, Valid Loss = 0.5181\n",
      "Iteration 80/120: Train Loss = 0.5054, Valid Loss = 0.5165\n",
      "Iteration 81/120: Train Loss = 0.5037, Valid Loss = 0.5150\n",
      "Iteration 82/120: Train Loss = 0.5021, Valid Loss = 0.5135\n",
      "Iteration 83/120: Train Loss = 0.5004, Valid Loss = 0.5120\n",
      "Iteration 84/120: Train Loss = 0.4988, Valid Loss = 0.5105\n",
      "Iteration 85/120: Train Loss = 0.4972, Valid Loss = 0.5090\n",
      "Iteration 86/120: Train Loss = 0.4956, Valid Loss = 0.5074\n",
      "Iteration 87/120: Train Loss = 0.4940, Valid Loss = 0.5060\n",
      "Iteration 88/120: Train Loss = 0.4924, Valid Loss = 0.5045\n",
      "Iteration 89/120: Train Loss = 0.4908, Valid Loss = 0.5030\n",
      "Iteration 90/120: Train Loss = 0.4892, Valid Loss = 0.5016\n",
      "Iteration 91/120: Train Loss = 0.4877, Valid Loss = 0.5001\n",
      "Iteration 92/120: Train Loss = 0.4861, Valid Loss = 0.4987\n",
      "Iteration 93/120: Train Loss = 0.4846, Valid Loss = 0.4973\n",
      "Iteration 94/120: Train Loss = 0.4831, Valid Loss = 0.4959\n",
      "Iteration 95/120: Train Loss = 0.4816, Valid Loss = 0.4945\n",
      "Iteration 96/120: Train Loss = 0.4801, Valid Loss = 0.4931\n",
      "Iteration 97/120: Train Loss = 0.4786, Valid Loss = 0.4917\n",
      "Iteration 98/120: Train Loss = 0.4771, Valid Loss = 0.4904\n",
      "Iteration 99/120: Train Loss = 0.4756, Valid Loss = 0.4890\n",
      "Iteration 100/120: Train Loss = 0.4742, Valid Loss = 0.4877\n",
      "Iteration 101/120: Train Loss = 0.4727, Valid Loss = 0.4863\n",
      "Iteration 102/120: Train Loss = 0.4713, Valid Loss = 0.4850\n",
      "Iteration 103/120: Train Loss = 0.4699, Valid Loss = 0.4837\n",
      "Iteration 104/120: Train Loss = 0.4685, Valid Loss = 0.4824\n",
      "Iteration 105/120: Train Loss = 0.4671, Valid Loss = 0.4811\n",
      "Iteration 106/120: Train Loss = 0.4657, Valid Loss = 0.4798\n",
      "Iteration 107/120: Train Loss = 0.4643, Valid Loss = 0.4786\n",
      "Iteration 108/120: Train Loss = 0.4629, Valid Loss = 0.4773\n",
      "Iteration 109/120: Train Loss = 0.4615, Valid Loss = 0.4761\n",
      "Iteration 110/120: Train Loss = 0.4602, Valid Loss = 0.4748\n",
      "Iteration 111/120: Train Loss = 0.4588, Valid Loss = 0.4736\n",
      "Iteration 112/120: Train Loss = 0.4575, Valid Loss = 0.4724\n",
      "Iteration 113/120: Train Loss = 0.4562, Valid Loss = 0.4712\n",
      "Iteration 114/120: Train Loss = 0.4549, Valid Loss = 0.4700\n",
      "Iteration 115/120: Train Loss = 0.4536, Valid Loss = 0.4687\n",
      "Iteration 116/120: Train Loss = 0.4523, Valid Loss = 0.4676\n",
      "Iteration 117/120: Train Loss = 0.4510, Valid Loss = 0.4664\n",
      "Iteration 118/120: Train Loss = 0.4497, Valid Loss = 0.4653\n",
      "Iteration 119/120: Train Loss = 0.4485, Valid Loss = 0.4641\n",
      "Iteration 120/120: Train Loss = 0.4472, Valid Loss = 0.4630\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-05 00:50:25,202] Trial 19 finished with value: 0.9617164056750892 and parameters: {'max_depth': 15, 'min_samples_leaf': 13, 'n_estimators': 120, 'learning_rate': 0.01747174211422389, 'subsample': 0.8819848713894572}. Best is trial 6 with value: 0.965235693124235.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1/95: Train Loss = 0.6069, Valid Loss = 0.6096\n",
      "Iteration 2/95: Train Loss = 0.5418, Valid Loss = 0.5469\n",
      "Iteration 3/95: Train Loss = 0.4916, Valid Loss = 0.5000\n",
      "Iteration 4/95: Train Loss = 0.4525, Valid Loss = 0.4627\n",
      "Iteration 5/95: Train Loss = 0.4206, Valid Loss = 0.4321\n",
      "Iteration 6/95: Train Loss = 0.3955, Valid Loss = 0.4082\n",
      "Iteration 7/95: Train Loss = 0.3742, Valid Loss = 0.3883\n",
      "Iteration 8/95: Train Loss = 0.3572, Valid Loss = 0.3722\n",
      "Iteration 9/95: Train Loss = 0.3420, Valid Loss = 0.3576\n",
      "Iteration 10/95: Train Loss = 0.3290, Valid Loss = 0.3459\n",
      "Iteration 11/95: Train Loss = 0.3178, Valid Loss = 0.3367\n",
      "Iteration 12/95: Train Loss = 0.3086, Valid Loss = 0.3287\n",
      "Iteration 13/95: Train Loss = 0.2997, Valid Loss = 0.3217\n",
      "Iteration 14/95: Train Loss = 0.2923, Valid Loss = 0.3156\n",
      "Iteration 15/95: Train Loss = 0.2856, Valid Loss = 0.3097\n",
      "Iteration 16/95: Train Loss = 0.2795, Valid Loss = 0.3048\n",
      "Iteration 17/95: Train Loss = 0.2741, Valid Loss = 0.3003\n",
      "Iteration 18/95: Train Loss = 0.2694, Valid Loss = 0.2960\n",
      "Iteration 19/95: Train Loss = 0.2650, Valid Loss = 0.2927\n",
      "Iteration 20/95: Train Loss = 0.2607, Valid Loss = 0.2898\n",
      "Iteration 21/95: Train Loss = 0.2570, Valid Loss = 0.2863\n",
      "Iteration 22/95: Train Loss = 0.2532, Valid Loss = 0.2833\n",
      "Iteration 23/95: Train Loss = 0.2501, Valid Loss = 0.2811\n",
      "Iteration 24/95: Train Loss = 0.2470, Valid Loss = 0.2789\n",
      "Iteration 25/95: Train Loss = 0.2441, Valid Loss = 0.2770\n",
      "Iteration 26/95: Train Loss = 0.2414, Valid Loss = 0.2755\n",
      "Iteration 27/95: Train Loss = 0.2390, Valid Loss = 0.2736\n",
      "Iteration 28/95: Train Loss = 0.2366, Valid Loss = 0.2715\n",
      "Iteration 29/95: Train Loss = 0.2346, Valid Loss = 0.2698\n",
      "Iteration 30/95: Train Loss = 0.2323, Valid Loss = 0.2687\n",
      "Iteration 31/95: Train Loss = 0.2305, Valid Loss = 0.2679\n",
      "Iteration 32/95: Train Loss = 0.2285, Valid Loss = 0.2662\n",
      "Iteration 33/95: Train Loss = 0.2269, Valid Loss = 0.2651\n",
      "Iteration 34/95: Train Loss = 0.2252, Valid Loss = 0.2637\n",
      "Iteration 35/95: Train Loss = 0.2238, Valid Loss = 0.2623\n",
      "Iteration 36/95: Train Loss = 0.2224, Valid Loss = 0.2609\n",
      "Iteration 37/95: Train Loss = 0.2209, Valid Loss = 0.2600\n",
      "Iteration 38/95: Train Loss = 0.2196, Valid Loss = 0.2593\n",
      "Iteration 39/95: Train Loss = 0.2180, Valid Loss = 0.2584\n",
      "Iteration 40/95: Train Loss = 0.2167, Valid Loss = 0.2581\n",
      "Iteration 41/95: Train Loss = 0.2154, Valid Loss = 0.2575\n",
      "Iteration 42/95: Train Loss = 0.2143, Valid Loss = 0.2568\n",
      "Iteration 43/95: Train Loss = 0.2129, Valid Loss = 0.2556\n",
      "Iteration 44/95: Train Loss = 0.2118, Valid Loss = 0.2550\n",
      "Iteration 45/95: Train Loss = 0.2108, Valid Loss = 0.2543\n",
      "Iteration 46/95: Train Loss = 0.2099, Valid Loss = 0.2537\n",
      "Iteration 47/95: Train Loss = 0.2090, Valid Loss = 0.2535\n",
      "Iteration 48/95: Train Loss = 0.2082, Valid Loss = 0.2532\n",
      "Iteration 49/95: Train Loss = 0.2070, Valid Loss = 0.2526\n",
      "Iteration 50/95: Train Loss = 0.2062, Valid Loss = 0.2524\n",
      "Iteration 51/95: Train Loss = 0.2054, Valid Loss = 0.2519\n",
      "Iteration 52/95: Train Loss = 0.2044, Valid Loss = 0.2511\n",
      "Iteration 53/95: Train Loss = 0.2037, Valid Loss = 0.2508\n",
      "Iteration 54/95: Train Loss = 0.2029, Valid Loss = 0.2501\n",
      "Iteration 55/95: Train Loss = 0.2021, Valid Loss = 0.2495\n",
      "Iteration 56/95: Train Loss = 0.2015, Valid Loss = 0.2492\n",
      "Iteration 57/95: Train Loss = 0.2007, Valid Loss = 0.2487\n",
      "Iteration 58/95: Train Loss = 0.1999, Valid Loss = 0.2483\n",
      "Iteration 59/95: Train Loss = 0.1992, Valid Loss = 0.2482\n",
      "Iteration 60/95: Train Loss = 0.1986, Valid Loss = 0.2479\n",
      "Iteration 61/95: Train Loss = 0.1980, Valid Loss = 0.2477\n",
      "Iteration 62/95: Train Loss = 0.1974, Valid Loss = 0.2475\n",
      "Iteration 63/95: Train Loss = 0.1968, Valid Loss = 0.2471\n",
      "Iteration 64/95: Train Loss = 0.1963, Valid Loss = 0.2469\n",
      "Iteration 65/95: Train Loss = 0.1957, Valid Loss = 0.2470\n",
      "Iteration 66/95: Train Loss = 0.1952, Valid Loss = 0.2470\n",
      "Iteration 67/95: Train Loss = 0.1947, Valid Loss = 0.2466\n",
      "Iteration 68/95: Train Loss = 0.1941, Valid Loss = 0.2466\n",
      "Iteration 69/95: Train Loss = 0.1936, Valid Loss = 0.2466\n",
      "Iteration 70/95: Train Loss = 0.1931, Valid Loss = 0.2466\n",
      "Iteration 71/95: Train Loss = 0.1926, Valid Loss = 0.2461\n",
      "Iteration 72/95: Train Loss = 0.1922, Valid Loss = 0.2459\n",
      "Iteration 73/95: Train Loss = 0.1918, Valid Loss = 0.2458\n",
      "Iteration 74/95: Train Loss = 0.1913, Valid Loss = 0.2456\n",
      "Iteration 75/95: Train Loss = 0.1909, Valid Loss = 0.2457\n",
      "Iteration 76/95: Train Loss = 0.1902, Valid Loss = 0.2459\n",
      "Iteration 77/95: Train Loss = 0.1897, Valid Loss = 0.2457\n",
      "Iteration 78/95: Train Loss = 0.1890, Valid Loss = 0.2457\n",
      "Iteration 79/95: Train Loss = 0.1887, Valid Loss = 0.2455\n",
      "Iteration 80/95: Train Loss = 0.1884, Valid Loss = 0.2454\n",
      "Iteration 81/95: Train Loss = 0.1877, Valid Loss = 0.2454\n",
      "Iteration 82/95: Train Loss = 0.1872, Valid Loss = 0.2452\n",
      "Iteration 83/95: Train Loss = 0.1867, Valid Loss = 0.2451\n",
      "Iteration 84/95: Train Loss = 0.1863, Valid Loss = 0.2452\n",
      "Iteration 85/95: Train Loss = 0.1860, Valid Loss = 0.2448\n",
      "Iteration 86/95: Train Loss = 0.1856, Valid Loss = 0.2445\n",
      "Iteration 87/95: Train Loss = 0.1853, Valid Loss = 0.2442\n",
      "Iteration 88/95: Train Loss = 0.1848, Valid Loss = 0.2441\n",
      "Iteration 89/95: Train Loss = 0.1846, Valid Loss = 0.2439\n",
      "Iteration 90/95: Train Loss = 0.1843, Valid Loss = 0.2435\n",
      "Iteration 91/95: Train Loss = 0.1839, Valid Loss = 0.2435\n",
      "Iteration 92/95: Train Loss = 0.1836, Valid Loss = 0.2436\n",
      "Iteration 93/95: Train Loss = 0.1833, Valid Loss = 0.2435\n",
      "Iteration 94/95: Train Loss = 0.1828, Valid Loss = 0.2437\n",
      "Iteration 95/95: Train Loss = 0.1825, Valid Loss = 0.2433\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-05 00:50:31,002] Trial 20 finished with value: 0.964221848560066 and parameters: {'max_depth': 8, 'min_samples_leaf': 15, 'n_estimators': 95, 'learning_rate': 0.5311993294957216, 'subsample': 0.8107743656887347}. Best is trial 6 with value: 0.965235693124235.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1/100: Train Loss = 0.6131, Valid Loss = 0.6158\n",
      "Iteration 2/100: Train Loss = 0.5509, Valid Loss = 0.5561\n",
      "Iteration 3/100: Train Loss = 0.5021, Valid Loss = 0.5086\n",
      "Iteration 4/100: Train Loss = 0.4636, Valid Loss = 0.4720\n",
      "Iteration 5/100: Train Loss = 0.4326, Valid Loss = 0.4419\n",
      "Iteration 6/100: Train Loss = 0.4075, Valid Loss = 0.4181\n",
      "Iteration 7/100: Train Loss = 0.3871, Valid Loss = 0.3981\n",
      "Iteration 8/100: Train Loss = 0.3700, Valid Loss = 0.3819\n",
      "Iteration 9/100: Train Loss = 0.3554, Valid Loss = 0.3683\n",
      "Iteration 10/100: Train Loss = 0.3430, Valid Loss = 0.3569\n",
      "Iteration 11/100: Train Loss = 0.3318, Valid Loss = 0.3464\n",
      "Iteration 12/100: Train Loss = 0.3222, Valid Loss = 0.3374\n",
      "Iteration 13/100: Train Loss = 0.3136, Valid Loss = 0.3297\n",
      "Iteration 14/100: Train Loss = 0.3060, Valid Loss = 0.3231\n",
      "Iteration 15/100: Train Loss = 0.2992, Valid Loss = 0.3178\n",
      "Iteration 16/100: Train Loss = 0.2931, Valid Loss = 0.3122\n",
      "Iteration 17/100: Train Loss = 0.2878, Valid Loss = 0.3071\n",
      "Iteration 18/100: Train Loss = 0.2831, Valid Loss = 0.3027\n",
      "Iteration 19/100: Train Loss = 0.2783, Valid Loss = 0.2985\n",
      "Iteration 20/100: Train Loss = 0.2742, Valid Loss = 0.2947\n",
      "Iteration 21/100: Train Loss = 0.2702, Valid Loss = 0.2908\n",
      "Iteration 22/100: Train Loss = 0.2667, Valid Loss = 0.2879\n",
      "Iteration 23/100: Train Loss = 0.2636, Valid Loss = 0.2853\n",
      "Iteration 24/100: Train Loss = 0.2608, Valid Loss = 0.2828\n",
      "Iteration 25/100: Train Loss = 0.2577, Valid Loss = 0.2809\n",
      "Iteration 26/100: Train Loss = 0.2548, Valid Loss = 0.2787\n",
      "Iteration 27/100: Train Loss = 0.2521, Valid Loss = 0.2767\n",
      "Iteration 28/100: Train Loss = 0.2496, Valid Loss = 0.2746\n",
      "Iteration 29/100: Train Loss = 0.2476, Valid Loss = 0.2734\n",
      "Iteration 30/100: Train Loss = 0.2455, Valid Loss = 0.2719\n",
      "Iteration 31/100: Train Loss = 0.2433, Valid Loss = 0.2705\n",
      "Iteration 32/100: Train Loss = 0.2413, Valid Loss = 0.2690\n",
      "Iteration 33/100: Train Loss = 0.2393, Valid Loss = 0.2674\n",
      "Iteration 34/100: Train Loss = 0.2377, Valid Loss = 0.2660\n",
      "Iteration 35/100: Train Loss = 0.2359, Valid Loss = 0.2649\n",
      "Iteration 36/100: Train Loss = 0.2343, Valid Loss = 0.2642\n",
      "Iteration 37/100: Train Loss = 0.2328, Valid Loss = 0.2631\n",
      "Iteration 38/100: Train Loss = 0.2314, Valid Loss = 0.2618\n",
      "Iteration 39/100: Train Loss = 0.2300, Valid Loss = 0.2612\n",
      "Iteration 40/100: Train Loss = 0.2285, Valid Loss = 0.2604\n",
      "Iteration 41/100: Train Loss = 0.2274, Valid Loss = 0.2598\n",
      "Iteration 42/100: Train Loss = 0.2260, Valid Loss = 0.2593\n",
      "Iteration 43/100: Train Loss = 0.2248, Valid Loss = 0.2582\n",
      "Iteration 44/100: Train Loss = 0.2238, Valid Loss = 0.2571\n",
      "Iteration 45/100: Train Loss = 0.2226, Valid Loss = 0.2564\n",
      "Iteration 46/100: Train Loss = 0.2216, Valid Loss = 0.2553\n",
      "Iteration 47/100: Train Loss = 0.2206, Valid Loss = 0.2548\n",
      "Iteration 48/100: Train Loss = 0.2195, Valid Loss = 0.2542\n",
      "Iteration 49/100: Train Loss = 0.2186, Valid Loss = 0.2538\n",
      "Iteration 50/100: Train Loss = 0.2177, Valid Loss = 0.2532\n",
      "Iteration 51/100: Train Loss = 0.2168, Valid Loss = 0.2526\n",
      "Iteration 52/100: Train Loss = 0.2160, Valid Loss = 0.2519\n",
      "Iteration 53/100: Train Loss = 0.2152, Valid Loss = 0.2511\n",
      "Iteration 54/100: Train Loss = 0.2145, Valid Loss = 0.2508\n",
      "Iteration 55/100: Train Loss = 0.2138, Valid Loss = 0.2502\n",
      "Iteration 56/100: Train Loss = 0.2132, Valid Loss = 0.2498\n",
      "Iteration 57/100: Train Loss = 0.2123, Valid Loss = 0.2497\n",
      "Iteration 58/100: Train Loss = 0.2114, Valid Loss = 0.2491\n",
      "Iteration 59/100: Train Loss = 0.2107, Valid Loss = 0.2488\n",
      "Iteration 60/100: Train Loss = 0.2101, Valid Loss = 0.2484\n",
      "Iteration 61/100: Train Loss = 0.2095, Valid Loss = 0.2481\n",
      "Iteration 62/100: Train Loss = 0.2089, Valid Loss = 0.2477\n",
      "Iteration 63/100: Train Loss = 0.2082, Valid Loss = 0.2472\n",
      "Iteration 64/100: Train Loss = 0.2075, Valid Loss = 0.2472\n",
      "Iteration 65/100: Train Loss = 0.2070, Valid Loss = 0.2467\n",
      "Iteration 66/100: Train Loss = 0.2065, Valid Loss = 0.2463\n",
      "Iteration 67/100: Train Loss = 0.2059, Valid Loss = 0.2462\n",
      "Iteration 68/100: Train Loss = 0.2052, Valid Loss = 0.2462\n",
      "Iteration 69/100: Train Loss = 0.2047, Valid Loss = 0.2460\n",
      "Iteration 70/100: Train Loss = 0.2041, Valid Loss = 0.2458\n",
      "Iteration 71/100: Train Loss = 0.2033, Valid Loss = 0.2456\n",
      "Iteration 72/100: Train Loss = 0.2030, Valid Loss = 0.2454\n",
      "Iteration 73/100: Train Loss = 0.2022, Valid Loss = 0.2450\n",
      "Iteration 74/100: Train Loss = 0.2019, Valid Loss = 0.2448\n",
      "Iteration 75/100: Train Loss = 0.2014, Valid Loss = 0.2445\n",
      "Iteration 76/100: Train Loss = 0.2010, Valid Loss = 0.2443\n",
      "Iteration 77/100: Train Loss = 0.2005, Valid Loss = 0.2440\n",
      "Iteration 78/100: Train Loss = 0.2002, Valid Loss = 0.2439\n",
      "Iteration 79/100: Train Loss = 0.1998, Valid Loss = 0.2437\n",
      "Iteration 80/100: Train Loss = 0.1994, Valid Loss = 0.2435\n",
      "Iteration 81/100: Train Loss = 0.1988, Valid Loss = 0.2433\n",
      "Iteration 82/100: Train Loss = 0.1983, Valid Loss = 0.2433\n",
      "Iteration 83/100: Train Loss = 0.1979, Valid Loss = 0.2432\n",
      "Iteration 84/100: Train Loss = 0.1973, Valid Loss = 0.2433\n",
      "Iteration 85/100: Train Loss = 0.1970, Valid Loss = 0.2432\n",
      "Iteration 86/100: Train Loss = 0.1966, Valid Loss = 0.2431\n",
      "Iteration 87/100: Train Loss = 0.1962, Valid Loss = 0.2428\n",
      "Iteration 88/100: Train Loss = 0.1959, Valid Loss = 0.2427\n",
      "Iteration 89/100: Train Loss = 0.1955, Valid Loss = 0.2427\n",
      "Iteration 90/100: Train Loss = 0.1951, Valid Loss = 0.2428\n",
      "Iteration 91/100: Train Loss = 0.1947, Valid Loss = 0.2429\n",
      "Iteration 92/100: Train Loss = 0.1943, Valid Loss = 0.2430\n",
      "Iteration 93/100: Train Loss = 0.1940, Valid Loss = 0.2425\n",
      "Iteration 94/100: Train Loss = 0.1937, Valid Loss = 0.2425\n",
      "Iteration 95/100: Train Loss = 0.1931, Valid Loss = 0.2427\n",
      "Iteration 96/100: Train Loss = 0.1928, Valid Loss = 0.2423\n",
      "Iteration 97/100: Train Loss = 0.1924, Valid Loss = 0.2421\n",
      "Iteration 98/100: Train Loss = 0.1921, Valid Loss = 0.2421\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-05 00:50:36,418] Trial 21 finished with value: 0.9643625438004493 and parameters: {'max_depth': 7, 'min_samples_leaf': 15, 'n_estimators': 100, 'learning_rate': 0.5035215960203637, 'subsample': 0.7817570489669037}. Best is trial 6 with value: 0.965235693124235.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 99/100: Train Loss = 0.1919, Valid Loss = 0.2418\n",
      "Iteration 100/100: Train Loss = 0.1915, Valid Loss = 0.2416\n",
      "Iteration 1/125: Train Loss = 0.6689, Valid Loss = 0.6696\n",
      "Iteration 2/125: Train Loss = 0.6467, Valid Loss = 0.6478\n",
      "Iteration 3/125: Train Loss = 0.6257, Valid Loss = 0.6274\n",
      "Iteration 4/125: Train Loss = 0.6064, Valid Loss = 0.6087\n",
      "Iteration 5/125: Train Loss = 0.5882, Valid Loss = 0.5908\n",
      "Iteration 6/125: Train Loss = 0.5713, Valid Loss = 0.5742\n",
      "Iteration 7/125: Train Loss = 0.5555, Valid Loss = 0.5587\n",
      "Iteration 8/125: Train Loss = 0.5406, Valid Loss = 0.5443\n",
      "Iteration 9/125: Train Loss = 0.5267, Valid Loss = 0.5307\n",
      "Iteration 10/125: Train Loss = 0.5139, Valid Loss = 0.5184\n",
      "Iteration 11/125: Train Loss = 0.5016, Valid Loss = 0.5065\n",
      "Iteration 12/125: Train Loss = 0.4903, Valid Loss = 0.4958\n",
      "Iteration 13/125: Train Loss = 0.4795, Valid Loss = 0.4852\n",
      "Iteration 14/125: Train Loss = 0.4695, Valid Loss = 0.4755\n",
      "Iteration 15/125: Train Loss = 0.4602, Valid Loss = 0.4663\n",
      "Iteration 16/125: Train Loss = 0.4513, Valid Loss = 0.4577\n",
      "Iteration 17/125: Train Loss = 0.4430, Valid Loss = 0.4499\n",
      "Iteration 18/125: Train Loss = 0.4350, Valid Loss = 0.4424\n",
      "Iteration 19/125: Train Loss = 0.4274, Valid Loss = 0.4352\n",
      "Iteration 20/125: Train Loss = 0.4203, Valid Loss = 0.4284\n",
      "Iteration 21/125: Train Loss = 0.4137, Valid Loss = 0.4221\n",
      "Iteration 22/125: Train Loss = 0.4073, Valid Loss = 0.4162\n",
      "Iteration 23/125: Train Loss = 0.4012, Valid Loss = 0.4104\n",
      "Iteration 24/125: Train Loss = 0.3955, Valid Loss = 0.4047\n",
      "Iteration 25/125: Train Loss = 0.3900, Valid Loss = 0.3995\n",
      "Iteration 26/125: Train Loss = 0.3850, Valid Loss = 0.3945\n",
      "Iteration 27/125: Train Loss = 0.3800, Valid Loss = 0.3895\n",
      "Iteration 28/125: Train Loss = 0.3751, Valid Loss = 0.3852\n",
      "Iteration 29/125: Train Loss = 0.3705, Valid Loss = 0.3810\n",
      "Iteration 30/125: Train Loss = 0.3662, Valid Loss = 0.3769\n",
      "Iteration 31/125: Train Loss = 0.3621, Valid Loss = 0.3732\n",
      "Iteration 32/125: Train Loss = 0.3579, Valid Loss = 0.3695\n",
      "Iteration 33/125: Train Loss = 0.3541, Valid Loss = 0.3661\n",
      "Iteration 34/125: Train Loss = 0.3505, Valid Loss = 0.3625\n",
      "Iteration 35/125: Train Loss = 0.3469, Valid Loss = 0.3594\n",
      "Iteration 36/125: Train Loss = 0.3436, Valid Loss = 0.3563\n",
      "Iteration 37/125: Train Loss = 0.3404, Valid Loss = 0.3532\n",
      "Iteration 38/125: Train Loss = 0.3373, Valid Loss = 0.3505\n",
      "Iteration 39/125: Train Loss = 0.3344, Valid Loss = 0.3477\n",
      "Iteration 40/125: Train Loss = 0.3315, Valid Loss = 0.3450\n",
      "Iteration 41/125: Train Loss = 0.3288, Valid Loss = 0.3425\n",
      "Iteration 42/125: Train Loss = 0.3261, Valid Loss = 0.3402\n",
      "Iteration 43/125: Train Loss = 0.3236, Valid Loss = 0.3378\n",
      "Iteration 44/125: Train Loss = 0.3211, Valid Loss = 0.3355\n",
      "Iteration 45/125: Train Loss = 0.3188, Valid Loss = 0.3334\n",
      "Iteration 46/125: Train Loss = 0.3164, Valid Loss = 0.3313\n",
      "Iteration 47/125: Train Loss = 0.3142, Valid Loss = 0.3294\n",
      "Iteration 48/125: Train Loss = 0.3121, Valid Loss = 0.3274\n",
      "Iteration 49/125: Train Loss = 0.3100, Valid Loss = 0.3256\n",
      "Iteration 50/125: Train Loss = 0.3078, Valid Loss = 0.3238\n",
      "Iteration 51/125: Train Loss = 0.3058, Valid Loss = 0.3220\n",
      "Iteration 52/125: Train Loss = 0.3038, Valid Loss = 0.3202\n",
      "Iteration 53/125: Train Loss = 0.3019, Valid Loss = 0.3185\n",
      "Iteration 54/125: Train Loss = 0.3001, Valid Loss = 0.3169\n",
      "Iteration 55/125: Train Loss = 0.2984, Valid Loss = 0.3153\n",
      "Iteration 56/125: Train Loss = 0.2966, Valid Loss = 0.3138\n",
      "Iteration 57/125: Train Loss = 0.2949, Valid Loss = 0.3124\n",
      "Iteration 58/125: Train Loss = 0.2932, Valid Loss = 0.3109\n",
      "Iteration 59/125: Train Loss = 0.2915, Valid Loss = 0.3095\n",
      "Iteration 60/125: Train Loss = 0.2899, Valid Loss = 0.3083\n",
      "Iteration 61/125: Train Loss = 0.2884, Valid Loss = 0.3072\n",
      "Iteration 62/125: Train Loss = 0.2870, Valid Loss = 0.3060\n",
      "Iteration 63/125: Train Loss = 0.2855, Valid Loss = 0.3046\n",
      "Iteration 64/125: Train Loss = 0.2842, Valid Loss = 0.3034\n",
      "Iteration 65/125: Train Loss = 0.2828, Valid Loss = 0.3022\n",
      "Iteration 66/125: Train Loss = 0.2814, Valid Loss = 0.3010\n",
      "Iteration 67/125: Train Loss = 0.2801, Valid Loss = 0.3000\n",
      "Iteration 68/125: Train Loss = 0.2789, Valid Loss = 0.2989\n",
      "Iteration 69/125: Train Loss = 0.2777, Valid Loss = 0.2978\n",
      "Iteration 70/125: Train Loss = 0.2765, Valid Loss = 0.2969\n",
      "Iteration 71/125: Train Loss = 0.2753, Valid Loss = 0.2958\n",
      "Iteration 72/125: Train Loss = 0.2742, Valid Loss = 0.2949\n",
      "Iteration 73/125: Train Loss = 0.2731, Valid Loss = 0.2939\n",
      "Iteration 74/125: Train Loss = 0.2720, Valid Loss = 0.2931\n",
      "Iteration 75/125: Train Loss = 0.2708, Valid Loss = 0.2921\n",
      "Iteration 76/125: Train Loss = 0.2698, Valid Loss = 0.2911\n",
      "Iteration 77/125: Train Loss = 0.2687, Valid Loss = 0.2900\n",
      "Iteration 78/125: Train Loss = 0.2677, Valid Loss = 0.2892\n",
      "Iteration 79/125: Train Loss = 0.2668, Valid Loss = 0.2883\n",
      "Iteration 80/125: Train Loss = 0.2659, Valid Loss = 0.2877\n",
      "Iteration 81/125: Train Loss = 0.2649, Valid Loss = 0.2870\n",
      "Iteration 82/125: Train Loss = 0.2641, Valid Loss = 0.2862\n",
      "Iteration 83/125: Train Loss = 0.2632, Valid Loss = 0.2855\n",
      "Iteration 84/125: Train Loss = 0.2624, Valid Loss = 0.2848\n",
      "Iteration 85/125: Train Loss = 0.2616, Valid Loss = 0.2840\n",
      "Iteration 86/125: Train Loss = 0.2606, Valid Loss = 0.2832\n",
      "Iteration 87/125: Train Loss = 0.2599, Valid Loss = 0.2826\n",
      "Iteration 88/125: Train Loss = 0.2591, Valid Loss = 0.2819\n",
      "Iteration 89/125: Train Loss = 0.2582, Valid Loss = 0.2812\n",
      "Iteration 90/125: Train Loss = 0.2575, Valid Loss = 0.2806\n",
      "Iteration 91/125: Train Loss = 0.2567, Valid Loss = 0.2800\n",
      "Iteration 92/125: Train Loss = 0.2560, Valid Loss = 0.2794\n",
      "Iteration 93/125: Train Loss = 0.2553, Valid Loss = 0.2787\n",
      "Iteration 94/125: Train Loss = 0.2545, Valid Loss = 0.2782\n",
      "Iteration 95/125: Train Loss = 0.2538, Valid Loss = 0.2776\n",
      "Iteration 96/125: Train Loss = 0.2531, Valid Loss = 0.2770\n",
      "Iteration 97/125: Train Loss = 0.2524, Valid Loss = 0.2764\n",
      "Iteration 98/125: Train Loss = 0.2516, Valid Loss = 0.2758\n",
      "Iteration 99/125: Train Loss = 0.2509, Valid Loss = 0.2753\n",
      "Iteration 100/125: Train Loss = 0.2501, Valid Loss = 0.2748\n",
      "Iteration 101/125: Train Loss = 0.2496, Valid Loss = 0.2744\n",
      "Iteration 102/125: Train Loss = 0.2490, Valid Loss = 0.2739\n",
      "Iteration 103/125: Train Loss = 0.2484, Valid Loss = 0.2734\n",
      "Iteration 104/125: Train Loss = 0.2478, Valid Loss = 0.2731\n",
      "Iteration 105/125: Train Loss = 0.2471, Valid Loss = 0.2727\n",
      "Iteration 106/125: Train Loss = 0.2466, Valid Loss = 0.2723\n",
      "Iteration 107/125: Train Loss = 0.2460, Valid Loss = 0.2718\n",
      "Iteration 108/125: Train Loss = 0.2455, Valid Loss = 0.2713\n",
      "Iteration 109/125: Train Loss = 0.2449, Valid Loss = 0.2707\n",
      "Iteration 110/125: Train Loss = 0.2443, Valid Loss = 0.2703\n",
      "Iteration 111/125: Train Loss = 0.2437, Valid Loss = 0.2698\n",
      "Iteration 112/125: Train Loss = 0.2432, Valid Loss = 0.2693\n",
      "Iteration 113/125: Train Loss = 0.2426, Valid Loss = 0.2689\n",
      "Iteration 114/125: Train Loss = 0.2421, Valid Loss = 0.2685\n",
      "Iteration 115/125: Train Loss = 0.2415, Valid Loss = 0.2681\n",
      "Iteration 116/125: Train Loss = 0.2410, Valid Loss = 0.2678\n",
      "Iteration 117/125: Train Loss = 0.2405, Valid Loss = 0.2675\n",
      "Iteration 118/125: Train Loss = 0.2399, Valid Loss = 0.2671\n",
      "Iteration 119/125: Train Loss = 0.2394, Valid Loss = 0.2668\n",
      "Iteration 120/125: Train Loss = 0.2390, Valid Loss = 0.2664\n",
      "Iteration 121/125: Train Loss = 0.2384, Valid Loss = 0.2660\n",
      "Iteration 122/125: Train Loss = 0.2380, Valid Loss = 0.2656\n",
      "Iteration 123/125: Train Loss = 0.2375, Valid Loss = 0.2653\n",
      "Iteration 124/125: Train Loss = 0.2371, Valid Loss = 0.2648\n",
      "Iteration 125/125: Train Loss = 0.2367, Valid Loss = 0.2644\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-05 00:50:42,695] Trial 22 finished with value: 0.9635035021294929 and parameters: {'max_depth': 7, 'min_samples_leaf': 18, 'n_estimators': 125, 'learning_rate': 0.14488702626990924, 'subsample': 0.6892931138916784}. Best is trial 6 with value: 0.965235693124235.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1/105: Train Loss = 0.6260, Valid Loss = 0.6282\n",
      "Iteration 2/105: Train Loss = 0.5728, Valid Loss = 0.5763\n",
      "Iteration 3/105: Train Loss = 0.5295, Valid Loss = 0.5342\n",
      "Iteration 4/105: Train Loss = 0.4941, Valid Loss = 0.4997\n",
      "Iteration 5/105: Train Loss = 0.4646, Valid Loss = 0.4709\n",
      "Iteration 6/105: Train Loss = 0.4402, Valid Loss = 0.4470\n",
      "Iteration 7/105: Train Loss = 0.4202, Valid Loss = 0.4275\n",
      "Iteration 8/105: Train Loss = 0.4027, Valid Loss = 0.4106\n",
      "Iteration 9/105: Train Loss = 0.3878, Valid Loss = 0.3962\n",
      "Iteration 10/105: Train Loss = 0.3751, Valid Loss = 0.3840\n",
      "Iteration 11/105: Train Loss = 0.3638, Valid Loss = 0.3736\n",
      "Iteration 12/105: Train Loss = 0.3542, Valid Loss = 0.3644\n",
      "Iteration 13/105: Train Loss = 0.3451, Valid Loss = 0.3558\n",
      "Iteration 14/105: Train Loss = 0.3374, Valid Loss = 0.3491\n",
      "Iteration 15/105: Train Loss = 0.3305, Valid Loss = 0.3425\n",
      "Iteration 16/105: Train Loss = 0.3242, Valid Loss = 0.3365\n",
      "Iteration 17/105: Train Loss = 0.3186, Valid Loss = 0.3314\n",
      "Iteration 18/105: Train Loss = 0.3135, Valid Loss = 0.3263\n",
      "Iteration 19/105: Train Loss = 0.3087, Valid Loss = 0.3221\n",
      "Iteration 20/105: Train Loss = 0.3043, Valid Loss = 0.3180\n",
      "Iteration 21/105: Train Loss = 0.3004, Valid Loss = 0.3145\n",
      "Iteration 22/105: Train Loss = 0.2967, Valid Loss = 0.3112\n",
      "Iteration 23/105: Train Loss = 0.2931, Valid Loss = 0.3080\n",
      "Iteration 24/105: Train Loss = 0.2899, Valid Loss = 0.3051\n",
      "Iteration 25/105: Train Loss = 0.2869, Valid Loss = 0.3025\n",
      "Iteration 26/105: Train Loss = 0.2841, Valid Loss = 0.3001\n",
      "Iteration 27/105: Train Loss = 0.2815, Valid Loss = 0.2977\n",
      "Iteration 28/105: Train Loss = 0.2788, Valid Loss = 0.2954\n",
      "Iteration 29/105: Train Loss = 0.2765, Valid Loss = 0.2929\n",
      "Iteration 30/105: Train Loss = 0.2741, Valid Loss = 0.2907\n",
      "Iteration 31/105: Train Loss = 0.2722, Valid Loss = 0.2891\n",
      "Iteration 32/105: Train Loss = 0.2702, Valid Loss = 0.2874\n",
      "Iteration 33/105: Train Loss = 0.2683, Valid Loss = 0.2859\n",
      "Iteration 34/105: Train Loss = 0.2665, Valid Loss = 0.2842\n",
      "Iteration 35/105: Train Loss = 0.2649, Valid Loss = 0.2827\n",
      "Iteration 36/105: Train Loss = 0.2633, Valid Loss = 0.2814\n",
      "Iteration 37/105: Train Loss = 0.2617, Valid Loss = 0.2799\n",
      "Iteration 38/105: Train Loss = 0.2603, Valid Loss = 0.2787\n",
      "Iteration 39/105: Train Loss = 0.2585, Valid Loss = 0.2772\n",
      "Iteration 40/105: Train Loss = 0.2570, Valid Loss = 0.2760\n",
      "Iteration 41/105: Train Loss = 0.2557, Valid Loss = 0.2750\n",
      "Iteration 42/105: Train Loss = 0.2544, Valid Loss = 0.2740\n",
      "Iteration 43/105: Train Loss = 0.2531, Valid Loss = 0.2729\n",
      "Iteration 44/105: Train Loss = 0.2518, Valid Loss = 0.2715\n",
      "Iteration 45/105: Train Loss = 0.2505, Valid Loss = 0.2705\n",
      "Iteration 46/105: Train Loss = 0.2493, Valid Loss = 0.2698\n",
      "Iteration 47/105: Train Loss = 0.2482, Valid Loss = 0.2690\n",
      "Iteration 48/105: Train Loss = 0.2472, Valid Loss = 0.2681\n",
      "Iteration 49/105: Train Loss = 0.2462, Valid Loss = 0.2672\n",
      "Iteration 50/105: Train Loss = 0.2451, Valid Loss = 0.2663\n",
      "Iteration 51/105: Train Loss = 0.2442, Valid Loss = 0.2656\n",
      "Iteration 52/105: Train Loss = 0.2432, Valid Loss = 0.2646\n",
      "Iteration 53/105: Train Loss = 0.2422, Valid Loss = 0.2637\n",
      "Iteration 54/105: Train Loss = 0.2414, Valid Loss = 0.2633\n",
      "Iteration 55/105: Train Loss = 0.2407, Valid Loss = 0.2628\n",
      "Iteration 56/105: Train Loss = 0.2400, Valid Loss = 0.2623\n",
      "Iteration 57/105: Train Loss = 0.2391, Valid Loss = 0.2613\n",
      "Iteration 58/105: Train Loss = 0.2384, Valid Loss = 0.2609\n",
      "Iteration 59/105: Train Loss = 0.2375, Valid Loss = 0.2604\n",
      "Iteration 60/105: Train Loss = 0.2366, Valid Loss = 0.2600\n",
      "Iteration 61/105: Train Loss = 0.2357, Valid Loss = 0.2593\n",
      "Iteration 62/105: Train Loss = 0.2350, Valid Loss = 0.2588\n",
      "Iteration 63/105: Train Loss = 0.2345, Valid Loss = 0.2584\n",
      "Iteration 64/105: Train Loss = 0.2338, Valid Loss = 0.2580\n",
      "Iteration 65/105: Train Loss = 0.2331, Valid Loss = 0.2578\n",
      "Iteration 66/105: Train Loss = 0.2325, Valid Loss = 0.2574\n",
      "Iteration 67/105: Train Loss = 0.2320, Valid Loss = 0.2571\n",
      "Iteration 68/105: Train Loss = 0.2314, Valid Loss = 0.2569\n",
      "Iteration 69/105: Train Loss = 0.2307, Valid Loss = 0.2565\n",
      "Iteration 70/105: Train Loss = 0.2302, Valid Loss = 0.2559\n",
      "Iteration 71/105: Train Loss = 0.2297, Valid Loss = 0.2555\n",
      "Iteration 72/105: Train Loss = 0.2293, Valid Loss = 0.2552\n",
      "Iteration 73/105: Train Loss = 0.2289, Valid Loss = 0.2549\n",
      "Iteration 74/105: Train Loss = 0.2284, Valid Loss = 0.2548\n",
      "Iteration 75/105: Train Loss = 0.2279, Valid Loss = 0.2546\n",
      "Iteration 76/105: Train Loss = 0.2274, Valid Loss = 0.2543\n",
      "Iteration 77/105: Train Loss = 0.2267, Valid Loss = 0.2537\n",
      "Iteration 78/105: Train Loss = 0.2263, Valid Loss = 0.2533\n",
      "Iteration 79/105: Train Loss = 0.2259, Valid Loss = 0.2532\n",
      "Iteration 80/105: Train Loss = 0.2255, Valid Loss = 0.2527\n",
      "Iteration 81/105: Train Loss = 0.2250, Valid Loss = 0.2524\n",
      "Iteration 82/105: Train Loss = 0.2245, Valid Loss = 0.2520\n",
      "Iteration 83/105: Train Loss = 0.2238, Valid Loss = 0.2516\n",
      "Iteration 84/105: Train Loss = 0.2233, Valid Loss = 0.2513\n",
      "Iteration 85/105: Train Loss = 0.2229, Valid Loss = 0.2510\n",
      "Iteration 86/105: Train Loss = 0.2224, Valid Loss = 0.2508\n",
      "Iteration 87/105: Train Loss = 0.2220, Valid Loss = 0.2505\n",
      "Iteration 88/105: Train Loss = 0.2217, Valid Loss = 0.2503\n",
      "Iteration 89/105: Train Loss = 0.2212, Valid Loss = 0.2500\n",
      "Iteration 90/105: Train Loss = 0.2208, Valid Loss = 0.2497\n",
      "Iteration 91/105: Train Loss = 0.2204, Valid Loss = 0.2493\n",
      "Iteration 92/105: Train Loss = 0.2200, Valid Loss = 0.2491\n",
      "Iteration 93/105: Train Loss = 0.2196, Valid Loss = 0.2489\n",
      "Iteration 94/105: Train Loss = 0.2192, Valid Loss = 0.2488\n",
      "Iteration 95/105: Train Loss = 0.2188, Valid Loss = 0.2487\n",
      "Iteration 96/105: Train Loss = 0.2184, Valid Loss = 0.2485\n",
      "Iteration 97/105: Train Loss = 0.2181, Valid Loss = 0.2482\n",
      "Iteration 98/105: Train Loss = 0.2178, Valid Loss = 0.2481\n",
      "Iteration 99/105: Train Loss = 0.2174, Valid Loss = 0.2479\n",
      "Iteration 100/105: Train Loss = 0.2170, Valid Loss = 0.2478\n",
      "Iteration 101/105: Train Loss = 0.2168, Valid Loss = 0.2476\n",
      "Iteration 102/105: Train Loss = 0.2166, Valid Loss = 0.2472\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-05 00:50:47,365] Trial 23 finished with value: 0.9639804933103036 and parameters: {'max_depth': 5, 'min_samples_leaf': 17, 'n_estimators': 105, 'learning_rate': 0.44137036864583695, 'subsample': 0.8446220906037643}. Best is trial 6 with value: 0.965235693124235.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 103/105: Train Loss = 0.2162, Valid Loss = 0.2471\n",
      "Iteration 104/105: Train Loss = 0.2159, Valid Loss = 0.2471\n",
      "Iteration 105/105: Train Loss = 0.2155, Valid Loss = 0.2469\n",
      "Iteration 1/80: Train Loss = 0.6124, Valid Loss = 0.6150\n",
      "Iteration 2/80: Train Loss = 0.5497, Valid Loss = 0.5540\n",
      "Iteration 3/80: Train Loss = 0.5014, Valid Loss = 0.5078\n",
      "Iteration 4/80: Train Loss = 0.4630, Valid Loss = 0.4710\n",
      "Iteration 5/80: Train Loss = 0.4316, Valid Loss = 0.4411\n",
      "Iteration 6/80: Train Loss = 0.4059, Valid Loss = 0.4171\n",
      "Iteration 7/80: Train Loss = 0.3850, Valid Loss = 0.3981\n",
      "Iteration 8/80: Train Loss = 0.3673, Valid Loss = 0.3813\n",
      "Iteration 9/80: Train Loss = 0.3525, Valid Loss = 0.3675\n",
      "Iteration 10/80: Train Loss = 0.3397, Valid Loss = 0.3551\n",
      "Iteration 11/80: Train Loss = 0.3284, Valid Loss = 0.3450\n",
      "Iteration 12/80: Train Loss = 0.3187, Valid Loss = 0.3370\n",
      "Iteration 13/80: Train Loss = 0.3104, Valid Loss = 0.3294\n",
      "Iteration 14/80: Train Loss = 0.3031, Valid Loss = 0.3231\n",
      "Iteration 15/80: Train Loss = 0.2961, Valid Loss = 0.3169\n",
      "Iteration 16/80: Train Loss = 0.2900, Valid Loss = 0.3114\n",
      "Iteration 17/80: Train Loss = 0.2843, Valid Loss = 0.3064\n",
      "Iteration 18/80: Train Loss = 0.2793, Valid Loss = 0.3019\n",
      "Iteration 19/80: Train Loss = 0.2749, Valid Loss = 0.2985\n",
      "Iteration 20/80: Train Loss = 0.2706, Valid Loss = 0.2953\n",
      "Iteration 21/80: Train Loss = 0.2670, Valid Loss = 0.2924\n",
      "Iteration 22/80: Train Loss = 0.2635, Valid Loss = 0.2898\n",
      "Iteration 23/80: Train Loss = 0.2603, Valid Loss = 0.2872\n",
      "Iteration 24/80: Train Loss = 0.2573, Valid Loss = 0.2839\n",
      "Iteration 25/80: Train Loss = 0.2544, Valid Loss = 0.2812\n",
      "Iteration 26/80: Train Loss = 0.2517, Valid Loss = 0.2793\n",
      "Iteration 27/80: Train Loss = 0.2491, Valid Loss = 0.2776\n",
      "Iteration 28/80: Train Loss = 0.2469, Valid Loss = 0.2759\n",
      "Iteration 29/80: Train Loss = 0.2448, Valid Loss = 0.2740\n",
      "Iteration 30/80: Train Loss = 0.2425, Valid Loss = 0.2725\n",
      "Iteration 31/80: Train Loss = 0.2403, Valid Loss = 0.2710\n",
      "Iteration 32/80: Train Loss = 0.2381, Valid Loss = 0.2690\n",
      "Iteration 33/80: Train Loss = 0.2363, Valid Loss = 0.2675\n",
      "Iteration 34/80: Train Loss = 0.2342, Valid Loss = 0.2663\n",
      "Iteration 35/80: Train Loss = 0.2327, Valid Loss = 0.2653\n",
      "Iteration 36/80: Train Loss = 0.2311, Valid Loss = 0.2642\n",
      "Iteration 37/80: Train Loss = 0.2293, Valid Loss = 0.2631\n",
      "Iteration 38/80: Train Loss = 0.2276, Valid Loss = 0.2615\n",
      "Iteration 39/80: Train Loss = 0.2263, Valid Loss = 0.2603\n",
      "Iteration 40/80: Train Loss = 0.2248, Valid Loss = 0.2592\n",
      "Iteration 41/80: Train Loss = 0.2236, Valid Loss = 0.2583\n",
      "Iteration 42/80: Train Loss = 0.2224, Valid Loss = 0.2576\n",
      "Iteration 43/80: Train Loss = 0.2214, Valid Loss = 0.2568\n",
      "Iteration 44/80: Train Loss = 0.2203, Valid Loss = 0.2561\n",
      "Iteration 45/80: Train Loss = 0.2193, Valid Loss = 0.2553\n",
      "Iteration 46/80: Train Loss = 0.2183, Valid Loss = 0.2548\n",
      "Iteration 47/80: Train Loss = 0.2174, Valid Loss = 0.2543\n",
      "Iteration 48/80: Train Loss = 0.2163, Valid Loss = 0.2535\n",
      "Iteration 49/80: Train Loss = 0.2154, Valid Loss = 0.2527\n",
      "Iteration 50/80: Train Loss = 0.2145, Valid Loss = 0.2525\n",
      "Iteration 51/80: Train Loss = 0.2134, Valid Loss = 0.2517\n",
      "Iteration 52/80: Train Loss = 0.2125, Valid Loss = 0.2515\n",
      "Iteration 53/80: Train Loss = 0.2117, Valid Loss = 0.2513\n",
      "Iteration 54/80: Train Loss = 0.2107, Valid Loss = 0.2506\n",
      "Iteration 55/80: Train Loss = 0.2098, Valid Loss = 0.2497\n",
      "Iteration 56/80: Train Loss = 0.2091, Valid Loss = 0.2492\n",
      "Iteration 57/80: Train Loss = 0.2083, Valid Loss = 0.2489\n",
      "Iteration 58/80: Train Loss = 0.2076, Valid Loss = 0.2484\n",
      "Iteration 59/80: Train Loss = 0.2069, Valid Loss = 0.2480\n",
      "Iteration 60/80: Train Loss = 0.2060, Valid Loss = 0.2476\n",
      "Iteration 61/80: Train Loss = 0.2054, Valid Loss = 0.2472\n",
      "Iteration 62/80: Train Loss = 0.2048, Valid Loss = 0.2470\n",
      "Iteration 63/80: Train Loss = 0.2043, Valid Loss = 0.2467\n",
      "Iteration 64/80: Train Loss = 0.2035, Valid Loss = 0.2462\n",
      "Iteration 65/80: Train Loss = 0.2030, Valid Loss = 0.2460\n",
      "Iteration 66/80: Train Loss = 0.2023, Valid Loss = 0.2456\n",
      "Iteration 67/80: Train Loss = 0.2017, Valid Loss = 0.2452\n",
      "Iteration 68/80: Train Loss = 0.2012, Valid Loss = 0.2449\n",
      "Iteration 69/80: Train Loss = 0.2007, Valid Loss = 0.2449\n",
      "Iteration 70/80: Train Loss = 0.2002, Valid Loss = 0.2446\n",
      "Iteration 71/80: Train Loss = 0.1995, Valid Loss = 0.2441\n",
      "Iteration 72/80: Train Loss = 0.1990, Valid Loss = 0.2440\n",
      "Iteration 73/80: Train Loss = 0.1986, Valid Loss = 0.2439\n",
      "Iteration 74/80: Train Loss = 0.1980, Valid Loss = 0.2438\n",
      "Iteration 75/80: Train Loss = 0.1974, Valid Loss = 0.2436\n",
      "Iteration 76/80: Train Loss = 0.1969, Valid Loss = 0.2434\n",
      "Iteration 77/80: Train Loss = 0.1965, Valid Loss = 0.2433\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-05 00:50:52,116] Trial 24 finished with value: 0.9648830018034918 and parameters: {'max_depth': 7, 'min_samples_leaf': 12, 'n_estimators': 80, 'learning_rate': 0.5040800946645468, 'subsample': 0.9192881340808673}. Best is trial 6 with value: 0.965235693124235.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 78/80: Train Loss = 0.1961, Valid Loss = 0.2432\n",
      "Iteration 79/80: Train Loss = 0.1957, Valid Loss = 0.2430\n",
      "Iteration 80/80: Train Loss = 0.1953, Valid Loss = 0.2430\n",
      "Iteration 1/50: Train Loss = 0.6602, Valid Loss = 0.6608\n",
      "Iteration 2/50: Train Loss = 0.6306, Valid Loss = 0.6321\n",
      "Iteration 3/50: Train Loss = 0.6041, Valid Loss = 0.6061\n",
      "Iteration 4/50: Train Loss = 0.5802, Valid Loss = 0.5825\n",
      "Iteration 5/50: Train Loss = 0.5589, Valid Loss = 0.5621\n",
      "Iteration 6/50: Train Loss = 0.5394, Valid Loss = 0.5430\n",
      "Iteration 7/50: Train Loss = 0.5220, Valid Loss = 0.5261\n",
      "Iteration 8/50: Train Loss = 0.5061, Valid Loss = 0.5106\n",
      "Iteration 9/50: Train Loss = 0.4912, Valid Loss = 0.4961\n",
      "Iteration 10/50: Train Loss = 0.4775, Valid Loss = 0.4824\n",
      "Iteration 11/50: Train Loss = 0.4653, Valid Loss = 0.4706\n",
      "Iteration 12/50: Train Loss = 0.4542, Valid Loss = 0.4600\n",
      "Iteration 13/50: Train Loss = 0.4439, Valid Loss = 0.4499\n",
      "Iteration 14/50: Train Loss = 0.4344, Valid Loss = 0.4406\n",
      "Iteration 15/50: Train Loss = 0.4254, Valid Loss = 0.4319\n",
      "Iteration 16/50: Train Loss = 0.4175, Valid Loss = 0.4241\n",
      "Iteration 17/50: Train Loss = 0.4100, Valid Loss = 0.4170\n",
      "Iteration 18/50: Train Loss = 0.4031, Valid Loss = 0.4101\n",
      "Iteration 19/50: Train Loss = 0.3964, Valid Loss = 0.4034\n",
      "Iteration 20/50: Train Loss = 0.3903, Valid Loss = 0.3976\n",
      "Iteration 21/50: Train Loss = 0.3846, Valid Loss = 0.3922\n",
      "Iteration 22/50: Train Loss = 0.3793, Valid Loss = 0.3872\n",
      "Iteration 23/50: Train Loss = 0.3745, Valid Loss = 0.3825\n",
      "Iteration 24/50: Train Loss = 0.3696, Valid Loss = 0.3778\n",
      "Iteration 25/50: Train Loss = 0.3652, Valid Loss = 0.3737\n",
      "Iteration 26/50: Train Loss = 0.3608, Valid Loss = 0.3693\n",
      "Iteration 27/50: Train Loss = 0.3569, Valid Loss = 0.3656\n",
      "Iteration 28/50: Train Loss = 0.3532, Valid Loss = 0.3620\n",
      "Iteration 29/50: Train Loss = 0.3496, Valid Loss = 0.3585\n",
      "Iteration 30/50: Train Loss = 0.3462, Valid Loss = 0.3551\n",
      "Iteration 31/50: Train Loss = 0.3430, Valid Loss = 0.3521\n",
      "Iteration 32/50: Train Loss = 0.3399, Valid Loss = 0.3491\n",
      "Iteration 33/50: Train Loss = 0.3370, Valid Loss = 0.3462\n",
      "Iteration 34/50: Train Loss = 0.3342, Valid Loss = 0.3435\n",
      "Iteration 35/50: Train Loss = 0.3316, Valid Loss = 0.3411\n",
      "Iteration 36/50: Train Loss = 0.3291, Valid Loss = 0.3388\n",
      "Iteration 37/50: Train Loss = 0.3267, Valid Loss = 0.3364\n",
      "Iteration 38/50: Train Loss = 0.3243, Valid Loss = 0.3342\n",
      "Iteration 39/50: Train Loss = 0.3222, Valid Loss = 0.3323\n",
      "Iteration 40/50: Train Loss = 0.3200, Valid Loss = 0.3303\n",
      "Iteration 41/50: Train Loss = 0.3179, Valid Loss = 0.3284\n",
      "Iteration 42/50: Train Loss = 0.3159, Valid Loss = 0.3264\n",
      "Iteration 43/50: Train Loss = 0.3140, Valid Loss = 0.3244\n",
      "Iteration 44/50: Train Loss = 0.3122, Valid Loss = 0.3229\n",
      "Iteration 45/50: Train Loss = 0.3103, Valid Loss = 0.3213\n",
      "Iteration 46/50: Train Loss = 0.3084, Valid Loss = 0.3195\n",
      "Iteration 47/50: Train Loss = 0.3068, Valid Loss = 0.3180\n",
      "Iteration 48/50: Train Loss = 0.3052, Valid Loss = 0.3167\n",
      "Iteration 49/50: Train Loss = 0.3037, Valid Loss = 0.3152\n",
      "Iteration 50/50: Train Loss = 0.3021, Valid Loss = 0.3136\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-05 00:50:53,959] Trial 25 finished with value: 0.9540895035250069 and parameters: {'max_depth': 4, 'min_samples_leaf': 12, 'n_estimators': 50, 'learning_rate': 0.22090927257459447, 'subsample': 0.9324820018344014}. Best is trial 6 with value: 0.965235693124235.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1/80: Train Loss = 0.6783, Valid Loss = 0.6789\n",
      "Iteration 2/80: Train Loss = 0.6641, Valid Loss = 0.6652\n",
      "Iteration 3/80: Train Loss = 0.6503, Valid Loss = 0.6521\n",
      "Iteration 4/80: Train Loss = 0.6373, Valid Loss = 0.6398\n",
      "Iteration 5/80: Train Loss = 0.6247, Valid Loss = 0.6277\n",
      "Iteration 6/80: Train Loss = 0.6126, Valid Loss = 0.6161\n",
      "Iteration 7/80: Train Loss = 0.6009, Valid Loss = 0.6052\n",
      "Iteration 8/80: Train Loss = 0.5896, Valid Loss = 0.5944\n",
      "Iteration 9/80: Train Loss = 0.5788, Valid Loss = 0.5841\n",
      "Iteration 10/80: Train Loss = 0.5684, Valid Loss = 0.5743\n",
      "Iteration 11/80: Train Loss = 0.5585, Valid Loss = 0.5648\n",
      "Iteration 12/80: Train Loss = 0.5489, Valid Loss = 0.5559\n",
      "Iteration 13/80: Train Loss = 0.5398, Valid Loss = 0.5472\n",
      "Iteration 14/80: Train Loss = 0.5309, Valid Loss = 0.5390\n",
      "Iteration 15/80: Train Loss = 0.5224, Valid Loss = 0.5308\n",
      "Iteration 16/80: Train Loss = 0.5144, Valid Loss = 0.5232\n",
      "Iteration 17/80: Train Loss = 0.5065, Valid Loss = 0.5157\n",
      "Iteration 18/80: Train Loss = 0.4987, Valid Loss = 0.5085\n",
      "Iteration 19/80: Train Loss = 0.4914, Valid Loss = 0.5016\n",
      "Iteration 20/80: Train Loss = 0.4844, Valid Loss = 0.4948\n",
      "Iteration 21/80: Train Loss = 0.4775, Valid Loss = 0.4882\n",
      "Iteration 22/80: Train Loss = 0.4709, Valid Loss = 0.4820\n",
      "Iteration 23/80: Train Loss = 0.4645, Valid Loss = 0.4761\n",
      "Iteration 24/80: Train Loss = 0.4584, Valid Loss = 0.4704\n",
      "Iteration 25/80: Train Loss = 0.4524, Valid Loss = 0.4649\n",
      "Iteration 26/80: Train Loss = 0.4467, Valid Loss = 0.4596\n",
      "Iteration 27/80: Train Loss = 0.4411, Valid Loss = 0.4545\n",
      "Iteration 28/80: Train Loss = 0.4358, Valid Loss = 0.4495\n",
      "Iteration 29/80: Train Loss = 0.4305, Valid Loss = 0.4446\n",
      "Iteration 30/80: Train Loss = 0.4255, Valid Loss = 0.4401\n",
      "Iteration 31/80: Train Loss = 0.4208, Valid Loss = 0.4356\n",
      "Iteration 32/80: Train Loss = 0.4161, Valid Loss = 0.4313\n",
      "Iteration 33/80: Train Loss = 0.4114, Valid Loss = 0.4271\n",
      "Iteration 34/80: Train Loss = 0.4071, Valid Loss = 0.4231\n",
      "Iteration 35/80: Train Loss = 0.4029, Valid Loss = 0.4193\n",
      "Iteration 36/80: Train Loss = 0.3988, Valid Loss = 0.4156\n",
      "Iteration 37/80: Train Loss = 0.3947, Valid Loss = 0.4118\n",
      "Iteration 38/80: Train Loss = 0.3908, Valid Loss = 0.4082\n",
      "Iteration 39/80: Train Loss = 0.3869, Valid Loss = 0.4047\n",
      "Iteration 40/80: Train Loss = 0.3832, Valid Loss = 0.4014\n",
      "Iteration 41/80: Train Loss = 0.3796, Valid Loss = 0.3982\n",
      "Iteration 42/80: Train Loss = 0.3762, Valid Loss = 0.3951\n",
      "Iteration 43/80: Train Loss = 0.3728, Valid Loss = 0.3921\n",
      "Iteration 44/80: Train Loss = 0.3696, Valid Loss = 0.3891\n",
      "Iteration 45/80: Train Loss = 0.3663, Valid Loss = 0.3862\n",
      "Iteration 46/80: Train Loss = 0.3631, Valid Loss = 0.3833\n",
      "Iteration 47/80: Train Loss = 0.3600, Valid Loss = 0.3805\n",
      "Iteration 48/80: Train Loss = 0.3570, Valid Loss = 0.3779\n",
      "Iteration 49/80: Train Loss = 0.3541, Valid Loss = 0.3754\n",
      "Iteration 50/80: Train Loss = 0.3512, Valid Loss = 0.3727\n",
      "Iteration 51/80: Train Loss = 0.3485, Valid Loss = 0.3702\n",
      "Iteration 52/80: Train Loss = 0.3458, Valid Loss = 0.3679\n",
      "Iteration 53/80: Train Loss = 0.3432, Valid Loss = 0.3656\n",
      "Iteration 54/80: Train Loss = 0.3406, Valid Loss = 0.3634\n",
      "Iteration 55/80: Train Loss = 0.3380, Valid Loss = 0.3612\n",
      "Iteration 56/80: Train Loss = 0.3357, Valid Loss = 0.3590\n",
      "Iteration 57/80: Train Loss = 0.3333, Valid Loss = 0.3569\n",
      "Iteration 58/80: Train Loss = 0.3309, Valid Loss = 0.3548\n",
      "Iteration 59/80: Train Loss = 0.3287, Valid Loss = 0.3528\n",
      "Iteration 60/80: Train Loss = 0.3266, Valid Loss = 0.3508\n",
      "Iteration 61/80: Train Loss = 0.3244, Valid Loss = 0.3490\n",
      "Iteration 62/80: Train Loss = 0.3224, Valid Loss = 0.3472\n",
      "Iteration 63/80: Train Loss = 0.3203, Valid Loss = 0.3454\n",
      "Iteration 64/80: Train Loss = 0.3183, Valid Loss = 0.3437\n",
      "Iteration 65/80: Train Loss = 0.3164, Valid Loss = 0.3420\n",
      "Iteration 66/80: Train Loss = 0.3144, Valid Loss = 0.3403\n",
      "Iteration 67/80: Train Loss = 0.3125, Valid Loss = 0.3387\n",
      "Iteration 68/80: Train Loss = 0.3105, Valid Loss = 0.3372\n",
      "Iteration 69/80: Train Loss = 0.3087, Valid Loss = 0.3357\n",
      "Iteration 70/80: Train Loss = 0.3069, Valid Loss = 0.3341\n",
      "Iteration 71/80: Train Loss = 0.3052, Valid Loss = 0.3326\n",
      "Iteration 72/80: Train Loss = 0.3036, Valid Loss = 0.3312\n",
      "Iteration 73/80: Train Loss = 0.3018, Valid Loss = 0.3300\n",
      "Iteration 74/80: Train Loss = 0.3002, Valid Loss = 0.3286\n",
      "Iteration 75/80: Train Loss = 0.2987, Valid Loss = 0.3273\n",
      "Iteration 76/80: Train Loss = 0.2972, Valid Loss = 0.3261\n",
      "Iteration 77/80: Train Loss = 0.2956, Valid Loss = 0.3248\n",
      "Iteration 78/80: Train Loss = 0.2941, Valid Loss = 0.3235\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-05 00:51:00,989] Trial 26 finished with value: 0.962779436380205 and parameters: {'max_depth': 9, 'min_samples_leaf': 7, 'n_estimators': 80, 'learning_rate': 0.08388246627370188, 'subsample': 0.9121250729123646}. Best is trial 6 with value: 0.965235693124235.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 79/80: Train Loss = 0.2926, Valid Loss = 0.3224\n",
      "Iteration 80/80: Train Loss = 0.2911, Valid Loss = 0.3212\n",
      "Iteration 1/140: Train Loss = 0.6404, Valid Loss = 0.6423\n",
      "Iteration 2/140: Train Loss = 0.5957, Valid Loss = 0.5992\n",
      "Iteration 3/140: Train Loss = 0.5576, Valid Loss = 0.5622\n",
      "Iteration 4/140: Train Loss = 0.5248, Valid Loss = 0.5299\n",
      "Iteration 5/140: Train Loss = 0.4967, Valid Loss = 0.5024\n",
      "Iteration 6/140: Train Loss = 0.4720, Valid Loss = 0.4786\n",
      "Iteration 7/140: Train Loss = 0.4505, Valid Loss = 0.4585\n",
      "Iteration 8/140: Train Loss = 0.4316, Valid Loss = 0.4409\n",
      "Iteration 9/140: Train Loss = 0.4152, Valid Loss = 0.4255\n",
      "Iteration 10/140: Train Loss = 0.4005, Valid Loss = 0.4113\n",
      "Iteration 11/140: Train Loss = 0.3875, Valid Loss = 0.3996\n",
      "Iteration 12/140: Train Loss = 0.3755, Valid Loss = 0.3887\n",
      "Iteration 13/140: Train Loss = 0.3653, Valid Loss = 0.3789\n",
      "Iteration 14/140: Train Loss = 0.3557, Valid Loss = 0.3700\n",
      "Iteration 15/140: Train Loss = 0.3469, Valid Loss = 0.3619\n",
      "Iteration 16/140: Train Loss = 0.3393, Valid Loss = 0.3547\n",
      "Iteration 17/140: Train Loss = 0.3321, Valid Loss = 0.3482\n",
      "Iteration 18/140: Train Loss = 0.3255, Valid Loss = 0.3424\n",
      "Iteration 19/140: Train Loss = 0.3196, Valid Loss = 0.3373\n",
      "Iteration 20/140: Train Loss = 0.3142, Valid Loss = 0.3324\n",
      "Iteration 21/140: Train Loss = 0.3088, Valid Loss = 0.3276\n",
      "Iteration 22/140: Train Loss = 0.3041, Valid Loss = 0.3231\n",
      "Iteration 23/140: Train Loss = 0.2998, Valid Loss = 0.3194\n",
      "Iteration 24/140: Train Loss = 0.2958, Valid Loss = 0.3157\n",
      "Iteration 25/140: Train Loss = 0.2921, Valid Loss = 0.3124\n",
      "Iteration 26/140: Train Loss = 0.2885, Valid Loss = 0.3089\n",
      "Iteration 27/140: Train Loss = 0.2850, Valid Loss = 0.3059\n",
      "Iteration 28/140: Train Loss = 0.2818, Valid Loss = 0.3031\n",
      "Iteration 29/140: Train Loss = 0.2788, Valid Loss = 0.3007\n",
      "Iteration 30/140: Train Loss = 0.2758, Valid Loss = 0.2982\n",
      "Iteration 31/140: Train Loss = 0.2731, Valid Loss = 0.2960\n",
      "Iteration 32/140: Train Loss = 0.2705, Valid Loss = 0.2939\n",
      "Iteration 33/140: Train Loss = 0.2679, Valid Loss = 0.2914\n",
      "Iteration 34/140: Train Loss = 0.2653, Valid Loss = 0.2890\n",
      "Iteration 35/140: Train Loss = 0.2629, Valid Loss = 0.2872\n",
      "Iteration 36/140: Train Loss = 0.2603, Valid Loss = 0.2852\n",
      "Iteration 37/140: Train Loss = 0.2583, Valid Loss = 0.2835\n",
      "Iteration 38/140: Train Loss = 0.2564, Valid Loss = 0.2821\n",
      "Iteration 39/140: Train Loss = 0.2543, Valid Loss = 0.2805\n",
      "Iteration 40/140: Train Loss = 0.2526, Valid Loss = 0.2789\n",
      "Iteration 41/140: Train Loss = 0.2509, Valid Loss = 0.2776\n",
      "Iteration 42/140: Train Loss = 0.2493, Valid Loss = 0.2761\n",
      "Iteration 43/140: Train Loss = 0.2478, Valid Loss = 0.2751\n",
      "Iteration 44/140: Train Loss = 0.2463, Valid Loss = 0.2737\n",
      "Iteration 45/140: Train Loss = 0.2447, Valid Loss = 0.2726\n",
      "Iteration 46/140: Train Loss = 0.2432, Valid Loss = 0.2713\n",
      "Iteration 47/140: Train Loss = 0.2420, Valid Loss = 0.2705\n",
      "Iteration 48/140: Train Loss = 0.2407, Valid Loss = 0.2695\n",
      "Iteration 49/140: Train Loss = 0.2394, Valid Loss = 0.2685\n",
      "Iteration 50/140: Train Loss = 0.2382, Valid Loss = 0.2674\n",
      "Iteration 51/140: Train Loss = 0.2369, Valid Loss = 0.2666\n",
      "Iteration 52/140: Train Loss = 0.2358, Valid Loss = 0.2658\n",
      "Iteration 53/140: Train Loss = 0.2347, Valid Loss = 0.2651\n",
      "Iteration 54/140: Train Loss = 0.2337, Valid Loss = 0.2643\n",
      "Iteration 55/140: Train Loss = 0.2326, Valid Loss = 0.2634\n",
      "Iteration 56/140: Train Loss = 0.2316, Valid Loss = 0.2629\n",
      "Iteration 57/140: Train Loss = 0.2306, Valid Loss = 0.2623\n",
      "Iteration 58/140: Train Loss = 0.2295, Valid Loss = 0.2612\n",
      "Iteration 59/140: Train Loss = 0.2285, Valid Loss = 0.2606\n",
      "Iteration 60/140: Train Loss = 0.2276, Valid Loss = 0.2597\n",
      "Iteration 61/140: Train Loss = 0.2267, Valid Loss = 0.2591\n",
      "Iteration 62/140: Train Loss = 0.2259, Valid Loss = 0.2584\n",
      "Iteration 63/140: Train Loss = 0.2250, Valid Loss = 0.2578\n",
      "Iteration 64/140: Train Loss = 0.2241, Valid Loss = 0.2573\n",
      "Iteration 65/140: Train Loss = 0.2233, Valid Loss = 0.2569\n",
      "Iteration 66/140: Train Loss = 0.2224, Valid Loss = 0.2566\n",
      "Iteration 67/140: Train Loss = 0.2217, Valid Loss = 0.2560\n",
      "Iteration 68/140: Train Loss = 0.2208, Valid Loss = 0.2553\n",
      "Iteration 69/140: Train Loss = 0.2199, Valid Loss = 0.2549\n",
      "Iteration 70/140: Train Loss = 0.2192, Valid Loss = 0.2544\n",
      "Iteration 71/140: Train Loss = 0.2185, Valid Loss = 0.2542\n",
      "Iteration 72/140: Train Loss = 0.2179, Valid Loss = 0.2539\n",
      "Iteration 73/140: Train Loss = 0.2172, Valid Loss = 0.2534\n",
      "Iteration 74/140: Train Loss = 0.2166, Valid Loss = 0.2528\n",
      "Iteration 75/140: Train Loss = 0.2161, Valid Loss = 0.2525\n",
      "Iteration 76/140: Train Loss = 0.2155, Valid Loss = 0.2521\n",
      "Iteration 77/140: Train Loss = 0.2148, Valid Loss = 0.2518\n",
      "Iteration 78/140: Train Loss = 0.2142, Valid Loss = 0.2515\n",
      "Iteration 79/140: Train Loss = 0.2137, Valid Loss = 0.2511\n",
      "Iteration 80/140: Train Loss = 0.2129, Valid Loss = 0.2507\n",
      "Iteration 81/140: Train Loss = 0.2124, Valid Loss = 0.2503\n",
      "Iteration 82/140: Train Loss = 0.2117, Valid Loss = 0.2500\n",
      "Iteration 83/140: Train Loss = 0.2113, Valid Loss = 0.2495\n",
      "Iteration 84/140: Train Loss = 0.2108, Valid Loss = 0.2494\n",
      "Iteration 85/140: Train Loss = 0.2103, Valid Loss = 0.2492\n",
      "Iteration 86/140: Train Loss = 0.2098, Valid Loss = 0.2489\n",
      "Iteration 87/140: Train Loss = 0.2094, Valid Loss = 0.2489\n",
      "Iteration 88/140: Train Loss = 0.2087, Valid Loss = 0.2485\n",
      "Iteration 89/140: Train Loss = 0.2083, Valid Loss = 0.2481\n",
      "Iteration 90/140: Train Loss = 0.2078, Valid Loss = 0.2478\n",
      "Iteration 91/140: Train Loss = 0.2074, Valid Loss = 0.2476\n",
      "Iteration 92/140: Train Loss = 0.2068, Valid Loss = 0.2472\n",
      "Iteration 93/140: Train Loss = 0.2064, Valid Loss = 0.2471\n",
      "Iteration 94/140: Train Loss = 0.2060, Valid Loss = 0.2470\n",
      "Iteration 95/140: Train Loss = 0.2056, Valid Loss = 0.2469\n",
      "Iteration 96/140: Train Loss = 0.2052, Valid Loss = 0.2468\n",
      "Iteration 97/140: Train Loss = 0.2047, Valid Loss = 0.2465\n",
      "Iteration 98/140: Train Loss = 0.2043, Valid Loss = 0.2463\n",
      "Iteration 99/140: Train Loss = 0.2039, Valid Loss = 0.2461\n",
      "Iteration 100/140: Train Loss = 0.2035, Valid Loss = 0.2458\n",
      "Iteration 101/140: Train Loss = 0.2031, Valid Loss = 0.2456\n",
      "Iteration 102/140: Train Loss = 0.2027, Valid Loss = 0.2455\n",
      "Iteration 103/140: Train Loss = 0.2024, Valid Loss = 0.2452\n",
      "Iteration 104/140: Train Loss = 0.2021, Valid Loss = 0.2450\n",
      "Iteration 105/140: Train Loss = 0.2018, Valid Loss = 0.2448\n",
      "Iteration 106/140: Train Loss = 0.2015, Valid Loss = 0.2448\n",
      "Iteration 107/140: Train Loss = 0.2012, Valid Loss = 0.2447\n",
      "Iteration 108/140: Train Loss = 0.2007, Valid Loss = 0.2445\n",
      "Iteration 109/140: Train Loss = 0.2004, Valid Loss = 0.2443\n",
      "Iteration 110/140: Train Loss = 0.2000, Valid Loss = 0.2441\n",
      "Iteration 111/140: Train Loss = 0.1997, Valid Loss = 0.2440\n",
      "Iteration 112/140: Train Loss = 0.1993, Valid Loss = 0.2439\n",
      "Iteration 113/140: Train Loss = 0.1990, Valid Loss = 0.2437\n",
      "Iteration 114/140: Train Loss = 0.1987, Valid Loss = 0.2436\n",
      "Iteration 115/140: Train Loss = 0.1985, Valid Loss = 0.2435\n",
      "Iteration 116/140: Train Loss = 0.1982, Valid Loss = 0.2433\n",
      "Iteration 117/140: Train Loss = 0.1979, Valid Loss = 0.2433\n",
      "Iteration 118/140: Train Loss = 0.1977, Valid Loss = 0.2434\n",
      "Iteration 119/140: Train Loss = 0.1973, Valid Loss = 0.2432\n",
      "Iteration 120/140: Train Loss = 0.1971, Valid Loss = 0.2431\n",
      "Iteration 121/140: Train Loss = 0.1968, Valid Loss = 0.2430\n",
      "Iteration 122/140: Train Loss = 0.1965, Valid Loss = 0.2428\n",
      "Iteration 123/140: Train Loss = 0.1961, Valid Loss = 0.2427\n",
      "Iteration 124/140: Train Loss = 0.1958, Valid Loss = 0.2427\n",
      "Iteration 125/140: Train Loss = 0.1955, Valid Loss = 0.2425\n",
      "Iteration 126/140: Train Loss = 0.1953, Valid Loss = 0.2424\n",
      "Iteration 127/140: Train Loss = 0.1950, Valid Loss = 0.2423\n",
      "Iteration 128/140: Train Loss = 0.1946, Valid Loss = 0.2421\n",
      "Iteration 129/140: Train Loss = 0.1944, Valid Loss = 0.2419\n",
      "Iteration 130/140: Train Loss = 0.1941, Valid Loss = 0.2418\n",
      "Iteration 131/140: Train Loss = 0.1938, Valid Loss = 0.2416\n",
      "Iteration 132/140: Train Loss = 0.1935, Valid Loss = 0.2415\n",
      "Iteration 133/140: Train Loss = 0.1933, Valid Loss = 0.2414\n",
      "Iteration 134/140: Train Loss = 0.1930, Valid Loss = 0.2412\n",
      "Iteration 135/140: Train Loss = 0.1927, Valid Loss = 0.2412\n",
      "Iteration 136/140: Train Loss = 0.1925, Valid Loss = 0.2411\n",
      "Iteration 137/140: Train Loss = 0.1923, Valid Loss = 0.2411\n",
      "Iteration 138/140: Train Loss = 0.1921, Valid Loss = 0.2410\n",
      "Iteration 139/140: Train Loss = 0.1918, Valid Loss = 0.2408\n",
      "Iteration 140/140: Train Loss = 0.1915, Valid Loss = 0.2407\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-05 00:51:08,520] Trial 27 finished with value: 0.9657550072635349 and parameters: {'max_depth': 7, 'min_samples_leaf': 11, 'n_estimators': 140, 'learning_rate': 0.3219266375247475, 'subsample': 0.7623886541997188}. Best is trial 27 with value: 0.9657550072635349.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1/140: Train Loss = 0.6643, Valid Loss = 0.6656\n",
      "Iteration 2/140: Train Loss = 0.6373, Valid Loss = 0.6396\n",
      "Iteration 3/140: Train Loss = 0.6126, Valid Loss = 0.6162\n",
      "Iteration 4/140: Train Loss = 0.5901, Valid Loss = 0.5945\n",
      "Iteration 5/140: Train Loss = 0.5692, Valid Loss = 0.5747\n",
      "Iteration 6/140: Train Loss = 0.5499, Valid Loss = 0.5564\n",
      "Iteration 7/140: Train Loss = 0.5316, Valid Loss = 0.5390\n",
      "Iteration 8/140: Train Loss = 0.5147, Valid Loss = 0.5232\n",
      "Iteration 9/140: Train Loss = 0.4995, Valid Loss = 0.5089\n",
      "Iteration 10/140: Train Loss = 0.4849, Valid Loss = 0.4952\n",
      "Iteration 11/140: Train Loss = 0.4716, Valid Loss = 0.4826\n",
      "Iteration 12/140: Train Loss = 0.4589, Valid Loss = 0.4708\n",
      "Iteration 13/140: Train Loss = 0.4470, Valid Loss = 0.4598\n",
      "Iteration 14/140: Train Loss = 0.4361, Valid Loss = 0.4493\n",
      "Iteration 15/140: Train Loss = 0.4258, Valid Loss = 0.4398\n",
      "Iteration 16/140: Train Loss = 0.4163, Valid Loss = 0.4313\n",
      "Iteration 17/140: Train Loss = 0.4072, Valid Loss = 0.4232\n",
      "Iteration 18/140: Train Loss = 0.3987, Valid Loss = 0.4154\n",
      "Iteration 19/140: Train Loss = 0.3906, Valid Loss = 0.4079\n",
      "Iteration 20/140: Train Loss = 0.3830, Valid Loss = 0.4012\n",
      "Iteration 21/140: Train Loss = 0.3760, Valid Loss = 0.3950\n",
      "Iteration 22/140: Train Loss = 0.3693, Valid Loss = 0.3891\n",
      "Iteration 23/140: Train Loss = 0.3630, Valid Loss = 0.3835\n",
      "Iteration 24/140: Train Loss = 0.3569, Valid Loss = 0.3782\n",
      "Iteration 25/140: Train Loss = 0.3511, Valid Loss = 0.3731\n",
      "Iteration 26/140: Train Loss = 0.3455, Valid Loss = 0.3681\n",
      "Iteration 27/140: Train Loss = 0.3403, Valid Loss = 0.3635\n",
      "Iteration 28/140: Train Loss = 0.3354, Valid Loss = 0.3595\n",
      "Iteration 29/140: Train Loss = 0.3307, Valid Loss = 0.3554\n",
      "Iteration 30/140: Train Loss = 0.3263, Valid Loss = 0.3516\n",
      "Iteration 31/140: Train Loss = 0.3221, Valid Loss = 0.3480\n",
      "Iteration 32/140: Train Loss = 0.3180, Valid Loss = 0.3446\n",
      "Iteration 33/140: Train Loss = 0.3141, Valid Loss = 0.3412\n",
      "Iteration 34/140: Train Loss = 0.3103, Valid Loss = 0.3380\n",
      "Iteration 35/140: Train Loss = 0.3067, Valid Loss = 0.3349\n",
      "Iteration 36/140: Train Loss = 0.3034, Valid Loss = 0.3318\n",
      "Iteration 37/140: Train Loss = 0.3001, Valid Loss = 0.3292\n",
      "Iteration 38/140: Train Loss = 0.2970, Valid Loss = 0.3267\n",
      "Iteration 39/140: Train Loss = 0.2939, Valid Loss = 0.3243\n",
      "Iteration 40/140: Train Loss = 0.2910, Valid Loss = 0.3218\n",
      "Iteration 41/140: Train Loss = 0.2883, Valid Loss = 0.3195\n",
      "Iteration 42/140: Train Loss = 0.2857, Valid Loss = 0.3174\n",
      "Iteration 43/140: Train Loss = 0.2831, Valid Loss = 0.3154\n",
      "Iteration 44/140: Train Loss = 0.2805, Valid Loss = 0.3132\n",
      "Iteration 45/140: Train Loss = 0.2780, Valid Loss = 0.3113\n",
      "Iteration 46/140: Train Loss = 0.2757, Valid Loss = 0.3095\n",
      "Iteration 47/140: Train Loss = 0.2734, Valid Loss = 0.3075\n",
      "Iteration 48/140: Train Loss = 0.2712, Valid Loss = 0.3056\n",
      "Iteration 49/140: Train Loss = 0.2691, Valid Loss = 0.3040\n",
      "Iteration 50/140: Train Loss = 0.2671, Valid Loss = 0.3025\n",
      "Iteration 51/140: Train Loss = 0.2651, Valid Loss = 0.3008\n",
      "Iteration 52/140: Train Loss = 0.2632, Valid Loss = 0.2993\n",
      "Iteration 53/140: Train Loss = 0.2614, Valid Loss = 0.2980\n",
      "Iteration 54/140: Train Loss = 0.2596, Valid Loss = 0.2965\n",
      "Iteration 55/140: Train Loss = 0.2579, Valid Loss = 0.2952\n",
      "Iteration 56/140: Train Loss = 0.2561, Valid Loss = 0.2938\n",
      "Iteration 57/140: Train Loss = 0.2544, Valid Loss = 0.2924\n",
      "Iteration 58/140: Train Loss = 0.2527, Valid Loss = 0.2912\n",
      "Iteration 59/140: Train Loss = 0.2512, Valid Loss = 0.2902\n",
      "Iteration 60/140: Train Loss = 0.2496, Valid Loss = 0.2891\n",
      "Iteration 61/140: Train Loss = 0.2481, Valid Loss = 0.2881\n",
      "Iteration 62/140: Train Loss = 0.2466, Valid Loss = 0.2869\n",
      "Iteration 63/140: Train Loss = 0.2452, Valid Loss = 0.2859\n",
      "Iteration 64/140: Train Loss = 0.2440, Valid Loss = 0.2849\n",
      "Iteration 65/140: Train Loss = 0.2427, Valid Loss = 0.2839\n",
      "Iteration 66/140: Train Loss = 0.2413, Valid Loss = 0.2829\n",
      "Iteration 67/140: Train Loss = 0.2399, Valid Loss = 0.2821\n",
      "Iteration 68/140: Train Loss = 0.2387, Valid Loss = 0.2813\n",
      "Iteration 69/140: Train Loss = 0.2376, Valid Loss = 0.2805\n",
      "Iteration 70/140: Train Loss = 0.2364, Valid Loss = 0.2797\n",
      "Iteration 71/140: Train Loss = 0.2352, Valid Loss = 0.2788\n",
      "Iteration 72/140: Train Loss = 0.2341, Valid Loss = 0.2781\n",
      "Iteration 73/140: Train Loss = 0.2331, Valid Loss = 0.2773\n",
      "Iteration 74/140: Train Loss = 0.2320, Valid Loss = 0.2767\n",
      "Iteration 75/140: Train Loss = 0.2309, Valid Loss = 0.2760\n",
      "Iteration 76/140: Train Loss = 0.2299, Valid Loss = 0.2752\n",
      "Iteration 77/140: Train Loss = 0.2288, Valid Loss = 0.2747\n",
      "Iteration 78/140: Train Loss = 0.2278, Valid Loss = 0.2739\n",
      "Iteration 79/140: Train Loss = 0.2269, Valid Loss = 0.2734\n",
      "Iteration 80/140: Train Loss = 0.2260, Valid Loss = 0.2728\n",
      "Iteration 81/140: Train Loss = 0.2250, Valid Loss = 0.2721\n",
      "Iteration 82/140: Train Loss = 0.2241, Valid Loss = 0.2714\n",
      "Iteration 83/140: Train Loss = 0.2231, Valid Loss = 0.2707\n",
      "Iteration 84/140: Train Loss = 0.2223, Valid Loss = 0.2702\n",
      "Iteration 85/140: Train Loss = 0.2214, Valid Loss = 0.2698\n",
      "Iteration 86/140: Train Loss = 0.2205, Valid Loss = 0.2693\n",
      "Iteration 87/140: Train Loss = 0.2197, Valid Loss = 0.2688\n",
      "Iteration 88/140: Train Loss = 0.2188, Valid Loss = 0.2681\n",
      "Iteration 89/140: Train Loss = 0.2179, Valid Loss = 0.2675\n",
      "Iteration 90/140: Train Loss = 0.2171, Valid Loss = 0.2669\n",
      "Iteration 91/140: Train Loss = 0.2164, Valid Loss = 0.2665\n",
      "Iteration 92/140: Train Loss = 0.2156, Valid Loss = 0.2659\n",
      "Iteration 93/140: Train Loss = 0.2149, Valid Loss = 0.2653\n",
      "Iteration 94/140: Train Loss = 0.2142, Valid Loss = 0.2648\n",
      "Iteration 95/140: Train Loss = 0.2136, Valid Loss = 0.2643\n",
      "Iteration 96/140: Train Loss = 0.2129, Valid Loss = 0.2640\n",
      "Iteration 97/140: Train Loss = 0.2122, Valid Loss = 0.2634\n",
      "Iteration 98/140: Train Loss = 0.2115, Valid Loss = 0.2629\n",
      "Iteration 99/140: Train Loss = 0.2109, Valid Loss = 0.2624\n",
      "Iteration 100/140: Train Loss = 0.2103, Valid Loss = 0.2620\n",
      "Iteration 101/140: Train Loss = 0.2095, Valid Loss = 0.2615\n",
      "Iteration 102/140: Train Loss = 0.2089, Valid Loss = 0.2613\n",
      "Iteration 103/140: Train Loss = 0.2083, Valid Loss = 0.2609\n",
      "Iteration 104/140: Train Loss = 0.2078, Valid Loss = 0.2605\n",
      "Iteration 105/140: Train Loss = 0.2071, Valid Loss = 0.2604\n",
      "Iteration 106/140: Train Loss = 0.2065, Valid Loss = 0.2598\n",
      "Iteration 107/140: Train Loss = 0.2059, Valid Loss = 0.2595\n",
      "Iteration 108/140: Train Loss = 0.2053, Valid Loss = 0.2591\n",
      "Iteration 109/140: Train Loss = 0.2047, Valid Loss = 0.2589\n",
      "Iteration 110/140: Train Loss = 0.2042, Valid Loss = 0.2586\n",
      "Iteration 111/140: Train Loss = 0.2037, Valid Loss = 0.2582\n",
      "Iteration 112/140: Train Loss = 0.2032, Valid Loss = 0.2578\n",
      "Iteration 113/140: Train Loss = 0.2026, Valid Loss = 0.2575\n",
      "Iteration 114/140: Train Loss = 0.2021, Valid Loss = 0.2574\n",
      "Iteration 115/140: Train Loss = 0.2015, Valid Loss = 0.2574\n",
      "Iteration 116/140: Train Loss = 0.2010, Valid Loss = 0.2570\n",
      "Iteration 117/140: Train Loss = 0.2004, Valid Loss = 0.2565\n",
      "Iteration 118/140: Train Loss = 0.1999, Valid Loss = 0.2563\n",
      "Iteration 119/140: Train Loss = 0.1994, Valid Loss = 0.2561\n",
      "Iteration 120/140: Train Loss = 0.1989, Valid Loss = 0.2559\n",
      "Iteration 121/140: Train Loss = 0.1984, Valid Loss = 0.2557\n",
      "Iteration 122/140: Train Loss = 0.1979, Valid Loss = 0.2553\n",
      "Iteration 123/140: Train Loss = 0.1975, Valid Loss = 0.2549\n",
      "Iteration 124/140: Train Loss = 0.1970, Valid Loss = 0.2547\n",
      "Iteration 125/140: Train Loss = 0.1965, Valid Loss = 0.2545\n",
      "Iteration 126/140: Train Loss = 0.1962, Valid Loss = 0.2543\n",
      "Iteration 127/140: Train Loss = 0.1957, Valid Loss = 0.2539\n",
      "Iteration 128/140: Train Loss = 0.1953, Valid Loss = 0.2538\n",
      "Iteration 129/140: Train Loss = 0.1949, Valid Loss = 0.2536\n",
      "Iteration 130/140: Train Loss = 0.1943, Valid Loss = 0.2534\n",
      "Iteration 131/140: Train Loss = 0.1939, Valid Loss = 0.2534\n",
      "Iteration 132/140: Train Loss = 0.1935, Valid Loss = 0.2531\n",
      "Iteration 133/140: Train Loss = 0.1931, Valid Loss = 0.2530\n",
      "Iteration 134/140: Train Loss = 0.1927, Valid Loss = 0.2528\n",
      "Iteration 135/140: Train Loss = 0.1923, Valid Loss = 0.2524\n",
      "Iteration 136/140: Train Loss = 0.1917, Valid Loss = 0.2521\n",
      "Iteration 137/140: Train Loss = 0.1913, Valid Loss = 0.2519\n",
      "Iteration 138/140: Train Loss = 0.1909, Valid Loss = 0.2519\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-05 00:51:17,617] Trial 28 finished with value: 0.9648803327880916 and parameters: {'max_depth': 10, 'min_samples_leaf': 7, 'n_estimators': 140, 'learning_rate': 0.16524303464831572, 'subsample': 0.5812322631414446}. Best is trial 27 with value: 0.9657550072635349.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 139/140: Train Loss = 0.1904, Valid Loss = 0.2519\n",
      "Iteration 140/140: Train Loss = 0.1901, Valid Loss = 0.2518\n",
      "Iteration 1/145: Train Loss = 0.6487, Valid Loss = 0.6495\n",
      "Iteration 2/145: Train Loss = 0.6105, Valid Loss = 0.6120\n",
      "Iteration 3/145: Train Loss = 0.5780, Valid Loss = 0.5801\n",
      "Iteration 4/145: Train Loss = 0.5488, Valid Loss = 0.5516\n",
      "Iteration 5/145: Train Loss = 0.5238, Valid Loss = 0.5270\n",
      "Iteration 6/145: Train Loss = 0.5014, Valid Loss = 0.5055\n",
      "Iteration 7/145: Train Loss = 0.4814, Valid Loss = 0.4865\n",
      "Iteration 8/145: Train Loss = 0.4637, Valid Loss = 0.4690\n",
      "Iteration 9/145: Train Loss = 0.4482, Valid Loss = 0.4538\n",
      "Iteration 10/145: Train Loss = 0.4343, Valid Loss = 0.4408\n",
      "Iteration 11/145: Train Loss = 0.4218, Valid Loss = 0.4285\n",
      "Iteration 12/145: Train Loss = 0.4106, Valid Loss = 0.4181\n",
      "Iteration 13/145: Train Loss = 0.4005, Valid Loss = 0.4084\n",
      "Iteration 14/145: Train Loss = 0.3909, Valid Loss = 0.3993\n",
      "Iteration 15/145: Train Loss = 0.3823, Valid Loss = 0.3910\n",
      "Iteration 16/145: Train Loss = 0.3744, Valid Loss = 0.3835\n",
      "Iteration 17/145: Train Loss = 0.3676, Valid Loss = 0.3768\n",
      "Iteration 18/145: Train Loss = 0.3609, Valid Loss = 0.3704\n",
      "Iteration 19/145: Train Loss = 0.3545, Valid Loss = 0.3645\n",
      "Iteration 20/145: Train Loss = 0.3490, Valid Loss = 0.3592\n",
      "Iteration 21/145: Train Loss = 0.3439, Valid Loss = 0.3541\n",
      "Iteration 22/145: Train Loss = 0.3389, Valid Loss = 0.3493\n",
      "Iteration 23/145: Train Loss = 0.3344, Valid Loss = 0.3447\n",
      "Iteration 24/145: Train Loss = 0.3301, Valid Loss = 0.3405\n",
      "Iteration 25/145: Train Loss = 0.3258, Valid Loss = 0.3366\n",
      "Iteration 26/145: Train Loss = 0.3221, Valid Loss = 0.3328\n",
      "Iteration 27/145: Train Loss = 0.3185, Valid Loss = 0.3296\n",
      "Iteration 28/145: Train Loss = 0.3153, Valid Loss = 0.3263\n",
      "Iteration 29/145: Train Loss = 0.3121, Valid Loss = 0.3236\n",
      "Iteration 30/145: Train Loss = 0.3089, Valid Loss = 0.3205\n",
      "Iteration 31/145: Train Loss = 0.3060, Valid Loss = 0.3176\n",
      "Iteration 32/145: Train Loss = 0.3033, Valid Loss = 0.3150\n",
      "Iteration 33/145: Train Loss = 0.3006, Valid Loss = 0.3125\n",
      "Iteration 34/145: Train Loss = 0.2984, Valid Loss = 0.3108\n",
      "Iteration 35/145: Train Loss = 0.2960, Valid Loss = 0.3085\n",
      "Iteration 36/145: Train Loss = 0.2939, Valid Loss = 0.3068\n",
      "Iteration 37/145: Train Loss = 0.2919, Valid Loss = 0.3049\n",
      "Iteration 38/145: Train Loss = 0.2900, Valid Loss = 0.3030\n",
      "Iteration 39/145: Train Loss = 0.2882, Valid Loss = 0.3013\n",
      "Iteration 40/145: Train Loss = 0.2862, Valid Loss = 0.2993\n",
      "Iteration 41/145: Train Loss = 0.2844, Valid Loss = 0.2975\n",
      "Iteration 42/145: Train Loss = 0.2827, Valid Loss = 0.2959\n",
      "Iteration 43/145: Train Loss = 0.2812, Valid Loss = 0.2948\n",
      "Iteration 44/145: Train Loss = 0.2796, Valid Loss = 0.2933\n",
      "Iteration 45/145: Train Loss = 0.2780, Valid Loss = 0.2921\n",
      "Iteration 46/145: Train Loss = 0.2765, Valid Loss = 0.2905\n",
      "Iteration 47/145: Train Loss = 0.2748, Valid Loss = 0.2888\n",
      "Iteration 48/145: Train Loss = 0.2733, Valid Loss = 0.2875\n",
      "Iteration 49/145: Train Loss = 0.2721, Valid Loss = 0.2863\n",
      "Iteration 50/145: Train Loss = 0.2708, Valid Loss = 0.2852\n",
      "Iteration 51/145: Train Loss = 0.2696, Valid Loss = 0.2842\n",
      "Iteration 52/145: Train Loss = 0.2684, Valid Loss = 0.2833\n",
      "Iteration 53/145: Train Loss = 0.2673, Valid Loss = 0.2822\n",
      "Iteration 54/145: Train Loss = 0.2663, Valid Loss = 0.2813\n",
      "Iteration 55/145: Train Loss = 0.2650, Valid Loss = 0.2805\n",
      "Iteration 56/145: Train Loss = 0.2639, Valid Loss = 0.2797\n",
      "Iteration 57/145: Train Loss = 0.2628, Valid Loss = 0.2785\n",
      "Iteration 58/145: Train Loss = 0.2617, Valid Loss = 0.2775\n",
      "Iteration 59/145: Train Loss = 0.2607, Valid Loss = 0.2765\n",
      "Iteration 60/145: Train Loss = 0.2598, Valid Loss = 0.2757\n",
      "Iteration 61/145: Train Loss = 0.2588, Valid Loss = 0.2749\n",
      "Iteration 62/145: Train Loss = 0.2580, Valid Loss = 0.2743\n",
      "Iteration 63/145: Train Loss = 0.2571, Valid Loss = 0.2735\n",
      "Iteration 64/145: Train Loss = 0.2562, Valid Loss = 0.2729\n",
      "Iteration 65/145: Train Loss = 0.2554, Valid Loss = 0.2723\n",
      "Iteration 66/145: Train Loss = 0.2544, Valid Loss = 0.2713\n",
      "Iteration 67/145: Train Loss = 0.2536, Valid Loss = 0.2706\n",
      "Iteration 68/145: Train Loss = 0.2528, Valid Loss = 0.2699\n",
      "Iteration 69/145: Train Loss = 0.2518, Valid Loss = 0.2690\n",
      "Iteration 70/145: Train Loss = 0.2510, Valid Loss = 0.2686\n",
      "Iteration 71/145: Train Loss = 0.2504, Valid Loss = 0.2681\n",
      "Iteration 72/145: Train Loss = 0.2497, Valid Loss = 0.2675\n",
      "Iteration 73/145: Train Loss = 0.2490, Valid Loss = 0.2668\n",
      "Iteration 74/145: Train Loss = 0.2483, Valid Loss = 0.2662\n",
      "Iteration 75/145: Train Loss = 0.2477, Valid Loss = 0.2659\n",
      "Iteration 76/145: Train Loss = 0.2471, Valid Loss = 0.2654\n",
      "Iteration 77/145: Train Loss = 0.2465, Valid Loss = 0.2650\n",
      "Iteration 78/145: Train Loss = 0.2459, Valid Loss = 0.2646\n",
      "Iteration 79/145: Train Loss = 0.2452, Valid Loss = 0.2641\n",
      "Iteration 80/145: Train Loss = 0.2446, Valid Loss = 0.2637\n",
      "Iteration 81/145: Train Loss = 0.2441, Valid Loss = 0.2633\n",
      "Iteration 82/145: Train Loss = 0.2436, Valid Loss = 0.2630\n",
      "Iteration 83/145: Train Loss = 0.2431, Valid Loss = 0.2626\n",
      "Iteration 84/145: Train Loss = 0.2425, Valid Loss = 0.2622\n",
      "Iteration 85/145: Train Loss = 0.2419, Valid Loss = 0.2617\n",
      "Iteration 86/145: Train Loss = 0.2415, Valid Loss = 0.2613\n",
      "Iteration 87/145: Train Loss = 0.2409, Valid Loss = 0.2609\n",
      "Iteration 88/145: Train Loss = 0.2404, Valid Loss = 0.2603\n",
      "Iteration 89/145: Train Loss = 0.2401, Valid Loss = 0.2601\n",
      "Iteration 90/145: Train Loss = 0.2396, Valid Loss = 0.2595\n",
      "Iteration 91/145: Train Loss = 0.2392, Valid Loss = 0.2591\n",
      "Iteration 92/145: Train Loss = 0.2387, Valid Loss = 0.2585\n",
      "Iteration 93/145: Train Loss = 0.2381, Valid Loss = 0.2582\n",
      "Iteration 94/145: Train Loss = 0.2376, Valid Loss = 0.2579\n",
      "Iteration 95/145: Train Loss = 0.2371, Valid Loss = 0.2575\n",
      "Iteration 96/145: Train Loss = 0.2367, Valid Loss = 0.2572\n",
      "Iteration 97/145: Train Loss = 0.2362, Valid Loss = 0.2568\n",
      "Iteration 98/145: Train Loss = 0.2359, Valid Loss = 0.2566\n",
      "Iteration 99/145: Train Loss = 0.2355, Valid Loss = 0.2564\n",
      "Iteration 100/145: Train Loss = 0.2352, Valid Loss = 0.2563\n",
      "Iteration 101/145: Train Loss = 0.2348, Valid Loss = 0.2560\n",
      "Iteration 102/145: Train Loss = 0.2344, Valid Loss = 0.2558\n",
      "Iteration 103/145: Train Loss = 0.2339, Valid Loss = 0.2555\n",
      "Iteration 104/145: Train Loss = 0.2336, Valid Loss = 0.2553\n",
      "Iteration 105/145: Train Loss = 0.2332, Valid Loss = 0.2549\n",
      "Iteration 106/145: Train Loss = 0.2328, Valid Loss = 0.2545\n",
      "Iteration 107/145: Train Loss = 0.2324, Valid Loss = 0.2542\n",
      "Iteration 108/145: Train Loss = 0.2320, Valid Loss = 0.2538\n",
      "Iteration 109/145: Train Loss = 0.2316, Valid Loss = 0.2536\n",
      "Iteration 110/145: Train Loss = 0.2313, Valid Loss = 0.2532\n",
      "Iteration 111/145: Train Loss = 0.2310, Valid Loss = 0.2532\n",
      "Iteration 112/145: Train Loss = 0.2307, Valid Loss = 0.2532\n",
      "Iteration 113/145: Train Loss = 0.2305, Valid Loss = 0.2530\n",
      "Iteration 114/145: Train Loss = 0.2301, Valid Loss = 0.2527\n",
      "Iteration 115/145: Train Loss = 0.2297, Valid Loss = 0.2524\n",
      "Iteration 116/145: Train Loss = 0.2293, Valid Loss = 0.2522\n",
      "Iteration 117/145: Train Loss = 0.2290, Valid Loss = 0.2519\n",
      "Iteration 118/145: Train Loss = 0.2285, Valid Loss = 0.2516\n",
      "Iteration 119/145: Train Loss = 0.2283, Valid Loss = 0.2513\n",
      "Iteration 120/145: Train Loss = 0.2280, Valid Loss = 0.2509\n",
      "Iteration 121/145: Train Loss = 0.2276, Valid Loss = 0.2507\n",
      "Iteration 122/145: Train Loss = 0.2272, Valid Loss = 0.2504\n",
      "Iteration 123/145: Train Loss = 0.2269, Valid Loss = 0.2501\n",
      "Iteration 124/145: Train Loss = 0.2266, Valid Loss = 0.2501\n",
      "Iteration 125/145: Train Loss = 0.2263, Valid Loss = 0.2498\n",
      "Iteration 126/145: Train Loss = 0.2261, Valid Loss = 0.2498\n",
      "Iteration 127/145: Train Loss = 0.2258, Valid Loss = 0.2497\n",
      "Iteration 128/145: Train Loss = 0.2256, Valid Loss = 0.2495\n",
      "Iteration 129/145: Train Loss = 0.2253, Valid Loss = 0.2495\n",
      "Iteration 130/145: Train Loss = 0.2250, Valid Loss = 0.2493\n",
      "Iteration 131/145: Train Loss = 0.2247, Valid Loss = 0.2492\n",
      "Iteration 132/145: Train Loss = 0.2245, Valid Loss = 0.2489\n",
      "Iteration 133/145: Train Loss = 0.2242, Valid Loss = 0.2488\n",
      "Iteration 134/145: Train Loss = 0.2239, Valid Loss = 0.2487\n",
      "Iteration 135/145: Train Loss = 0.2237, Valid Loss = 0.2486\n",
      "Iteration 136/145: Train Loss = 0.2234, Valid Loss = 0.2485\n",
      "Iteration 137/145: Train Loss = 0.2231, Valid Loss = 0.2483\n",
      "Iteration 138/145: Train Loss = 0.2227, Valid Loss = 0.2479\n",
      "Iteration 139/145: Train Loss = 0.2225, Valid Loss = 0.2477\n",
      "Iteration 140/145: Train Loss = 0.2223, Valid Loss = 0.2476\n",
      "Iteration 141/145: Train Loss = 0.2220, Valid Loss = 0.2473\n",
      "Iteration 142/145: Train Loss = 0.2218, Valid Loss = 0.2471\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-05 00:51:23,378] Trial 29 finished with value: 0.9643770327411934 and parameters: {'max_depth': 5, 'min_samples_leaf': 19, 'n_estimators': 145, 'learning_rate': 0.2846085649977731, 'subsample': 0.6686720105160319}. Best is trial 27 with value: 0.9657550072635349.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 143/145: Train Loss = 0.2216, Valid Loss = 0.2470\n",
      "Iteration 144/145: Train Loss = 0.2213, Valid Loss = 0.2467\n",
      "Iteration 145/145: Train Loss = 0.2211, Valid Loss = 0.2466\n",
      "Iteration 1/125: Train Loss = 0.6885, Valid Loss = 0.6886\n",
      "Iteration 2/125: Train Loss = 0.6840, Valid Loss = 0.6841\n",
      "Iteration 3/125: Train Loss = 0.6795, Valid Loss = 0.6797\n",
      "Iteration 4/125: Train Loss = 0.6750, Valid Loss = 0.6754\n",
      "Iteration 5/125: Train Loss = 0.6707, Valid Loss = 0.6712\n",
      "Iteration 6/125: Train Loss = 0.6664, Valid Loss = 0.6670\n",
      "Iteration 7/125: Train Loss = 0.6622, Valid Loss = 0.6629\n",
      "Iteration 8/125: Train Loss = 0.6580, Valid Loss = 0.6588\n",
      "Iteration 9/125: Train Loss = 0.6540, Valid Loss = 0.6548\n",
      "Iteration 10/125: Train Loss = 0.6499, Valid Loss = 0.6509\n",
      "Iteration 11/125: Train Loss = 0.6459, Valid Loss = 0.6470\n",
      "Iteration 12/125: Train Loss = 0.6420, Valid Loss = 0.6432\n",
      "Iteration 13/125: Train Loss = 0.6382, Valid Loss = 0.6395\n",
      "Iteration 14/125: Train Loss = 0.6344, Valid Loss = 0.6357\n",
      "Iteration 15/125: Train Loss = 0.6306, Valid Loss = 0.6321\n",
      "Iteration 16/125: Train Loss = 0.6269, Valid Loss = 0.6285\n",
      "Iteration 17/125: Train Loss = 0.6233, Valid Loss = 0.6249\n",
      "Iteration 18/125: Train Loss = 0.6197, Valid Loss = 0.6214\n",
      "Iteration 19/125: Train Loss = 0.6162, Valid Loss = 0.6181\n",
      "Iteration 20/125: Train Loss = 0.6128, Valid Loss = 0.6146\n",
      "Iteration 21/125: Train Loss = 0.6093, Valid Loss = 0.6113\n",
      "Iteration 22/125: Train Loss = 0.6060, Valid Loss = 0.6081\n",
      "Iteration 23/125: Train Loss = 0.6027, Valid Loss = 0.6048\n",
      "Iteration 24/125: Train Loss = 0.5994, Valid Loss = 0.6017\n",
      "Iteration 25/125: Train Loss = 0.5962, Valid Loss = 0.5985\n",
      "Iteration 26/125: Train Loss = 0.5930, Valid Loss = 0.5954\n",
      "Iteration 27/125: Train Loss = 0.5898, Valid Loss = 0.5923\n",
      "Iteration 28/125: Train Loss = 0.5867, Valid Loss = 0.5893\n",
      "Iteration 29/125: Train Loss = 0.5837, Valid Loss = 0.5864\n",
      "Iteration 30/125: Train Loss = 0.5807, Valid Loss = 0.5835\n",
      "Iteration 31/125: Train Loss = 0.5777, Valid Loss = 0.5806\n",
      "Iteration 32/125: Train Loss = 0.5747, Valid Loss = 0.5778\n",
      "Iteration 33/125: Train Loss = 0.5718, Valid Loss = 0.5749\n",
      "Iteration 34/125: Train Loss = 0.5690, Valid Loss = 0.5722\n",
      "Iteration 35/125: Train Loss = 0.5663, Valid Loss = 0.5695\n",
      "Iteration 36/125: Train Loss = 0.5635, Valid Loss = 0.5668\n",
      "Iteration 37/125: Train Loss = 0.5608, Valid Loss = 0.5642\n",
      "Iteration 38/125: Train Loss = 0.5582, Valid Loss = 0.5616\n",
      "Iteration 39/125: Train Loss = 0.5556, Valid Loss = 0.5590\n",
      "Iteration 40/125: Train Loss = 0.5529, Valid Loss = 0.5565\n",
      "Iteration 41/125: Train Loss = 0.5504, Valid Loss = 0.5540\n",
      "Iteration 42/125: Train Loss = 0.5478, Valid Loss = 0.5515\n",
      "Iteration 43/125: Train Loss = 0.5453, Valid Loss = 0.5491\n",
      "Iteration 44/125: Train Loss = 0.5429, Valid Loss = 0.5467\n",
      "Iteration 45/125: Train Loss = 0.5404, Valid Loss = 0.5442\n",
      "Iteration 46/125: Train Loss = 0.5380, Valid Loss = 0.5419\n",
      "Iteration 47/125: Train Loss = 0.5357, Valid Loss = 0.5396\n",
      "Iteration 48/125: Train Loss = 0.5333, Valid Loss = 0.5373\n",
      "Iteration 49/125: Train Loss = 0.5311, Valid Loss = 0.5351\n",
      "Iteration 50/125: Train Loss = 0.5288, Valid Loss = 0.5329\n",
      "Iteration 51/125: Train Loss = 0.5266, Valid Loss = 0.5307\n",
      "Iteration 52/125: Train Loss = 0.5244, Valid Loss = 0.5286\n",
      "Iteration 53/125: Train Loss = 0.5222, Valid Loss = 0.5264\n",
      "Iteration 54/125: Train Loss = 0.5201, Valid Loss = 0.5244\n",
      "Iteration 55/125: Train Loss = 0.5180, Valid Loss = 0.5223\n",
      "Iteration 56/125: Train Loss = 0.5159, Valid Loss = 0.5203\n",
      "Iteration 57/125: Train Loss = 0.5139, Valid Loss = 0.5182\n",
      "Iteration 58/125: Train Loss = 0.5118, Valid Loss = 0.5162\n",
      "Iteration 59/125: Train Loss = 0.5099, Valid Loss = 0.5143\n",
      "Iteration 60/125: Train Loss = 0.5079, Valid Loss = 0.5123\n",
      "Iteration 61/125: Train Loss = 0.5059, Valid Loss = 0.5104\n",
      "Iteration 62/125: Train Loss = 0.5040, Valid Loss = 0.5086\n",
      "Iteration 63/125: Train Loss = 0.5021, Valid Loss = 0.5067\n",
      "Iteration 64/125: Train Loss = 0.5002, Valid Loss = 0.5049\n",
      "Iteration 65/125: Train Loss = 0.4984, Valid Loss = 0.5031\n",
      "Iteration 66/125: Train Loss = 0.4965, Valid Loss = 0.5013\n",
      "Iteration 67/125: Train Loss = 0.4947, Valid Loss = 0.4996\n",
      "Iteration 68/125: Train Loss = 0.4929, Valid Loss = 0.4978\n",
      "Iteration 69/125: Train Loss = 0.4911, Valid Loss = 0.4961\n",
      "Iteration 70/125: Train Loss = 0.4893, Valid Loss = 0.4943\n",
      "Iteration 71/125: Train Loss = 0.4876, Valid Loss = 0.4926\n",
      "Iteration 72/125: Train Loss = 0.4859, Valid Loss = 0.4910\n",
      "Iteration 73/125: Train Loss = 0.4842, Valid Loss = 0.4894\n",
      "Iteration 74/125: Train Loss = 0.4825, Valid Loss = 0.4877\n",
      "Iteration 75/125: Train Loss = 0.4809, Valid Loss = 0.4861\n",
      "Iteration 76/125: Train Loss = 0.4792, Valid Loss = 0.4845\n",
      "Iteration 77/125: Train Loss = 0.4776, Valid Loss = 0.4829\n",
      "Iteration 78/125: Train Loss = 0.4760, Valid Loss = 0.4814\n",
      "Iteration 79/125: Train Loss = 0.4744, Valid Loss = 0.4798\n",
      "Iteration 80/125: Train Loss = 0.4729, Valid Loss = 0.4783\n",
      "Iteration 81/125: Train Loss = 0.4714, Valid Loss = 0.4769\n",
      "Iteration 82/125: Train Loss = 0.4700, Valid Loss = 0.4755\n",
      "Iteration 83/125: Train Loss = 0.4684, Valid Loss = 0.4739\n",
      "Iteration 84/125: Train Loss = 0.4669, Valid Loss = 0.4724\n",
      "Iteration 85/125: Train Loss = 0.4654, Valid Loss = 0.4710\n",
      "Iteration 86/125: Train Loss = 0.4640, Valid Loss = 0.4696\n",
      "Iteration 87/125: Train Loss = 0.4626, Valid Loss = 0.4682\n",
      "Iteration 88/125: Train Loss = 0.4612, Valid Loss = 0.4669\n",
      "Iteration 89/125: Train Loss = 0.4598, Valid Loss = 0.4655\n",
      "Iteration 90/125: Train Loss = 0.4584, Valid Loss = 0.4642\n",
      "Iteration 91/125: Train Loss = 0.4571, Valid Loss = 0.4628\n",
      "Iteration 92/125: Train Loss = 0.4557, Valid Loss = 0.4615\n",
      "Iteration 93/125: Train Loss = 0.4544, Valid Loss = 0.4601\n",
      "Iteration 94/125: Train Loss = 0.4530, Valid Loss = 0.4589\n",
      "Iteration 95/125: Train Loss = 0.4517, Valid Loss = 0.4575\n",
      "Iteration 96/125: Train Loss = 0.4504, Valid Loss = 0.4562\n",
      "Iteration 97/125: Train Loss = 0.4491, Valid Loss = 0.4549\n",
      "Iteration 98/125: Train Loss = 0.4479, Valid Loss = 0.4537\n",
      "Iteration 99/125: Train Loss = 0.4466, Valid Loss = 0.4525\n",
      "Iteration 100/125: Train Loss = 0.4454, Valid Loss = 0.4513\n",
      "Iteration 101/125: Train Loss = 0.4442, Valid Loss = 0.4501\n",
      "Iteration 102/125: Train Loss = 0.4430, Valid Loss = 0.4490\n",
      "Iteration 103/125: Train Loss = 0.4418, Valid Loss = 0.4478\n",
      "Iteration 104/125: Train Loss = 0.4406, Valid Loss = 0.4467\n",
      "Iteration 105/125: Train Loss = 0.4394, Valid Loss = 0.4455\n",
      "Iteration 106/125: Train Loss = 0.4382, Valid Loss = 0.4443\n",
      "Iteration 107/125: Train Loss = 0.4371, Valid Loss = 0.4432\n",
      "Iteration 108/125: Train Loss = 0.4360, Valid Loss = 0.4421\n",
      "Iteration 109/125: Train Loss = 0.4348, Valid Loss = 0.4410\n",
      "Iteration 110/125: Train Loss = 0.4337, Valid Loss = 0.4399\n",
      "Iteration 111/125: Train Loss = 0.4326, Valid Loss = 0.4388\n",
      "Iteration 112/125: Train Loss = 0.4315, Valid Loss = 0.4378\n",
      "Iteration 113/125: Train Loss = 0.4305, Valid Loss = 0.4367\n",
      "Iteration 114/125: Train Loss = 0.4294, Valid Loss = 0.4357\n",
      "Iteration 115/125: Train Loss = 0.4284, Valid Loss = 0.4347\n",
      "Iteration 116/125: Train Loss = 0.4273, Valid Loss = 0.4336\n",
      "Iteration 117/125: Train Loss = 0.4263, Valid Loss = 0.4326\n",
      "Iteration 118/125: Train Loss = 0.4252, Valid Loss = 0.4316\n",
      "Iteration 119/125: Train Loss = 0.4242, Valid Loss = 0.4306\n",
      "Iteration 120/125: Train Loss = 0.4232, Valid Loss = 0.4296\n",
      "Iteration 121/125: Train Loss = 0.4222, Valid Loss = 0.4287\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-05 00:51:27,283] Trial 30 finished with value: 0.9410799598885116 and parameters: {'max_depth': 3, 'min_samples_leaf': 16, 'n_estimators': 125, 'learning_rate': 0.03210410711854999, 'subsample': 0.748576283378865}. Best is trial 27 with value: 0.9657550072635349.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 122/125: Train Loss = 0.4213, Valid Loss = 0.4278\n",
      "Iteration 123/125: Train Loss = 0.4204, Valid Loss = 0.4269\n",
      "Iteration 124/125: Train Loss = 0.4194, Valid Loss = 0.4259\n",
      "Iteration 125/125: Train Loss = 0.4184, Valid Loss = 0.4250\n",
      "Iteration 1/70: Train Loss = 0.5942, Valid Loss = 0.5973\n",
      "Iteration 2/70: Train Loss = 0.5227, Valid Loss = 0.5282\n",
      "Iteration 3/70: Train Loss = 0.4690, Valid Loss = 0.4763\n",
      "Iteration 4/70: Train Loss = 0.4292, Valid Loss = 0.4387\n",
      "Iteration 5/70: Train Loss = 0.3978, Valid Loss = 0.4097\n",
      "Iteration 6/70: Train Loss = 0.3731, Valid Loss = 0.3872\n",
      "Iteration 7/70: Train Loss = 0.3542, Valid Loss = 0.3693\n",
      "Iteration 8/70: Train Loss = 0.3378, Valid Loss = 0.3550\n",
      "Iteration 9/70: Train Loss = 0.3241, Valid Loss = 0.3428\n",
      "Iteration 10/70: Train Loss = 0.3128, Valid Loss = 0.3319\n",
      "Iteration 11/70: Train Loss = 0.3021, Valid Loss = 0.3229\n",
      "Iteration 12/70: Train Loss = 0.2930, Valid Loss = 0.3152\n",
      "Iteration 13/70: Train Loss = 0.2852, Valid Loss = 0.3085\n",
      "Iteration 14/70: Train Loss = 0.2786, Valid Loss = 0.3027\n",
      "Iteration 15/70: Train Loss = 0.2727, Valid Loss = 0.2981\n",
      "Iteration 16/70: Train Loss = 0.2675, Valid Loss = 0.2936\n",
      "Iteration 17/70: Train Loss = 0.2631, Valid Loss = 0.2901\n",
      "Iteration 18/70: Train Loss = 0.2592, Valid Loss = 0.2866\n",
      "Iteration 19/70: Train Loss = 0.2555, Valid Loss = 0.2842\n",
      "Iteration 20/70: Train Loss = 0.2514, Valid Loss = 0.2807\n",
      "Iteration 21/70: Train Loss = 0.2478, Valid Loss = 0.2775\n",
      "Iteration 22/70: Train Loss = 0.2449, Valid Loss = 0.2750\n",
      "Iteration 23/70: Train Loss = 0.2418, Valid Loss = 0.2732\n",
      "Iteration 24/70: Train Loss = 0.2395, Valid Loss = 0.2717\n",
      "Iteration 25/70: Train Loss = 0.2372, Valid Loss = 0.2697\n",
      "Iteration 26/70: Train Loss = 0.2349, Valid Loss = 0.2680\n",
      "Iteration 27/70: Train Loss = 0.2328, Valid Loss = 0.2660\n",
      "Iteration 28/70: Train Loss = 0.2307, Valid Loss = 0.2647\n",
      "Iteration 29/70: Train Loss = 0.2285, Valid Loss = 0.2632\n",
      "Iteration 30/70: Train Loss = 0.2264, Valid Loss = 0.2618\n",
      "Iteration 31/70: Train Loss = 0.2251, Valid Loss = 0.2605\n",
      "Iteration 32/70: Train Loss = 0.2235, Valid Loss = 0.2595\n",
      "Iteration 33/70: Train Loss = 0.2219, Valid Loss = 0.2581\n",
      "Iteration 34/70: Train Loss = 0.2207, Valid Loss = 0.2575\n",
      "Iteration 35/70: Train Loss = 0.2192, Valid Loss = 0.2564\n",
      "Iteration 36/70: Train Loss = 0.2182, Valid Loss = 0.2561\n",
      "Iteration 37/70: Train Loss = 0.2169, Valid Loss = 0.2552\n",
      "Iteration 38/70: Train Loss = 0.2155, Valid Loss = 0.2549\n",
      "Iteration 39/70: Train Loss = 0.2144, Valid Loss = 0.2546\n",
      "Iteration 40/70: Train Loss = 0.2134, Valid Loss = 0.2537\n",
      "Iteration 41/70: Train Loss = 0.2122, Valid Loss = 0.2532\n",
      "Iteration 42/70: Train Loss = 0.2113, Valid Loss = 0.2527\n",
      "Iteration 43/70: Train Loss = 0.2102, Valid Loss = 0.2518\n",
      "Iteration 44/70: Train Loss = 0.2093, Valid Loss = 0.2513\n",
      "Iteration 45/70: Train Loss = 0.2080, Valid Loss = 0.2513\n",
      "Iteration 46/70: Train Loss = 0.2072, Valid Loss = 0.2509\n",
      "Iteration 47/70: Train Loss = 0.2065, Valid Loss = 0.2504\n",
      "Iteration 48/70: Train Loss = 0.2056, Valid Loss = 0.2498\n",
      "Iteration 49/70: Train Loss = 0.2049, Valid Loss = 0.2494\n",
      "Iteration 50/70: Train Loss = 0.2039, Valid Loss = 0.2488\n",
      "Iteration 51/70: Train Loss = 0.2032, Valid Loss = 0.2482\n",
      "Iteration 52/70: Train Loss = 0.2026, Valid Loss = 0.2482\n",
      "Iteration 53/70: Train Loss = 0.2017, Valid Loss = 0.2476\n",
      "Iteration 54/70: Train Loss = 0.2011, Valid Loss = 0.2476\n",
      "Iteration 55/70: Train Loss = 0.2004, Valid Loss = 0.2471\n",
      "Iteration 56/70: Train Loss = 0.1994, Valid Loss = 0.2466\n",
      "Iteration 57/70: Train Loss = 0.1990, Valid Loss = 0.2461\n",
      "Iteration 58/70: Train Loss = 0.1984, Valid Loss = 0.2457\n",
      "Iteration 59/70: Train Loss = 0.1979, Valid Loss = 0.2456\n",
      "Iteration 60/70: Train Loss = 0.1973, Valid Loss = 0.2457\n",
      "Iteration 61/70: Train Loss = 0.1965, Valid Loss = 0.2453\n",
      "Iteration 62/70: Train Loss = 0.1958, Valid Loss = 0.2450\n",
      "Iteration 63/70: Train Loss = 0.1950, Valid Loss = 0.2446\n",
      "Iteration 64/70: Train Loss = 0.1946, Valid Loss = 0.2445\n",
      "Iteration 65/70: Train Loss = 0.1942, Valid Loss = 0.2444\n",
      "Iteration 66/70: Train Loss = 0.1939, Valid Loss = 0.2445\n",
      "Iteration 67/70: Train Loss = 0.1935, Valid Loss = 0.2443\n",
      "Iteration 68/70: Train Loss = 0.1930, Valid Loss = 0.2442\n",
      "Iteration 69/70: Train Loss = 0.1922, Valid Loss = 0.2442\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-05 00:51:31,246] Trial 31 finished with value: 0.9649947191623867 and parameters: {'max_depth': 7, 'min_samples_leaf': 11, 'n_estimators': 70, 'learning_rate': 0.6314369375439696, 'subsample': 0.8414901069343628}. Best is trial 27 with value: 0.9657550072635349.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 70/70: Train Loss = 0.1918, Valid Loss = 0.2437\n",
      "Iteration 1/70: Train Loss = 0.6445, Valid Loss = 0.6462\n",
      "Iteration 2/70: Train Loss = 0.6027, Valid Loss = 0.6055\n",
      "Iteration 3/70: Train Loss = 0.5666, Valid Loss = 0.5708\n",
      "Iteration 4/70: Train Loss = 0.5350, Valid Loss = 0.5405\n",
      "Iteration 5/70: Train Loss = 0.5079, Valid Loss = 0.5145\n",
      "Iteration 6/70: Train Loss = 0.4842, Valid Loss = 0.4915\n",
      "Iteration 7/70: Train Loss = 0.4633, Valid Loss = 0.4714\n",
      "Iteration 8/70: Train Loss = 0.4446, Valid Loss = 0.4540\n",
      "Iteration 9/70: Train Loss = 0.4278, Valid Loss = 0.4380\n",
      "Iteration 10/70: Train Loss = 0.4128, Valid Loss = 0.4240\n",
      "Iteration 11/70: Train Loss = 0.3994, Valid Loss = 0.4113\n",
      "Iteration 12/70: Train Loss = 0.3875, Valid Loss = 0.4002\n",
      "Iteration 13/70: Train Loss = 0.3768, Valid Loss = 0.3902\n",
      "Iteration 14/70: Train Loss = 0.3670, Valid Loss = 0.3814\n",
      "Iteration 15/70: Train Loss = 0.3579, Valid Loss = 0.3738\n",
      "Iteration 16/70: Train Loss = 0.3497, Valid Loss = 0.3662\n",
      "Iteration 17/70: Train Loss = 0.3424, Valid Loss = 0.3591\n",
      "Iteration 18/70: Train Loss = 0.3353, Valid Loss = 0.3525\n",
      "Iteration 19/70: Train Loss = 0.3289, Valid Loss = 0.3468\n",
      "Iteration 20/70: Train Loss = 0.3231, Valid Loss = 0.3414\n",
      "Iteration 21/70: Train Loss = 0.3176, Valid Loss = 0.3361\n",
      "Iteration 22/70: Train Loss = 0.3127, Valid Loss = 0.3318\n",
      "Iteration 23/70: Train Loss = 0.3079, Valid Loss = 0.3275\n",
      "Iteration 24/70: Train Loss = 0.3033, Valid Loss = 0.3234\n",
      "Iteration 25/70: Train Loss = 0.2991, Valid Loss = 0.3196\n",
      "Iteration 26/70: Train Loss = 0.2953, Valid Loss = 0.3160\n",
      "Iteration 27/70: Train Loss = 0.2916, Valid Loss = 0.3126\n",
      "Iteration 28/70: Train Loss = 0.2882, Valid Loss = 0.3096\n",
      "Iteration 29/70: Train Loss = 0.2848, Valid Loss = 0.3065\n",
      "Iteration 30/70: Train Loss = 0.2818, Valid Loss = 0.3041\n",
      "Iteration 31/70: Train Loss = 0.2785, Valid Loss = 0.3017\n",
      "Iteration 32/70: Train Loss = 0.2756, Valid Loss = 0.2994\n",
      "Iteration 33/70: Train Loss = 0.2731, Valid Loss = 0.2972\n",
      "Iteration 34/70: Train Loss = 0.2704, Valid Loss = 0.2950\n",
      "Iteration 35/70: Train Loss = 0.2680, Valid Loss = 0.2931\n",
      "Iteration 36/70: Train Loss = 0.2656, Valid Loss = 0.2911\n",
      "Iteration 37/70: Train Loss = 0.2634, Valid Loss = 0.2892\n",
      "Iteration 38/70: Train Loss = 0.2613, Valid Loss = 0.2873\n",
      "Iteration 39/70: Train Loss = 0.2593, Valid Loss = 0.2856\n",
      "Iteration 40/70: Train Loss = 0.2574, Valid Loss = 0.2842\n",
      "Iteration 41/70: Train Loss = 0.2557, Valid Loss = 0.2827\n",
      "Iteration 42/70: Train Loss = 0.2538, Valid Loss = 0.2814\n",
      "Iteration 43/70: Train Loss = 0.2521, Valid Loss = 0.2799\n",
      "Iteration 44/70: Train Loss = 0.2504, Valid Loss = 0.2789\n",
      "Iteration 45/70: Train Loss = 0.2487, Valid Loss = 0.2776\n",
      "Iteration 46/70: Train Loss = 0.2470, Valid Loss = 0.2764\n",
      "Iteration 47/70: Train Loss = 0.2455, Valid Loss = 0.2752\n",
      "Iteration 48/70: Train Loss = 0.2442, Valid Loss = 0.2742\n",
      "Iteration 49/70: Train Loss = 0.2428, Valid Loss = 0.2732\n",
      "Iteration 50/70: Train Loss = 0.2415, Valid Loss = 0.2722\n",
      "Iteration 51/70: Train Loss = 0.2402, Valid Loss = 0.2712\n",
      "Iteration 52/70: Train Loss = 0.2391, Valid Loss = 0.2698\n",
      "Iteration 53/70: Train Loss = 0.2380, Valid Loss = 0.2689\n",
      "Iteration 54/70: Train Loss = 0.2368, Valid Loss = 0.2680\n",
      "Iteration 55/70: Train Loss = 0.2357, Valid Loss = 0.2674\n",
      "Iteration 56/70: Train Loss = 0.2346, Valid Loss = 0.2665\n",
      "Iteration 57/70: Train Loss = 0.2334, Valid Loss = 0.2658\n",
      "Iteration 58/70: Train Loss = 0.2323, Valid Loss = 0.2650\n",
      "Iteration 59/70: Train Loss = 0.2313, Valid Loss = 0.2643\n",
      "Iteration 60/70: Train Loss = 0.2304, Valid Loss = 0.2635\n",
      "Iteration 61/70: Train Loss = 0.2294, Valid Loss = 0.2628\n",
      "Iteration 62/70: Train Loss = 0.2285, Valid Loss = 0.2622\n",
      "Iteration 63/70: Train Loss = 0.2276, Valid Loss = 0.2617\n",
      "Iteration 64/70: Train Loss = 0.2267, Valid Loss = 0.2615\n",
      "Iteration 65/70: Train Loss = 0.2259, Valid Loss = 0.2609\n",
      "Iteration 66/70: Train Loss = 0.2250, Valid Loss = 0.2602\n",
      "Iteration 67/70: Train Loss = 0.2241, Valid Loss = 0.2597\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-05 00:51:35,238] Trial 32 finished with value: 0.9641646553729186 and parameters: {'max_depth': 7, 'min_samples_leaf': 9, 'n_estimators': 70, 'learning_rate': 0.29264101851603114, 'subsample': 0.838570752994886}. Best is trial 27 with value: 0.9657550072635349.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 68/70: Train Loss = 0.2233, Valid Loss = 0.2590\n",
      "Iteration 69/70: Train Loss = 0.2226, Valid Loss = 0.2586\n",
      "Iteration 70/70: Train Loss = 0.2218, Valid Loss = 0.2580\n",
      "Iteration 1/65: Train Loss = 0.5883, Valid Loss = 0.5924\n",
      "Iteration 2/65: Train Loss = 0.5130, Valid Loss = 0.5194\n",
      "Iteration 3/65: Train Loss = 0.4583, Valid Loss = 0.4669\n",
      "Iteration 4/65: Train Loss = 0.4166, Valid Loss = 0.4280\n",
      "Iteration 5/65: Train Loss = 0.3854, Valid Loss = 0.3994\n",
      "Iteration 6/65: Train Loss = 0.3600, Valid Loss = 0.3761\n",
      "Iteration 7/65: Train Loss = 0.3399, Valid Loss = 0.3584\n",
      "Iteration 8/65: Train Loss = 0.3227, Valid Loss = 0.3438\n",
      "Iteration 9/65: Train Loss = 0.3087, Valid Loss = 0.3317\n",
      "Iteration 10/65: Train Loss = 0.2974, Valid Loss = 0.3221\n",
      "Iteration 11/65: Train Loss = 0.2880, Valid Loss = 0.3149\n",
      "Iteration 12/65: Train Loss = 0.2796, Valid Loss = 0.3074\n",
      "Iteration 13/65: Train Loss = 0.2718, Valid Loss = 0.3003\n",
      "Iteration 14/65: Train Loss = 0.2648, Valid Loss = 0.2946\n",
      "Iteration 15/65: Train Loss = 0.2587, Valid Loss = 0.2898\n",
      "Iteration 16/65: Train Loss = 0.2532, Valid Loss = 0.2854\n",
      "Iteration 17/65: Train Loss = 0.2486, Valid Loss = 0.2817\n",
      "Iteration 18/65: Train Loss = 0.2438, Valid Loss = 0.2786\n",
      "Iteration 19/65: Train Loss = 0.2394, Valid Loss = 0.2759\n",
      "Iteration 20/65: Train Loss = 0.2354, Valid Loss = 0.2740\n",
      "Iteration 21/65: Train Loss = 0.2321, Valid Loss = 0.2715\n",
      "Iteration 22/65: Train Loss = 0.2289, Valid Loss = 0.2687\n",
      "Iteration 23/65: Train Loss = 0.2259, Valid Loss = 0.2676\n",
      "Iteration 24/65: Train Loss = 0.2234, Valid Loss = 0.2664\n",
      "Iteration 25/65: Train Loss = 0.2205, Valid Loss = 0.2652\n",
      "Iteration 26/65: Train Loss = 0.2177, Valid Loss = 0.2636\n",
      "Iteration 27/65: Train Loss = 0.2157, Valid Loss = 0.2625\n",
      "Iteration 28/65: Train Loss = 0.2133, Valid Loss = 0.2605\n",
      "Iteration 29/65: Train Loss = 0.2114, Valid Loss = 0.2589\n",
      "Iteration 30/65: Train Loss = 0.2095, Valid Loss = 0.2580\n",
      "Iteration 31/65: Train Loss = 0.2078, Valid Loss = 0.2563\n",
      "Iteration 32/65: Train Loss = 0.2059, Valid Loss = 0.2553\n",
      "Iteration 33/65: Train Loss = 0.2040, Valid Loss = 0.2542\n",
      "Iteration 34/65: Train Loss = 0.2028, Valid Loss = 0.2534\n",
      "Iteration 35/65: Train Loss = 0.2013, Valid Loss = 0.2525\n",
      "Iteration 36/65: Train Loss = 0.1999, Valid Loss = 0.2518\n",
      "Iteration 37/65: Train Loss = 0.1983, Valid Loss = 0.2509\n",
      "Iteration 38/65: Train Loss = 0.1972, Valid Loss = 0.2503\n",
      "Iteration 39/65: Train Loss = 0.1960, Valid Loss = 0.2500\n",
      "Iteration 40/65: Train Loss = 0.1949, Valid Loss = 0.2498\n",
      "Iteration 41/65: Train Loss = 0.1936, Valid Loss = 0.2494\n",
      "Iteration 42/65: Train Loss = 0.1923, Valid Loss = 0.2492\n",
      "Iteration 43/65: Train Loss = 0.1913, Valid Loss = 0.2482\n",
      "Iteration 44/65: Train Loss = 0.1903, Valid Loss = 0.2476\n",
      "Iteration 45/65: Train Loss = 0.1894, Valid Loss = 0.2477\n",
      "Iteration 46/65: Train Loss = 0.1884, Valid Loss = 0.2475\n",
      "Iteration 47/65: Train Loss = 0.1874, Valid Loss = 0.2470\n",
      "Iteration 48/65: Train Loss = 0.1864, Valid Loss = 0.2465\n",
      "Iteration 49/65: Train Loss = 0.1856, Valid Loss = 0.2464\n",
      "Iteration 50/65: Train Loss = 0.1847, Valid Loss = 0.2457\n",
      "Iteration 51/65: Train Loss = 0.1839, Valid Loss = 0.2452\n",
      "Iteration 52/65: Train Loss = 0.1831, Valid Loss = 0.2452\n",
      "Iteration 53/65: Train Loss = 0.1824, Valid Loss = 0.2450\n",
      "Iteration 54/65: Train Loss = 0.1816, Valid Loss = 0.2451\n",
      "Iteration 55/65: Train Loss = 0.1810, Valid Loss = 0.2448\n",
      "Iteration 56/65: Train Loss = 0.1804, Valid Loss = 0.2444\n",
      "Iteration 57/65: Train Loss = 0.1797, Valid Loss = 0.2441\n",
      "Iteration 58/65: Train Loss = 0.1789, Valid Loss = 0.2439\n",
      "Iteration 59/65: Train Loss = 0.1784, Valid Loss = 0.2440\n",
      "Iteration 60/65: Train Loss = 0.1778, Valid Loss = 0.2439\n",
      "Iteration 61/65: Train Loss = 0.1770, Valid Loss = 0.2439\n",
      "Iteration 62/65: Train Loss = 0.1764, Valid Loss = 0.2436\n",
      "Iteration 63/65: Train Loss = 0.1756, Valid Loss = 0.2437\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-05 00:51:39,566] Trial 33 finished with value: 0.9648158951305721 and parameters: {'max_depth': 9, 'min_samples_leaf': 11, 'n_estimators': 65, 'learning_rate': 0.6500436265890529, 'subsample': 0.7636354545560328}. Best is trial 27 with value: 0.9657550072635349.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 64/65: Train Loss = 0.1750, Valid Loss = 0.2436\n",
      "Iteration 65/65: Train Loss = 0.1745, Valid Loss = 0.2431\n",
      "Iteration 1/55: Train Loss = 0.6613, Valid Loss = 0.6622\n",
      "Iteration 2/55: Train Loss = 0.6322, Valid Loss = 0.6337\n",
      "Iteration 3/55: Train Loss = 0.6058, Valid Loss = 0.6079\n",
      "Iteration 4/55: Train Loss = 0.5814, Valid Loss = 0.5844\n",
      "Iteration 5/55: Train Loss = 0.5595, Valid Loss = 0.5633\n",
      "Iteration 6/55: Train Loss = 0.5395, Valid Loss = 0.5440\n",
      "Iteration 7/55: Train Loss = 0.5212, Valid Loss = 0.5264\n",
      "Iteration 8/55: Train Loss = 0.5046, Valid Loss = 0.5108\n",
      "Iteration 9/55: Train Loss = 0.4894, Valid Loss = 0.4963\n",
      "Iteration 10/55: Train Loss = 0.4755, Valid Loss = 0.4829\n",
      "Iteration 11/55: Train Loss = 0.4624, Valid Loss = 0.4705\n",
      "Iteration 12/55: Train Loss = 0.4505, Valid Loss = 0.4592\n",
      "Iteration 13/55: Train Loss = 0.4394, Valid Loss = 0.4486\n",
      "Iteration 14/55: Train Loss = 0.4291, Valid Loss = 0.4388\n",
      "Iteration 15/55: Train Loss = 0.4195, Valid Loss = 0.4297\n",
      "Iteration 16/55: Train Loss = 0.4106, Valid Loss = 0.4212\n",
      "Iteration 17/55: Train Loss = 0.4023, Valid Loss = 0.4135\n",
      "Iteration 18/55: Train Loss = 0.3947, Valid Loss = 0.4064\n",
      "Iteration 19/55: Train Loss = 0.3877, Valid Loss = 0.3994\n",
      "Iteration 20/55: Train Loss = 0.3809, Valid Loss = 0.3931\n",
      "Iteration 21/55: Train Loss = 0.3747, Valid Loss = 0.3871\n",
      "Iteration 22/55: Train Loss = 0.3687, Valid Loss = 0.3816\n",
      "Iteration 23/55: Train Loss = 0.3632, Valid Loss = 0.3764\n",
      "Iteration 24/55: Train Loss = 0.3579, Valid Loss = 0.3716\n",
      "Iteration 25/55: Train Loss = 0.3530, Valid Loss = 0.3671\n",
      "Iteration 26/55: Train Loss = 0.3482, Valid Loss = 0.3628\n",
      "Iteration 27/55: Train Loss = 0.3437, Valid Loss = 0.3586\n",
      "Iteration 28/55: Train Loss = 0.3393, Valid Loss = 0.3543\n",
      "Iteration 29/55: Train Loss = 0.3353, Valid Loss = 0.3508\n",
      "Iteration 30/55: Train Loss = 0.3316, Valid Loss = 0.3473\n",
      "Iteration 31/55: Train Loss = 0.3279, Valid Loss = 0.3438\n",
      "Iteration 32/55: Train Loss = 0.3244, Valid Loss = 0.3407\n",
      "Iteration 33/55: Train Loss = 0.3211, Valid Loss = 0.3375\n",
      "Iteration 34/55: Train Loss = 0.3179, Valid Loss = 0.3346\n",
      "Iteration 35/55: Train Loss = 0.3149, Valid Loss = 0.3317\n",
      "Iteration 36/55: Train Loss = 0.3118, Valid Loss = 0.3289\n",
      "Iteration 37/55: Train Loss = 0.3091, Valid Loss = 0.3264\n",
      "Iteration 38/55: Train Loss = 0.3064, Valid Loss = 0.3239\n",
      "Iteration 39/55: Train Loss = 0.3038, Valid Loss = 0.3216\n",
      "Iteration 40/55: Train Loss = 0.3012, Valid Loss = 0.3194\n",
      "Iteration 41/55: Train Loss = 0.2988, Valid Loss = 0.3173\n",
      "Iteration 42/55: Train Loss = 0.2966, Valid Loss = 0.3151\n",
      "Iteration 43/55: Train Loss = 0.2944, Valid Loss = 0.3131\n",
      "Iteration 44/55: Train Loss = 0.2923, Valid Loss = 0.3112\n",
      "Iteration 45/55: Train Loss = 0.2902, Valid Loss = 0.3093\n",
      "Iteration 46/55: Train Loss = 0.2881, Valid Loss = 0.3075\n",
      "Iteration 47/55: Train Loss = 0.2863, Valid Loss = 0.3059\n",
      "Iteration 48/55: Train Loss = 0.2844, Valid Loss = 0.3041\n",
      "Iteration 49/55: Train Loss = 0.2827, Valid Loss = 0.3026\n",
      "Iteration 50/55: Train Loss = 0.2810, Valid Loss = 0.3012\n",
      "Iteration 51/55: Train Loss = 0.2793, Valid Loss = 0.2996\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-05 00:51:42,297] Trial 34 finished with value: 0.9614113753436357 and parameters: {'max_depth': 6, 'min_samples_leaf': 5, 'n_estimators': 55, 'learning_rate': 0.19677515591519582, 'subsample': 0.8279177303013826}. Best is trial 27 with value: 0.9657550072635349.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 52/55: Train Loss = 0.2776, Valid Loss = 0.2981\n",
      "Iteration 53/55: Train Loss = 0.2760, Valid Loss = 0.2965\n",
      "Iteration 54/55: Train Loss = 0.2745, Valid Loss = 0.2953\n",
      "Iteration 55/55: Train Loss = 0.2730, Valid Loss = 0.2940\n",
      "Iteration 1/90: Train Loss = 0.6470, Valid Loss = 0.6478\n",
      "Iteration 2/90: Train Loss = 0.6075, Valid Loss = 0.6094\n",
      "Iteration 3/90: Train Loss = 0.5729, Valid Loss = 0.5758\n",
      "Iteration 4/90: Train Loss = 0.5433, Valid Loss = 0.5469\n",
      "Iteration 5/90: Train Loss = 0.5177, Valid Loss = 0.5217\n",
      "Iteration 6/90: Train Loss = 0.4957, Valid Loss = 0.5001\n",
      "Iteration 7/90: Train Loss = 0.4761, Valid Loss = 0.4812\n",
      "Iteration 8/90: Train Loss = 0.4592, Valid Loss = 0.4649\n",
      "Iteration 9/90: Train Loss = 0.4443, Valid Loss = 0.4505\n",
      "Iteration 10/90: Train Loss = 0.4307, Valid Loss = 0.4368\n",
      "Iteration 11/90: Train Loss = 0.4184, Valid Loss = 0.4251\n",
      "Iteration 12/90: Train Loss = 0.4073, Valid Loss = 0.4143\n",
      "Iteration 13/90: Train Loss = 0.3974, Valid Loss = 0.4042\n",
      "Iteration 14/90: Train Loss = 0.3884, Valid Loss = 0.3956\n",
      "Iteration 15/90: Train Loss = 0.3805, Valid Loss = 0.3884\n",
      "Iteration 16/90: Train Loss = 0.3732, Valid Loss = 0.3814\n",
      "Iteration 17/90: Train Loss = 0.3664, Valid Loss = 0.3745\n",
      "Iteration 18/90: Train Loss = 0.3600, Valid Loss = 0.3684\n",
      "Iteration 19/90: Train Loss = 0.3544, Valid Loss = 0.3629\n",
      "Iteration 20/90: Train Loss = 0.3493, Valid Loss = 0.3583\n",
      "Iteration 21/90: Train Loss = 0.3443, Valid Loss = 0.3534\n",
      "Iteration 22/90: Train Loss = 0.3397, Valid Loss = 0.3490\n",
      "Iteration 23/90: Train Loss = 0.3354, Valid Loss = 0.3447\n",
      "Iteration 24/90: Train Loss = 0.3314, Valid Loss = 0.3409\n",
      "Iteration 25/90: Train Loss = 0.3280, Valid Loss = 0.3375\n",
      "Iteration 26/90: Train Loss = 0.3243, Valid Loss = 0.3340\n",
      "Iteration 27/90: Train Loss = 0.3213, Valid Loss = 0.3311\n",
      "Iteration 28/90: Train Loss = 0.3183, Valid Loss = 0.3281\n",
      "Iteration 29/90: Train Loss = 0.3154, Valid Loss = 0.3254\n",
      "Iteration 30/90: Train Loss = 0.3125, Valid Loss = 0.3228\n",
      "Iteration 31/90: Train Loss = 0.3097, Valid Loss = 0.3201\n",
      "Iteration 32/90: Train Loss = 0.3071, Valid Loss = 0.3177\n",
      "Iteration 33/90: Train Loss = 0.3049, Valid Loss = 0.3153\n",
      "Iteration 34/90: Train Loss = 0.3026, Valid Loss = 0.3131\n",
      "Iteration 35/90: Train Loss = 0.3007, Valid Loss = 0.3115\n",
      "Iteration 36/90: Train Loss = 0.2986, Valid Loss = 0.3093\n",
      "Iteration 37/90: Train Loss = 0.2967, Valid Loss = 0.3074\n",
      "Iteration 38/90: Train Loss = 0.2946, Valid Loss = 0.3053\n",
      "Iteration 39/90: Train Loss = 0.2929, Valid Loss = 0.3038\n",
      "Iteration 40/90: Train Loss = 0.2912, Valid Loss = 0.3021\n",
      "Iteration 41/90: Train Loss = 0.2896, Valid Loss = 0.3005\n",
      "Iteration 42/90: Train Loss = 0.2882, Valid Loss = 0.2994\n",
      "Iteration 43/90: Train Loss = 0.2863, Valid Loss = 0.2979\n",
      "Iteration 44/90: Train Loss = 0.2849, Valid Loss = 0.2966\n",
      "Iteration 45/90: Train Loss = 0.2835, Valid Loss = 0.2952\n",
      "Iteration 46/90: Train Loss = 0.2821, Valid Loss = 0.2941\n",
      "Iteration 47/90: Train Loss = 0.2808, Valid Loss = 0.2929\n",
      "Iteration 48/90: Train Loss = 0.2795, Valid Loss = 0.2919\n",
      "Iteration 49/90: Train Loss = 0.2782, Valid Loss = 0.2909\n",
      "Iteration 50/90: Train Loss = 0.2769, Valid Loss = 0.2899\n",
      "Iteration 51/90: Train Loss = 0.2757, Valid Loss = 0.2886\n",
      "Iteration 52/90: Train Loss = 0.2745, Valid Loss = 0.2877\n",
      "Iteration 53/90: Train Loss = 0.2735, Valid Loss = 0.2867\n",
      "Iteration 54/90: Train Loss = 0.2725, Valid Loss = 0.2858\n",
      "Iteration 55/90: Train Loss = 0.2715, Valid Loss = 0.2848\n",
      "Iteration 56/90: Train Loss = 0.2704, Valid Loss = 0.2838\n",
      "Iteration 57/90: Train Loss = 0.2693, Valid Loss = 0.2828\n",
      "Iteration 58/90: Train Loss = 0.2684, Valid Loss = 0.2822\n",
      "Iteration 59/90: Train Loss = 0.2675, Valid Loss = 0.2815\n",
      "Iteration 60/90: Train Loss = 0.2666, Valid Loss = 0.2807\n",
      "Iteration 61/90: Train Loss = 0.2656, Valid Loss = 0.2800\n",
      "Iteration 62/90: Train Loss = 0.2648, Valid Loss = 0.2792\n",
      "Iteration 63/90: Train Loss = 0.2638, Valid Loss = 0.2783\n",
      "Iteration 64/90: Train Loss = 0.2630, Valid Loss = 0.2774\n",
      "Iteration 65/90: Train Loss = 0.2620, Valid Loss = 0.2765\n",
      "Iteration 66/90: Train Loss = 0.2612, Valid Loss = 0.2757\n",
      "Iteration 67/90: Train Loss = 0.2605, Valid Loss = 0.2753\n",
      "Iteration 68/90: Train Loss = 0.2597, Valid Loss = 0.2745\n",
      "Iteration 69/90: Train Loss = 0.2590, Valid Loss = 0.2738\n",
      "Iteration 70/90: Train Loss = 0.2584, Valid Loss = 0.2734\n",
      "Iteration 71/90: Train Loss = 0.2577, Valid Loss = 0.2728\n",
      "Iteration 72/90: Train Loss = 0.2572, Valid Loss = 0.2722\n",
      "Iteration 73/90: Train Loss = 0.2565, Valid Loss = 0.2717\n",
      "Iteration 74/90: Train Loss = 0.2557, Valid Loss = 0.2710\n",
      "Iteration 75/90: Train Loss = 0.2552, Valid Loss = 0.2704\n",
      "Iteration 76/90: Train Loss = 0.2546, Valid Loss = 0.2699\n",
      "Iteration 77/90: Train Loss = 0.2540, Valid Loss = 0.2693\n",
      "Iteration 78/90: Train Loss = 0.2535, Valid Loss = 0.2688\n",
      "Iteration 79/90: Train Loss = 0.2529, Valid Loss = 0.2684\n",
      "Iteration 80/90: Train Loss = 0.2523, Valid Loss = 0.2679\n",
      "Iteration 81/90: Train Loss = 0.2518, Valid Loss = 0.2676\n",
      "Iteration 82/90: Train Loss = 0.2512, Valid Loss = 0.2673\n",
      "Iteration 83/90: Train Loss = 0.2507, Valid Loss = 0.2666\n",
      "Iteration 84/90: Train Loss = 0.2502, Valid Loss = 0.2662\n",
      "Iteration 85/90: Train Loss = 0.2497, Valid Loss = 0.2657\n",
      "Iteration 86/90: Train Loss = 0.2493, Valid Loss = 0.2653\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-05 00:51:45,509] Trial 35 finished with value: 0.9611010069813817 and parameters: {'max_depth': 4, 'min_samples_leaf': 9, 'n_estimators': 90, 'learning_rate': 0.31605918454875487, 'subsample': 0.7880828896973697}. Best is trial 27 with value: 0.9657550072635349.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 87/90: Train Loss = 0.2488, Valid Loss = 0.2646\n",
      "Iteration 88/90: Train Loss = 0.2483, Valid Loss = 0.2643\n",
      "Iteration 89/90: Train Loss = 0.2477, Valid Loss = 0.2640\n",
      "Iteration 90/90: Train Loss = 0.2472, Valid Loss = 0.2637\n",
      "Iteration 1/140: Train Loss = 0.5839, Valid Loss = 0.5869\n",
      "Iteration 2/140: Train Loss = 0.5086, Valid Loss = 0.5135\n",
      "Iteration 3/140: Train Loss = 0.4561, Valid Loss = 0.4624\n",
      "Iteration 4/140: Train Loss = 0.4169, Valid Loss = 0.4245\n",
      "Iteration 5/140: Train Loss = 0.3875, Valid Loss = 0.3965\n",
      "Iteration 6/140: Train Loss = 0.3648, Valid Loss = 0.3743\n",
      "Iteration 7/140: Train Loss = 0.3464, Valid Loss = 0.3572\n",
      "Iteration 8/140: Train Loss = 0.3319, Valid Loss = 0.3439\n",
      "Iteration 9/140: Train Loss = 0.3201, Valid Loss = 0.3326\n",
      "Iteration 10/140: Train Loss = 0.3095, Valid Loss = 0.3238\n",
      "Iteration 11/140: Train Loss = 0.3006, Valid Loss = 0.3159\n",
      "Iteration 12/140: Train Loss = 0.2932, Valid Loss = 0.3090\n",
      "Iteration 13/140: Train Loss = 0.2861, Valid Loss = 0.3032\n",
      "Iteration 14/140: Train Loss = 0.2803, Valid Loss = 0.2981\n",
      "Iteration 15/140: Train Loss = 0.2750, Valid Loss = 0.2933\n",
      "Iteration 16/140: Train Loss = 0.2705, Valid Loss = 0.2892\n",
      "Iteration 17/140: Train Loss = 0.2665, Valid Loss = 0.2853\n",
      "Iteration 18/140: Train Loss = 0.2622, Valid Loss = 0.2813\n",
      "Iteration 19/140: Train Loss = 0.2583, Valid Loss = 0.2783\n",
      "Iteration 20/140: Train Loss = 0.2553, Valid Loss = 0.2758\n",
      "Iteration 21/140: Train Loss = 0.2524, Valid Loss = 0.2736\n",
      "Iteration 22/140: Train Loss = 0.2497, Valid Loss = 0.2717\n",
      "Iteration 23/140: Train Loss = 0.2467, Valid Loss = 0.2688\n",
      "Iteration 24/140: Train Loss = 0.2446, Valid Loss = 0.2674\n",
      "Iteration 25/140: Train Loss = 0.2423, Valid Loss = 0.2656\n",
      "Iteration 26/140: Train Loss = 0.2403, Valid Loss = 0.2636\n",
      "Iteration 27/140: Train Loss = 0.2381, Valid Loss = 0.2622\n",
      "Iteration 28/140: Train Loss = 0.2363, Valid Loss = 0.2606\n",
      "Iteration 29/140: Train Loss = 0.2347, Valid Loss = 0.2595\n",
      "Iteration 30/140: Train Loss = 0.2333, Valid Loss = 0.2586\n",
      "Iteration 31/140: Train Loss = 0.2318, Valid Loss = 0.2575\n",
      "Iteration 32/140: Train Loss = 0.2302, Valid Loss = 0.2569\n",
      "Iteration 33/140: Train Loss = 0.2287, Valid Loss = 0.2565\n",
      "Iteration 34/140: Train Loss = 0.2270, Valid Loss = 0.2559\n",
      "Iteration 35/140: Train Loss = 0.2258, Valid Loss = 0.2547\n",
      "Iteration 36/140: Train Loss = 0.2247, Valid Loss = 0.2539\n",
      "Iteration 37/140: Train Loss = 0.2233, Valid Loss = 0.2530\n",
      "Iteration 38/140: Train Loss = 0.2222, Valid Loss = 0.2526\n",
      "Iteration 39/140: Train Loss = 0.2211, Valid Loss = 0.2522\n",
      "Iteration 40/140: Train Loss = 0.2202, Valid Loss = 0.2518\n",
      "Iteration 41/140: Train Loss = 0.2192, Valid Loss = 0.2512\n",
      "Iteration 42/140: Train Loss = 0.2183, Valid Loss = 0.2502\n",
      "Iteration 43/140: Train Loss = 0.2174, Valid Loss = 0.2493\n",
      "Iteration 44/140: Train Loss = 0.2165, Valid Loss = 0.2488\n",
      "Iteration 45/140: Train Loss = 0.2158, Valid Loss = 0.2485\n",
      "Iteration 46/140: Train Loss = 0.2150, Valid Loss = 0.2479\n",
      "Iteration 47/140: Train Loss = 0.2144, Valid Loss = 0.2475\n",
      "Iteration 48/140: Train Loss = 0.2134, Valid Loss = 0.2475\n",
      "Iteration 49/140: Train Loss = 0.2126, Valid Loss = 0.2472\n",
      "Iteration 50/140: Train Loss = 0.2118, Valid Loss = 0.2466\n",
      "Iteration 51/140: Train Loss = 0.2113, Valid Loss = 0.2462\n",
      "Iteration 52/140: Train Loss = 0.2105, Valid Loss = 0.2457\n",
      "Iteration 53/140: Train Loss = 0.2097, Valid Loss = 0.2454\n",
      "Iteration 54/140: Train Loss = 0.2090, Valid Loss = 0.2452\n",
      "Iteration 55/140: Train Loss = 0.2083, Valid Loss = 0.2447\n",
      "Iteration 56/140: Train Loss = 0.2076, Valid Loss = 0.2445\n",
      "Iteration 57/140: Train Loss = 0.2072, Valid Loss = 0.2447\n",
      "Iteration 58/140: Train Loss = 0.2065, Valid Loss = 0.2444\n",
      "Iteration 59/140: Train Loss = 0.2061, Valid Loss = 0.2441\n",
      "Iteration 60/140: Train Loss = 0.2053, Valid Loss = 0.2436\n",
      "Iteration 61/140: Train Loss = 0.2049, Valid Loss = 0.2434\n",
      "Iteration 62/140: Train Loss = 0.2043, Valid Loss = 0.2431\n",
      "Iteration 63/140: Train Loss = 0.2038, Valid Loss = 0.2432\n",
      "Iteration 64/140: Train Loss = 0.2033, Valid Loss = 0.2431\n",
      "Iteration 65/140: Train Loss = 0.2028, Valid Loss = 0.2429\n",
      "Iteration 66/140: Train Loss = 0.2021, Valid Loss = 0.2425\n",
      "Iteration 67/140: Train Loss = 0.2016, Valid Loss = 0.2422\n",
      "Iteration 68/140: Train Loss = 0.2011, Valid Loss = 0.2421\n",
      "Iteration 69/140: Train Loss = 0.2007, Valid Loss = 0.2418\n",
      "Iteration 70/140: Train Loss = 0.2003, Valid Loss = 0.2415\n",
      "Iteration 71/140: Train Loss = 0.1999, Valid Loss = 0.2413\n",
      "Iteration 72/140: Train Loss = 0.1996, Valid Loss = 0.2412\n",
      "Iteration 73/140: Train Loss = 0.1993, Valid Loss = 0.2414\n",
      "Iteration 74/140: Train Loss = 0.1989, Valid Loss = 0.2413\n",
      "Iteration 75/140: Train Loss = 0.1985, Valid Loss = 0.2411\n",
      "Iteration 76/140: Train Loss = 0.1982, Valid Loss = 0.2412\n",
      "Iteration 77/140: Train Loss = 0.1976, Valid Loss = 0.2413\n",
      "Iteration 78/140: Train Loss = 0.1972, Valid Loss = 0.2414\n",
      "Iteration 79/140: Train Loss = 0.1968, Valid Loss = 0.2414\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-05 00:51:49,518] Trial 36 finished with value: 0.9650458117429052 and parameters: {'max_depth': 6, 'min_samples_leaf': 14, 'n_estimators': 140, 'learning_rate': 0.7234446962053851, 'subsample': 0.8652769824890513}. Best is trial 27 with value: 0.9657550072635349.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 80/140: Train Loss = 0.1966, Valid Loss = 0.2413\n",
      "Iteration 81/140: Train Loss = 0.1963, Valid Loss = 0.2415\n",
      "Early stopping triggered.\n",
      "Iteration 1/140: Train Loss = 0.6316, Valid Loss = 0.6330\n",
      "Iteration 2/140: Train Loss = 0.5810, Valid Loss = 0.5840\n",
      "Iteration 3/140: Train Loss = 0.5396, Valid Loss = 0.5441\n",
      "Iteration 4/140: Train Loss = 0.5052, Valid Loss = 0.5108\n",
      "Iteration 5/140: Train Loss = 0.4763, Valid Loss = 0.4826\n",
      "Iteration 6/140: Train Loss = 0.4520, Valid Loss = 0.4595\n",
      "Iteration 7/140: Train Loss = 0.4309, Valid Loss = 0.4391\n",
      "Iteration 8/140: Train Loss = 0.4128, Valid Loss = 0.4220\n",
      "Iteration 9/140: Train Loss = 0.3971, Valid Loss = 0.4065\n",
      "Iteration 10/140: Train Loss = 0.3835, Valid Loss = 0.3939\n",
      "Iteration 11/140: Train Loss = 0.3713, Valid Loss = 0.3826\n",
      "Iteration 12/140: Train Loss = 0.3605, Valid Loss = 0.3724\n",
      "Iteration 13/140: Train Loss = 0.3510, Valid Loss = 0.3637\n",
      "Iteration 14/140: Train Loss = 0.3423, Valid Loss = 0.3555\n",
      "Iteration 15/140: Train Loss = 0.3340, Valid Loss = 0.3482\n",
      "Iteration 16/140: Train Loss = 0.3269, Valid Loss = 0.3416\n",
      "Iteration 17/140: Train Loss = 0.3207, Valid Loss = 0.3353\n",
      "Iteration 18/140: Train Loss = 0.3146, Valid Loss = 0.3301\n",
      "Iteration 19/140: Train Loss = 0.3092, Valid Loss = 0.3250\n",
      "Iteration 20/140: Train Loss = 0.3044, Valid Loss = 0.3204\n",
      "Iteration 21/140: Train Loss = 0.3001, Valid Loss = 0.3164\n",
      "Iteration 22/140: Train Loss = 0.2957, Valid Loss = 0.3127\n",
      "Iteration 23/140: Train Loss = 0.2918, Valid Loss = 0.3092\n",
      "Iteration 24/140: Train Loss = 0.2884, Valid Loss = 0.3060\n",
      "Iteration 25/140: Train Loss = 0.2851, Valid Loss = 0.3031\n",
      "Iteration 26/140: Train Loss = 0.2820, Valid Loss = 0.3003\n",
      "Iteration 27/140: Train Loss = 0.2790, Valid Loss = 0.2976\n",
      "Iteration 28/140: Train Loss = 0.2764, Valid Loss = 0.2954\n",
      "Iteration 29/140: Train Loss = 0.2738, Valid Loss = 0.2929\n",
      "Iteration 30/140: Train Loss = 0.2711, Valid Loss = 0.2907\n",
      "Iteration 31/140: Train Loss = 0.2687, Valid Loss = 0.2885\n",
      "Iteration 32/140: Train Loss = 0.2665, Valid Loss = 0.2870\n",
      "Iteration 33/140: Train Loss = 0.2640, Valid Loss = 0.2848\n",
      "Iteration 34/140: Train Loss = 0.2621, Valid Loss = 0.2831\n",
      "Iteration 35/140: Train Loss = 0.2602, Valid Loss = 0.2818\n",
      "Iteration 36/140: Train Loss = 0.2585, Valid Loss = 0.2804\n",
      "Iteration 37/140: Train Loss = 0.2563, Valid Loss = 0.2789\n",
      "Iteration 38/140: Train Loss = 0.2546, Valid Loss = 0.2773\n",
      "Iteration 39/140: Train Loss = 0.2528, Valid Loss = 0.2758\n",
      "Iteration 40/140: Train Loss = 0.2511, Valid Loss = 0.2745\n",
      "Iteration 41/140: Train Loss = 0.2498, Valid Loss = 0.2735\n",
      "Iteration 42/140: Train Loss = 0.2483, Valid Loss = 0.2721\n",
      "Iteration 43/140: Train Loss = 0.2469, Valid Loss = 0.2711\n",
      "Iteration 44/140: Train Loss = 0.2455, Valid Loss = 0.2700\n",
      "Iteration 45/140: Train Loss = 0.2442, Valid Loss = 0.2686\n",
      "Iteration 46/140: Train Loss = 0.2429, Valid Loss = 0.2675\n",
      "Iteration 47/140: Train Loss = 0.2416, Valid Loss = 0.2664\n",
      "Iteration 48/140: Train Loss = 0.2405, Valid Loss = 0.2657\n",
      "Iteration 49/140: Train Loss = 0.2395, Valid Loss = 0.2650\n",
      "Iteration 50/140: Train Loss = 0.2383, Valid Loss = 0.2642\n",
      "Iteration 51/140: Train Loss = 0.2373, Valid Loss = 0.2630\n",
      "Iteration 52/140: Train Loss = 0.2364, Valid Loss = 0.2620\n",
      "Iteration 53/140: Train Loss = 0.2353, Valid Loss = 0.2612\n",
      "Iteration 54/140: Train Loss = 0.2344, Valid Loss = 0.2607\n",
      "Iteration 55/140: Train Loss = 0.2337, Valid Loss = 0.2604\n",
      "Iteration 56/140: Train Loss = 0.2329, Valid Loss = 0.2596\n",
      "Iteration 57/140: Train Loss = 0.2321, Valid Loss = 0.2589\n",
      "Iteration 58/140: Train Loss = 0.2313, Valid Loss = 0.2585\n",
      "Iteration 59/140: Train Loss = 0.2304, Valid Loss = 0.2578\n",
      "Iteration 60/140: Train Loss = 0.2297, Valid Loss = 0.2575\n",
      "Iteration 61/140: Train Loss = 0.2289, Valid Loss = 0.2569\n",
      "Iteration 62/140: Train Loss = 0.2281, Valid Loss = 0.2564\n",
      "Iteration 63/140: Train Loss = 0.2276, Valid Loss = 0.2558\n",
      "Iteration 64/140: Train Loss = 0.2269, Valid Loss = 0.2551\n",
      "Iteration 65/140: Train Loss = 0.2261, Valid Loss = 0.2547\n",
      "Iteration 66/140: Train Loss = 0.2255, Valid Loss = 0.2545\n",
      "Iteration 67/140: Train Loss = 0.2249, Valid Loss = 0.2541\n",
      "Iteration 68/140: Train Loss = 0.2244, Valid Loss = 0.2535\n",
      "Iteration 69/140: Train Loss = 0.2238, Valid Loss = 0.2531\n",
      "Iteration 70/140: Train Loss = 0.2232, Valid Loss = 0.2527\n",
      "Iteration 71/140: Train Loss = 0.2226, Valid Loss = 0.2524\n",
      "Iteration 72/140: Train Loss = 0.2219, Valid Loss = 0.2520\n",
      "Iteration 73/140: Train Loss = 0.2214, Valid Loss = 0.2516\n",
      "Iteration 74/140: Train Loss = 0.2208, Valid Loss = 0.2511\n",
      "Iteration 75/140: Train Loss = 0.2203, Valid Loss = 0.2508\n",
      "Iteration 76/140: Train Loss = 0.2197, Valid Loss = 0.2503\n",
      "Iteration 77/140: Train Loss = 0.2191, Valid Loss = 0.2497\n",
      "Iteration 78/140: Train Loss = 0.2185, Valid Loss = 0.2496\n",
      "Iteration 79/140: Train Loss = 0.2180, Valid Loss = 0.2493\n",
      "Iteration 80/140: Train Loss = 0.2176, Valid Loss = 0.2491\n",
      "Iteration 81/140: Train Loss = 0.2171, Valid Loss = 0.2489\n",
      "Iteration 82/140: Train Loss = 0.2166, Valid Loss = 0.2486\n",
      "Iteration 83/140: Train Loss = 0.2161, Valid Loss = 0.2486\n",
      "Iteration 84/140: Train Loss = 0.2157, Valid Loss = 0.2482\n",
      "Iteration 85/140: Train Loss = 0.2152, Valid Loss = 0.2480\n",
      "Iteration 86/140: Train Loss = 0.2148, Valid Loss = 0.2477\n",
      "Iteration 87/140: Train Loss = 0.2143, Valid Loss = 0.2473\n",
      "Iteration 88/140: Train Loss = 0.2139, Valid Loss = 0.2470\n",
      "Iteration 89/140: Train Loss = 0.2135, Valid Loss = 0.2468\n",
      "Iteration 90/140: Train Loss = 0.2130, Valid Loss = 0.2468\n",
      "Iteration 91/140: Train Loss = 0.2125, Valid Loss = 0.2466\n",
      "Iteration 92/140: Train Loss = 0.2121, Valid Loss = 0.2464\n",
      "Iteration 93/140: Train Loss = 0.2117, Valid Loss = 0.2462\n",
      "Iteration 94/140: Train Loss = 0.2113, Valid Loss = 0.2461\n",
      "Iteration 95/140: Train Loss = 0.2111, Valid Loss = 0.2461\n",
      "Iteration 96/140: Train Loss = 0.2107, Valid Loss = 0.2459\n",
      "Iteration 97/140: Train Loss = 0.2105, Valid Loss = 0.2456\n",
      "Iteration 98/140: Train Loss = 0.2100, Valid Loss = 0.2452\n",
      "Iteration 99/140: Train Loss = 0.2096, Valid Loss = 0.2454\n",
      "Iteration 100/140: Train Loss = 0.2092, Valid Loss = 0.2450\n",
      "Iteration 101/140: Train Loss = 0.2090, Valid Loss = 0.2449\n",
      "Iteration 102/140: Train Loss = 0.2087, Valid Loss = 0.2448\n",
      "Iteration 103/140: Train Loss = 0.2084, Valid Loss = 0.2446\n",
      "Iteration 104/140: Train Loss = 0.2081, Valid Loss = 0.2444\n",
      "Iteration 105/140: Train Loss = 0.2076, Valid Loss = 0.2443\n",
      "Iteration 106/140: Train Loss = 0.2071, Valid Loss = 0.2443\n",
      "Iteration 107/140: Train Loss = 0.2068, Valid Loss = 0.2442\n",
      "Iteration 108/140: Train Loss = 0.2065, Valid Loss = 0.2442\n",
      "Iteration 109/140: Train Loss = 0.2061, Valid Loss = 0.2437\n",
      "Iteration 110/140: Train Loss = 0.2058, Valid Loss = 0.2436\n",
      "Iteration 111/140: Train Loss = 0.2055, Valid Loss = 0.2433\n",
      "Iteration 112/140: Train Loss = 0.2051, Valid Loss = 0.2432\n",
      "Iteration 113/140: Train Loss = 0.2048, Valid Loss = 0.2431\n",
      "Iteration 114/140: Train Loss = 0.2045, Valid Loss = 0.2430\n",
      "Iteration 115/140: Train Loss = 0.2043, Valid Loss = 0.2428\n",
      "Iteration 116/140: Train Loss = 0.2040, Valid Loss = 0.2427\n",
      "Iteration 117/140: Train Loss = 0.2037, Valid Loss = 0.2428\n",
      "Iteration 118/140: Train Loss = 0.2033, Valid Loss = 0.2426\n",
      "Iteration 119/140: Train Loss = 0.2031, Valid Loss = 0.2425\n",
      "Iteration 120/140: Train Loss = 0.2027, Valid Loss = 0.2426\n",
      "Iteration 121/140: Train Loss = 0.2024, Valid Loss = 0.2425\n",
      "Iteration 122/140: Train Loss = 0.2021, Valid Loss = 0.2424\n",
      "Iteration 123/140: Train Loss = 0.2018, Valid Loss = 0.2423\n",
      "Iteration 124/140: Train Loss = 0.2016, Valid Loss = 0.2422\n",
      "Iteration 125/140: Train Loss = 0.2012, Valid Loss = 0.2420\n",
      "Iteration 126/140: Train Loss = 0.2009, Valid Loss = 0.2419\n",
      "Iteration 127/140: Train Loss = 0.2006, Valid Loss = 0.2417\n",
      "Iteration 128/140: Train Loss = 0.2004, Valid Loss = 0.2415\n",
      "Iteration 129/140: Train Loss = 0.2002, Valid Loss = 0.2416\n",
      "Iteration 130/140: Train Loss = 0.1999, Valid Loss = 0.2414\n",
      "Iteration 131/140: Train Loss = 0.1998, Valid Loss = 0.2415\n",
      "Iteration 132/140: Train Loss = 0.1996, Valid Loss = 0.2414\n",
      "Iteration 133/140: Train Loss = 0.1993, Valid Loss = 0.2412\n",
      "Iteration 134/140: Train Loss = 0.1989, Valid Loss = 0.2409\n",
      "Iteration 135/140: Train Loss = 0.1987, Valid Loss = 0.2410\n",
      "Iteration 136/140: Train Loss = 0.1985, Valid Loss = 0.2409\n",
      "Iteration 137/140: Train Loss = 0.1982, Valid Loss = 0.2407\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-05 00:51:56,707] Trial 37 finished with value: 0.9652017584998609 and parameters: {'max_depth': 6, 'min_samples_leaf': 14, 'n_estimators': 140, 'learning_rate': 0.38820432920167947, 'subsample': 0.886972000981122}. Best is trial 27 with value: 0.9657550072635349.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 138/140: Train Loss = 0.1979, Valid Loss = 0.2409\n",
      "Iteration 139/140: Train Loss = 0.1976, Valid Loss = 0.2409\n",
      "Iteration 140/140: Train Loss = 0.1974, Valid Loss = 0.2410\n",
      "Iteration 1/135: Train Loss = 0.6323, Valid Loss = 0.6337\n",
      "Iteration 2/135: Train Loss = 0.5834, Valid Loss = 0.5860\n",
      "Iteration 3/135: Train Loss = 0.5424, Valid Loss = 0.5457\n",
      "Iteration 4/135: Train Loss = 0.5087, Valid Loss = 0.5128\n",
      "Iteration 5/135: Train Loss = 0.4807, Valid Loss = 0.4854\n",
      "Iteration 6/135: Train Loss = 0.4572, Valid Loss = 0.4627\n",
      "Iteration 7/135: Train Loss = 0.4368, Valid Loss = 0.4430\n",
      "Iteration 8/135: Train Loss = 0.4192, Valid Loss = 0.4264\n",
      "Iteration 9/135: Train Loss = 0.4035, Valid Loss = 0.4112\n",
      "Iteration 10/135: Train Loss = 0.3902, Valid Loss = 0.3988\n",
      "Iteration 11/135: Train Loss = 0.3788, Valid Loss = 0.3882\n",
      "Iteration 12/135: Train Loss = 0.3685, Valid Loss = 0.3784\n",
      "Iteration 13/135: Train Loss = 0.3594, Valid Loss = 0.3698\n",
      "Iteration 14/135: Train Loss = 0.3510, Valid Loss = 0.3618\n",
      "Iteration 15/135: Train Loss = 0.3438, Valid Loss = 0.3551\n",
      "Iteration 16/135: Train Loss = 0.3369, Valid Loss = 0.3483\n",
      "Iteration 17/135: Train Loss = 0.3307, Valid Loss = 0.3426\n",
      "Iteration 18/135: Train Loss = 0.3250, Valid Loss = 0.3370\n",
      "Iteration 19/135: Train Loss = 0.3200, Valid Loss = 0.3322\n",
      "Iteration 20/135: Train Loss = 0.3156, Valid Loss = 0.3280\n",
      "Iteration 21/135: Train Loss = 0.3114, Valid Loss = 0.3240\n",
      "Iteration 22/135: Train Loss = 0.3076, Valid Loss = 0.3204\n",
      "Iteration 23/135: Train Loss = 0.3038, Valid Loss = 0.3167\n",
      "Iteration 24/135: Train Loss = 0.3001, Valid Loss = 0.3137\n",
      "Iteration 25/135: Train Loss = 0.2970, Valid Loss = 0.3108\n",
      "Iteration 26/135: Train Loss = 0.2941, Valid Loss = 0.3080\n",
      "Iteration 27/135: Train Loss = 0.2909, Valid Loss = 0.3049\n",
      "Iteration 28/135: Train Loss = 0.2883, Valid Loss = 0.3026\n",
      "Iteration 29/135: Train Loss = 0.2858, Valid Loss = 0.3004\n",
      "Iteration 30/135: Train Loss = 0.2833, Valid Loss = 0.2984\n",
      "Iteration 31/135: Train Loss = 0.2811, Valid Loss = 0.2966\n",
      "Iteration 32/135: Train Loss = 0.2789, Valid Loss = 0.2947\n",
      "Iteration 33/135: Train Loss = 0.2768, Valid Loss = 0.2928\n",
      "Iteration 34/135: Train Loss = 0.2749, Valid Loss = 0.2908\n",
      "Iteration 35/135: Train Loss = 0.2732, Valid Loss = 0.2893\n",
      "Iteration 36/135: Train Loss = 0.2715, Valid Loss = 0.2880\n",
      "Iteration 37/135: Train Loss = 0.2698, Valid Loss = 0.2863\n",
      "Iteration 38/135: Train Loss = 0.2681, Valid Loss = 0.2848\n",
      "Iteration 39/135: Train Loss = 0.2665, Valid Loss = 0.2837\n",
      "Iteration 40/135: Train Loss = 0.2649, Valid Loss = 0.2822\n",
      "Iteration 41/135: Train Loss = 0.2634, Valid Loss = 0.2808\n",
      "Iteration 42/135: Train Loss = 0.2620, Valid Loss = 0.2797\n",
      "Iteration 43/135: Train Loss = 0.2607, Valid Loss = 0.2785\n",
      "Iteration 44/135: Train Loss = 0.2594, Valid Loss = 0.2770\n",
      "Iteration 45/135: Train Loss = 0.2581, Valid Loss = 0.2757\n",
      "Iteration 46/135: Train Loss = 0.2567, Valid Loss = 0.2747\n",
      "Iteration 47/135: Train Loss = 0.2554, Valid Loss = 0.2738\n",
      "Iteration 48/135: Train Loss = 0.2540, Valid Loss = 0.2722\n",
      "Iteration 49/135: Train Loss = 0.2530, Valid Loss = 0.2710\n",
      "Iteration 50/135: Train Loss = 0.2521, Valid Loss = 0.2701\n",
      "Iteration 51/135: Train Loss = 0.2511, Valid Loss = 0.2688\n",
      "Iteration 52/135: Train Loss = 0.2502, Valid Loss = 0.2677\n",
      "Iteration 53/135: Train Loss = 0.2492, Valid Loss = 0.2670\n",
      "Iteration 54/135: Train Loss = 0.2484, Valid Loss = 0.2664\n",
      "Iteration 55/135: Train Loss = 0.2475, Valid Loss = 0.2658\n",
      "Iteration 56/135: Train Loss = 0.2467, Valid Loss = 0.2655\n",
      "Iteration 57/135: Train Loss = 0.2458, Valid Loss = 0.2649\n",
      "Iteration 58/135: Train Loss = 0.2449, Valid Loss = 0.2643\n",
      "Iteration 59/135: Train Loss = 0.2440, Valid Loss = 0.2637\n",
      "Iteration 60/135: Train Loss = 0.2433, Valid Loss = 0.2633\n",
      "Iteration 61/135: Train Loss = 0.2426, Valid Loss = 0.2628\n",
      "Iteration 62/135: Train Loss = 0.2419, Valid Loss = 0.2624\n",
      "Iteration 63/135: Train Loss = 0.2411, Valid Loss = 0.2618\n",
      "Iteration 64/135: Train Loss = 0.2404, Valid Loss = 0.2613\n",
      "Iteration 65/135: Train Loss = 0.2397, Valid Loss = 0.2609\n",
      "Iteration 66/135: Train Loss = 0.2391, Valid Loss = 0.2605\n",
      "Iteration 67/135: Train Loss = 0.2383, Valid Loss = 0.2597\n",
      "Iteration 68/135: Train Loss = 0.2377, Valid Loss = 0.2590\n",
      "Iteration 69/135: Train Loss = 0.2371, Valid Loss = 0.2586\n",
      "Iteration 70/135: Train Loss = 0.2365, Valid Loss = 0.2581\n",
      "Iteration 71/135: Train Loss = 0.2360, Valid Loss = 0.2579\n",
      "Iteration 72/135: Train Loss = 0.2353, Valid Loss = 0.2577\n",
      "Iteration 73/135: Train Loss = 0.2348, Valid Loss = 0.2575\n",
      "Iteration 74/135: Train Loss = 0.2341, Valid Loss = 0.2570\n",
      "Iteration 75/135: Train Loss = 0.2337, Valid Loss = 0.2566\n",
      "Iteration 76/135: Train Loss = 0.2332, Valid Loss = 0.2561\n",
      "Iteration 77/135: Train Loss = 0.2327, Valid Loss = 0.2557\n",
      "Iteration 78/135: Train Loss = 0.2322, Valid Loss = 0.2553\n",
      "Iteration 79/135: Train Loss = 0.2317, Valid Loss = 0.2548\n",
      "Iteration 80/135: Train Loss = 0.2310, Valid Loss = 0.2544\n",
      "Iteration 81/135: Train Loss = 0.2306, Valid Loss = 0.2540\n",
      "Iteration 82/135: Train Loss = 0.2299, Valid Loss = 0.2533\n",
      "Iteration 83/135: Train Loss = 0.2295, Valid Loss = 0.2530\n",
      "Iteration 84/135: Train Loss = 0.2290, Valid Loss = 0.2525\n",
      "Iteration 85/135: Train Loss = 0.2285, Valid Loss = 0.2523\n",
      "Iteration 86/135: Train Loss = 0.2281, Valid Loss = 0.2520\n",
      "Iteration 87/135: Train Loss = 0.2276, Valid Loss = 0.2516\n",
      "Iteration 88/135: Train Loss = 0.2272, Valid Loss = 0.2512\n",
      "Iteration 89/135: Train Loss = 0.2268, Valid Loss = 0.2509\n",
      "Iteration 90/135: Train Loss = 0.2263, Valid Loss = 0.2505\n",
      "Iteration 91/135: Train Loss = 0.2259, Valid Loss = 0.2501\n",
      "Iteration 92/135: Train Loss = 0.2255, Valid Loss = 0.2500\n",
      "Iteration 93/135: Train Loss = 0.2251, Valid Loss = 0.2496\n",
      "Iteration 94/135: Train Loss = 0.2246, Valid Loss = 0.2495\n",
      "Iteration 95/135: Train Loss = 0.2243, Valid Loss = 0.2494\n",
      "Iteration 96/135: Train Loss = 0.2239, Valid Loss = 0.2491\n",
      "Iteration 97/135: Train Loss = 0.2235, Valid Loss = 0.2489\n",
      "Iteration 98/135: Train Loss = 0.2231, Valid Loss = 0.2484\n",
      "Iteration 99/135: Train Loss = 0.2228, Valid Loss = 0.2483\n",
      "Iteration 100/135: Train Loss = 0.2224, Valid Loss = 0.2478\n",
      "Iteration 101/135: Train Loss = 0.2221, Valid Loss = 0.2477\n",
      "Iteration 102/135: Train Loss = 0.2218, Valid Loss = 0.2474\n",
      "Iteration 103/135: Train Loss = 0.2214, Valid Loss = 0.2473\n",
      "Iteration 104/135: Train Loss = 0.2210, Valid Loss = 0.2472\n",
      "Iteration 105/135: Train Loss = 0.2208, Valid Loss = 0.2470\n",
      "Iteration 106/135: Train Loss = 0.2203, Valid Loss = 0.2470\n",
      "Iteration 107/135: Train Loss = 0.2200, Valid Loss = 0.2468\n",
      "Iteration 108/135: Train Loss = 0.2197, Valid Loss = 0.2465\n",
      "Iteration 109/135: Train Loss = 0.2195, Valid Loss = 0.2464\n",
      "Iteration 110/135: Train Loss = 0.2192, Valid Loss = 0.2461\n",
      "Iteration 111/135: Train Loss = 0.2187, Valid Loss = 0.2457\n",
      "Iteration 112/135: Train Loss = 0.2184, Valid Loss = 0.2454\n",
      "Iteration 113/135: Train Loss = 0.2181, Valid Loss = 0.2454\n",
      "Iteration 114/135: Train Loss = 0.2178, Valid Loss = 0.2454\n",
      "Iteration 115/135: Train Loss = 0.2176, Valid Loss = 0.2451\n",
      "Iteration 116/135: Train Loss = 0.2174, Valid Loss = 0.2451\n",
      "Iteration 117/135: Train Loss = 0.2171, Valid Loss = 0.2449\n",
      "Iteration 118/135: Train Loss = 0.2168, Valid Loss = 0.2449\n",
      "Iteration 119/135: Train Loss = 0.2165, Valid Loss = 0.2446\n",
      "Iteration 120/135: Train Loss = 0.2163, Valid Loss = 0.2444\n",
      "Iteration 121/135: Train Loss = 0.2161, Valid Loss = 0.2443\n",
      "Iteration 122/135: Train Loss = 0.2158, Valid Loss = 0.2444\n",
      "Iteration 123/135: Train Loss = 0.2156, Valid Loss = 0.2441\n",
      "Iteration 124/135: Train Loss = 0.2152, Valid Loss = 0.2439\n",
      "Iteration 125/135: Train Loss = 0.2150, Valid Loss = 0.2439\n",
      "Iteration 126/135: Train Loss = 0.2147, Valid Loss = 0.2436\n",
      "Iteration 127/135: Train Loss = 0.2144, Valid Loss = 0.2436\n",
      "Iteration 128/135: Train Loss = 0.2143, Valid Loss = 0.2434\n",
      "Iteration 129/135: Train Loss = 0.2140, Valid Loss = 0.2433\n",
      "Iteration 130/135: Train Loss = 0.2138, Valid Loss = 0.2431\n",
      "Iteration 131/135: Train Loss = 0.2136, Valid Loss = 0.2428\n",
      "Iteration 132/135: Train Loss = 0.2132, Valid Loss = 0.2427\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-05 00:52:01,991] Trial 38 finished with value: 0.9651956578932318 and parameters: {'max_depth': 5, 'min_samples_leaf': 16, 'n_estimators': 135, 'learning_rate': 0.39515783736370624, 'subsample': 0.6034108461987672}. Best is trial 27 with value: 0.9657550072635349.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 133/135: Train Loss = 0.2130, Valid Loss = 0.2426\n",
      "Iteration 134/135: Train Loss = 0.2128, Valid Loss = 0.2425\n",
      "Iteration 135/135: Train Loss = 0.2125, Valid Loss = 0.2423\n",
      "Iteration 1/135: Train Loss = 0.6810, Valid Loss = 0.6811\n",
      "Iteration 2/135: Train Loss = 0.6694, Valid Loss = 0.6698\n",
      "Iteration 3/135: Train Loss = 0.6583, Valid Loss = 0.6589\n",
      "Iteration 4/135: Train Loss = 0.6478, Valid Loss = 0.6486\n",
      "Iteration 5/135: Train Loss = 0.6374, Valid Loss = 0.6385\n",
      "Iteration 6/135: Train Loss = 0.6277, Valid Loss = 0.6291\n",
      "Iteration 7/135: Train Loss = 0.6182, Valid Loss = 0.6198\n",
      "Iteration 8/135: Train Loss = 0.6091, Valid Loss = 0.6111\n",
      "Iteration 9/135: Train Loss = 0.6003, Valid Loss = 0.6024\n",
      "Iteration 10/135: Train Loss = 0.5920, Valid Loss = 0.5942\n",
      "Iteration 11/135: Train Loss = 0.5839, Valid Loss = 0.5864\n",
      "Iteration 12/135: Train Loss = 0.5760, Valid Loss = 0.5787\n",
      "Iteration 13/135: Train Loss = 0.5686, Valid Loss = 0.5713\n",
      "Iteration 14/135: Train Loss = 0.5613, Valid Loss = 0.5643\n",
      "Iteration 15/135: Train Loss = 0.5544, Valid Loss = 0.5574\n",
      "Iteration 16/135: Train Loss = 0.5478, Valid Loss = 0.5509\n",
      "Iteration 17/135: Train Loss = 0.5413, Valid Loss = 0.5446\n",
      "Iteration 18/135: Train Loss = 0.5351, Valid Loss = 0.5385\n",
      "Iteration 19/135: Train Loss = 0.5289, Valid Loss = 0.5326\n",
      "Iteration 20/135: Train Loss = 0.5231, Valid Loss = 0.5269\n",
      "Iteration 21/135: Train Loss = 0.5175, Valid Loss = 0.5215\n",
      "Iteration 22/135: Train Loss = 0.5122, Valid Loss = 0.5164\n",
      "Iteration 23/135: Train Loss = 0.5070, Valid Loss = 0.5112\n",
      "Iteration 24/135: Train Loss = 0.5019, Valid Loss = 0.5063\n",
      "Iteration 25/135: Train Loss = 0.4968, Valid Loss = 0.5014\n",
      "Iteration 26/135: Train Loss = 0.4922, Valid Loss = 0.4970\n",
      "Iteration 27/135: Train Loss = 0.4877, Valid Loss = 0.4926\n",
      "Iteration 28/135: Train Loss = 0.4833, Valid Loss = 0.4883\n",
      "Iteration 29/135: Train Loss = 0.4789, Valid Loss = 0.4840\n",
      "Iteration 30/135: Train Loss = 0.4749, Valid Loss = 0.4801\n",
      "Iteration 31/135: Train Loss = 0.4709, Valid Loss = 0.4761\n",
      "Iteration 32/135: Train Loss = 0.4669, Valid Loss = 0.4723\n",
      "Iteration 33/135: Train Loss = 0.4630, Valid Loss = 0.4685\n",
      "Iteration 34/135: Train Loss = 0.4594, Valid Loss = 0.4649\n",
      "Iteration 35/135: Train Loss = 0.4559, Valid Loss = 0.4614\n",
      "Iteration 36/135: Train Loss = 0.4523, Valid Loss = 0.4579\n",
      "Iteration 37/135: Train Loss = 0.4490, Valid Loss = 0.4547\n",
      "Iteration 38/135: Train Loss = 0.4458, Valid Loss = 0.4515\n",
      "Iteration 39/135: Train Loss = 0.4426, Valid Loss = 0.4483\n",
      "Iteration 40/135: Train Loss = 0.4394, Valid Loss = 0.4453\n",
      "Iteration 41/135: Train Loss = 0.4363, Valid Loss = 0.4422\n",
      "Iteration 42/135: Train Loss = 0.4335, Valid Loss = 0.4393\n",
      "Iteration 43/135: Train Loss = 0.4307, Valid Loss = 0.4367\n",
      "Iteration 44/135: Train Loss = 0.4280, Valid Loss = 0.4340\n",
      "Iteration 45/135: Train Loss = 0.4253, Valid Loss = 0.4314\n",
      "Iteration 46/135: Train Loss = 0.4226, Valid Loss = 0.4288\n",
      "Iteration 47/135: Train Loss = 0.4200, Valid Loss = 0.4264\n",
      "Iteration 48/135: Train Loss = 0.4176, Valid Loss = 0.4239\n",
      "Iteration 49/135: Train Loss = 0.4151, Valid Loss = 0.4214\n",
      "Iteration 50/135: Train Loss = 0.4127, Valid Loss = 0.4191\n",
      "Iteration 51/135: Train Loss = 0.4105, Valid Loss = 0.4169\n",
      "Iteration 52/135: Train Loss = 0.4083, Valid Loss = 0.4148\n",
      "Iteration 53/135: Train Loss = 0.4061, Valid Loss = 0.4127\n",
      "Iteration 54/135: Train Loss = 0.4040, Valid Loss = 0.4107\n",
      "Iteration 55/135: Train Loss = 0.4020, Valid Loss = 0.4086\n",
      "Iteration 56/135: Train Loss = 0.4000, Valid Loss = 0.4067\n",
      "Iteration 57/135: Train Loss = 0.3980, Valid Loss = 0.4048\n",
      "Iteration 58/135: Train Loss = 0.3961, Valid Loss = 0.4029\n",
      "Iteration 59/135: Train Loss = 0.3942, Valid Loss = 0.4010\n",
      "Iteration 60/135: Train Loss = 0.3923, Valid Loss = 0.3992\n",
      "Iteration 61/135: Train Loss = 0.3906, Valid Loss = 0.3975\n",
      "Iteration 62/135: Train Loss = 0.3888, Valid Loss = 0.3958\n",
      "Iteration 63/135: Train Loss = 0.3871, Valid Loss = 0.3941\n",
      "Iteration 64/135: Train Loss = 0.3854, Valid Loss = 0.3923\n",
      "Iteration 65/135: Train Loss = 0.3837, Valid Loss = 0.3906\n",
      "Iteration 66/135: Train Loss = 0.3821, Valid Loss = 0.3890\n",
      "Iteration 67/135: Train Loss = 0.3804, Valid Loss = 0.3873\n",
      "Iteration 68/135: Train Loss = 0.3789, Valid Loss = 0.3859\n",
      "Iteration 69/135: Train Loss = 0.3774, Valid Loss = 0.3844\n",
      "Iteration 70/135: Train Loss = 0.3760, Valid Loss = 0.3831\n",
      "Iteration 71/135: Train Loss = 0.3746, Valid Loss = 0.3817\n",
      "Iteration 72/135: Train Loss = 0.3732, Valid Loss = 0.3803\n",
      "Iteration 73/135: Train Loss = 0.3717, Valid Loss = 0.3789\n",
      "Iteration 74/135: Train Loss = 0.3704, Valid Loss = 0.3776\n",
      "Iteration 75/135: Train Loss = 0.3690, Valid Loss = 0.3762\n",
      "Iteration 76/135: Train Loss = 0.3677, Valid Loss = 0.3750\n",
      "Iteration 77/135: Train Loss = 0.3664, Valid Loss = 0.3738\n",
      "Iteration 78/135: Train Loss = 0.3651, Valid Loss = 0.3725\n",
      "Iteration 79/135: Train Loss = 0.3639, Valid Loss = 0.3713\n",
      "Iteration 80/135: Train Loss = 0.3626, Valid Loss = 0.3700\n",
      "Iteration 81/135: Train Loss = 0.3614, Valid Loss = 0.3689\n",
      "Iteration 82/135: Train Loss = 0.3603, Valid Loss = 0.3677\n",
      "Iteration 83/135: Train Loss = 0.3592, Valid Loss = 0.3667\n",
      "Iteration 84/135: Train Loss = 0.3580, Valid Loss = 0.3655\n",
      "Iteration 85/135: Train Loss = 0.3569, Valid Loss = 0.3643\n",
      "Iteration 86/135: Train Loss = 0.3557, Valid Loss = 0.3633\n",
      "Iteration 87/135: Train Loss = 0.3546, Valid Loss = 0.3621\n",
      "Iteration 88/135: Train Loss = 0.3535, Valid Loss = 0.3610\n",
      "Iteration 89/135: Train Loss = 0.3525, Valid Loss = 0.3600\n",
      "Iteration 90/135: Train Loss = 0.3515, Valid Loss = 0.3590\n",
      "Iteration 91/135: Train Loss = 0.3505, Valid Loss = 0.3579\n",
      "Iteration 92/135: Train Loss = 0.3495, Valid Loss = 0.3569\n",
      "Iteration 93/135: Train Loss = 0.3486, Valid Loss = 0.3560\n",
      "Iteration 94/135: Train Loss = 0.3476, Valid Loss = 0.3550\n",
      "Iteration 95/135: Train Loss = 0.3467, Valid Loss = 0.3542\n",
      "Iteration 96/135: Train Loss = 0.3457, Valid Loss = 0.3533\n",
      "Iteration 97/135: Train Loss = 0.3448, Valid Loss = 0.3524\n",
      "Iteration 98/135: Train Loss = 0.3438, Valid Loss = 0.3515\n",
      "Iteration 99/135: Train Loss = 0.3429, Valid Loss = 0.3506\n",
      "Iteration 100/135: Train Loss = 0.3421, Valid Loss = 0.3497\n",
      "Iteration 101/135: Train Loss = 0.3412, Valid Loss = 0.3489\n",
      "Iteration 102/135: Train Loss = 0.3404, Valid Loss = 0.3481\n",
      "Iteration 103/135: Train Loss = 0.3395, Valid Loss = 0.3473\n",
      "Iteration 104/135: Train Loss = 0.3387, Valid Loss = 0.3465\n",
      "Iteration 105/135: Train Loss = 0.3378, Valid Loss = 0.3457\n",
      "Iteration 106/135: Train Loss = 0.3371, Valid Loss = 0.3451\n",
      "Iteration 107/135: Train Loss = 0.3364, Valid Loss = 0.3443\n",
      "Iteration 108/135: Train Loss = 0.3357, Valid Loss = 0.3437\n",
      "Iteration 109/135: Train Loss = 0.3349, Valid Loss = 0.3430\n",
      "Iteration 110/135: Train Loss = 0.3342, Valid Loss = 0.3423\n",
      "Iteration 111/135: Train Loss = 0.3334, Valid Loss = 0.3417\n",
      "Iteration 112/135: Train Loss = 0.3327, Valid Loss = 0.3410\n",
      "Iteration 113/135: Train Loss = 0.3320, Valid Loss = 0.3403\n",
      "Iteration 114/135: Train Loss = 0.3312, Valid Loss = 0.3395\n",
      "Iteration 115/135: Train Loss = 0.3306, Valid Loss = 0.3388\n",
      "Iteration 116/135: Train Loss = 0.3298, Valid Loss = 0.3382\n",
      "Iteration 117/135: Train Loss = 0.3291, Valid Loss = 0.3375\n",
      "Iteration 118/135: Train Loss = 0.3285, Valid Loss = 0.3369\n",
      "Iteration 119/135: Train Loss = 0.3278, Valid Loss = 0.3363\n",
      "Iteration 120/135: Train Loss = 0.3272, Valid Loss = 0.3357\n",
      "Iteration 121/135: Train Loss = 0.3265, Valid Loss = 0.3350\n",
      "Iteration 122/135: Train Loss = 0.3259, Valid Loss = 0.3343\n",
      "Iteration 123/135: Train Loss = 0.3253, Valid Loss = 0.3337\n",
      "Iteration 124/135: Train Loss = 0.3247, Valid Loss = 0.3331\n",
      "Iteration 125/135: Train Loss = 0.3241, Valid Loss = 0.3325\n",
      "Iteration 126/135: Train Loss = 0.3235, Valid Loss = 0.3320\n",
      "Iteration 127/135: Train Loss = 0.3229, Valid Loss = 0.3313\n",
      "Iteration 128/135: Train Loss = 0.3223, Valid Loss = 0.3307\n",
      "Iteration 129/135: Train Loss = 0.3217, Valid Loss = 0.3301\n",
      "Iteration 130/135: Train Loss = 0.3211, Valid Loss = 0.3296\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-05 00:52:05,829] Trial 39 finished with value: 0.949228845193294 and parameters: {'max_depth': 3, 'min_samples_leaf': 18, 'n_estimators': 135, 'learning_rate': 0.08390500031772391, 'subsample': 0.6088693565173435}. Best is trial 27 with value: 0.9657550072635349.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 131/135: Train Loss = 0.3205, Valid Loss = 0.3290\n",
      "Iteration 132/135: Train Loss = 0.3199, Valid Loss = 0.3284\n",
      "Iteration 133/135: Train Loss = 0.3194, Valid Loss = 0.3278\n",
      "Iteration 134/135: Train Loss = 0.3189, Valid Loss = 0.3273\n",
      "Iteration 135/135: Train Loss = 0.3183, Valid Loss = 0.3268\n",
      "Iteration 1/145: Train Loss = 0.6853, Valid Loss = 0.6855\n",
      "Iteration 2/145: Train Loss = 0.6777, Valid Loss = 0.6781\n",
      "Iteration 3/145: Train Loss = 0.6701, Valid Loss = 0.6707\n",
      "Iteration 4/145: Train Loss = 0.6628, Valid Loss = 0.6636\n",
      "Iteration 5/145: Train Loss = 0.6557, Valid Loss = 0.6566\n",
      "Iteration 6/145: Train Loss = 0.6488, Valid Loss = 0.6498\n",
      "Iteration 7/145: Train Loss = 0.6420, Valid Loss = 0.6432\n",
      "Iteration 8/145: Train Loss = 0.6353, Valid Loss = 0.6367\n",
      "Iteration 9/145: Train Loss = 0.6288, Valid Loss = 0.6302\n",
      "Iteration 10/145: Train Loss = 0.6225, Valid Loss = 0.6241\n",
      "Iteration 11/145: Train Loss = 0.6163, Valid Loss = 0.6179\n",
      "Iteration 12/145: Train Loss = 0.6103, Valid Loss = 0.6120\n",
      "Iteration 13/145: Train Loss = 0.6045, Valid Loss = 0.6063\n",
      "Iteration 14/145: Train Loss = 0.5987, Valid Loss = 0.6008\n",
      "Iteration 15/145: Train Loss = 0.5931, Valid Loss = 0.5952\n",
      "Iteration 16/145: Train Loss = 0.5877, Valid Loss = 0.5900\n",
      "Iteration 17/145: Train Loss = 0.5822, Valid Loss = 0.5848\n",
      "Iteration 18/145: Train Loss = 0.5769, Valid Loss = 0.5796\n",
      "Iteration 19/145: Train Loss = 0.5717, Valid Loss = 0.5744\n",
      "Iteration 20/145: Train Loss = 0.5668, Valid Loss = 0.5696\n",
      "Iteration 21/145: Train Loss = 0.5619, Valid Loss = 0.5648\n",
      "Iteration 22/145: Train Loss = 0.5570, Valid Loss = 0.5601\n",
      "Iteration 23/145: Train Loss = 0.5524, Valid Loss = 0.5554\n",
      "Iteration 24/145: Train Loss = 0.5478, Valid Loss = 0.5510\n",
      "Iteration 25/145: Train Loss = 0.5433, Valid Loss = 0.5466\n",
      "Iteration 26/145: Train Loss = 0.5389, Valid Loss = 0.5423\n",
      "Iteration 27/145: Train Loss = 0.5346, Valid Loss = 0.5381\n",
      "Iteration 28/145: Train Loss = 0.5304, Valid Loss = 0.5340\n",
      "Iteration 29/145: Train Loss = 0.5263, Valid Loss = 0.5300\n",
      "Iteration 30/145: Train Loss = 0.5222, Valid Loss = 0.5260\n",
      "Iteration 31/145: Train Loss = 0.5182, Valid Loss = 0.5221\n",
      "Iteration 32/145: Train Loss = 0.5144, Valid Loss = 0.5185\n",
      "Iteration 33/145: Train Loss = 0.5106, Valid Loss = 0.5147\n",
      "Iteration 34/145: Train Loss = 0.5068, Valid Loss = 0.5110\n",
      "Iteration 35/145: Train Loss = 0.5033, Valid Loss = 0.5075\n",
      "Iteration 36/145: Train Loss = 0.4997, Valid Loss = 0.5041\n",
      "Iteration 37/145: Train Loss = 0.4962, Valid Loss = 0.5008\n",
      "Iteration 38/145: Train Loss = 0.4928, Valid Loss = 0.4975\n",
      "Iteration 39/145: Train Loss = 0.4894, Valid Loss = 0.4942\n",
      "Iteration 40/145: Train Loss = 0.4860, Valid Loss = 0.4910\n",
      "Iteration 41/145: Train Loss = 0.4828, Valid Loss = 0.4878\n",
      "Iteration 42/145: Train Loss = 0.4797, Valid Loss = 0.4848\n",
      "Iteration 43/145: Train Loss = 0.4766, Valid Loss = 0.4819\n",
      "Iteration 44/145: Train Loss = 0.4736, Valid Loss = 0.4790\n",
      "Iteration 45/145: Train Loss = 0.4707, Valid Loss = 0.4761\n",
      "Iteration 46/145: Train Loss = 0.4678, Valid Loss = 0.4733\n",
      "Iteration 47/145: Train Loss = 0.4648, Valid Loss = 0.4704\n",
      "Iteration 48/145: Train Loss = 0.4621, Valid Loss = 0.4677\n",
      "Iteration 49/145: Train Loss = 0.4594, Valid Loss = 0.4651\n",
      "Iteration 50/145: Train Loss = 0.4567, Valid Loss = 0.4625\n",
      "Iteration 51/145: Train Loss = 0.4541, Valid Loss = 0.4600\n",
      "Iteration 52/145: Train Loss = 0.4515, Valid Loss = 0.4575\n",
      "Iteration 53/145: Train Loss = 0.4490, Valid Loss = 0.4551\n",
      "Iteration 54/145: Train Loss = 0.4465, Valid Loss = 0.4526\n",
      "Iteration 55/145: Train Loss = 0.4440, Valid Loss = 0.4502\n",
      "Iteration 56/145: Train Loss = 0.4416, Valid Loss = 0.4478\n",
      "Iteration 57/145: Train Loss = 0.4392, Valid Loss = 0.4456\n",
      "Iteration 58/145: Train Loss = 0.4369, Valid Loss = 0.4434\n",
      "Iteration 59/145: Train Loss = 0.4347, Valid Loss = 0.4412\n",
      "Iteration 60/145: Train Loss = 0.4325, Valid Loss = 0.4390\n",
      "Iteration 61/145: Train Loss = 0.4303, Valid Loss = 0.4370\n",
      "Iteration 62/145: Train Loss = 0.4282, Valid Loss = 0.4349\n",
      "Iteration 63/145: Train Loss = 0.4261, Valid Loss = 0.4329\n",
      "Iteration 64/145: Train Loss = 0.4240, Valid Loss = 0.4309\n",
      "Iteration 65/145: Train Loss = 0.4220, Valid Loss = 0.4289\n",
      "Iteration 66/145: Train Loss = 0.4200, Valid Loss = 0.4269\n",
      "Iteration 67/145: Train Loss = 0.4179, Valid Loss = 0.4250\n",
      "Iteration 68/145: Train Loss = 0.4160, Valid Loss = 0.4232\n",
      "Iteration 69/145: Train Loss = 0.4141, Valid Loss = 0.4213\n",
      "Iteration 70/145: Train Loss = 0.4122, Valid Loss = 0.4195\n",
      "Iteration 71/145: Train Loss = 0.4104, Valid Loss = 0.4178\n",
      "Iteration 72/145: Train Loss = 0.4086, Valid Loss = 0.4161\n",
      "Iteration 73/145: Train Loss = 0.4068, Valid Loss = 0.4143\n",
      "Iteration 74/145: Train Loss = 0.4051, Valid Loss = 0.4126\n",
      "Iteration 75/145: Train Loss = 0.4034, Valid Loss = 0.4110\n",
      "Iteration 76/145: Train Loss = 0.4016, Valid Loss = 0.4093\n",
      "Iteration 77/145: Train Loss = 0.4000, Valid Loss = 0.4077\n",
      "Iteration 78/145: Train Loss = 0.3984, Valid Loss = 0.4062\n",
      "Iteration 79/145: Train Loss = 0.3968, Valid Loss = 0.4047\n",
      "Iteration 80/145: Train Loss = 0.3952, Valid Loss = 0.4031\n",
      "Iteration 81/145: Train Loss = 0.3937, Valid Loss = 0.4016\n",
      "Iteration 82/145: Train Loss = 0.3921, Valid Loss = 0.4001\n",
      "Iteration 83/145: Train Loss = 0.3906, Valid Loss = 0.3986\n",
      "Iteration 84/145: Train Loss = 0.3891, Valid Loss = 0.3971\n",
      "Iteration 85/145: Train Loss = 0.3876, Valid Loss = 0.3956\n",
      "Iteration 86/145: Train Loss = 0.3861, Valid Loss = 0.3941\n",
      "Iteration 87/145: Train Loss = 0.3847, Valid Loss = 0.3928\n",
      "Iteration 88/145: Train Loss = 0.3832, Valid Loss = 0.3914\n",
      "Iteration 89/145: Train Loss = 0.3819, Valid Loss = 0.3901\n",
      "Iteration 90/145: Train Loss = 0.3805, Valid Loss = 0.3888\n",
      "Iteration 91/145: Train Loss = 0.3792, Valid Loss = 0.3875\n",
      "Iteration 92/145: Train Loss = 0.3779, Valid Loss = 0.3863\n",
      "Iteration 93/145: Train Loss = 0.3766, Valid Loss = 0.3851\n",
      "Iteration 94/145: Train Loss = 0.3753, Valid Loss = 0.3839\n",
      "Iteration 95/145: Train Loss = 0.3740, Valid Loss = 0.3826\n",
      "Iteration 96/145: Train Loss = 0.3728, Valid Loss = 0.3815\n",
      "Iteration 97/145: Train Loss = 0.3715, Valid Loss = 0.3803\n",
      "Iteration 98/145: Train Loss = 0.3703, Valid Loss = 0.3791\n",
      "Iteration 99/145: Train Loss = 0.3691, Valid Loss = 0.3779\n",
      "Iteration 100/145: Train Loss = 0.3679, Valid Loss = 0.3768\n",
      "Iteration 101/145: Train Loss = 0.3667, Valid Loss = 0.3756\n",
      "Iteration 102/145: Train Loss = 0.3656, Valid Loss = 0.3745\n",
      "Iteration 103/145: Train Loss = 0.3644, Valid Loss = 0.3734\n",
      "Iteration 104/145: Train Loss = 0.3633, Valid Loss = 0.3723\n",
      "Iteration 105/145: Train Loss = 0.3622, Valid Loss = 0.3713\n",
      "Iteration 106/145: Train Loss = 0.3611, Valid Loss = 0.3702\n",
      "Iteration 107/145: Train Loss = 0.3600, Valid Loss = 0.3692\n",
      "Iteration 108/145: Train Loss = 0.3589, Valid Loss = 0.3682\n",
      "Iteration 109/145: Train Loss = 0.3579, Valid Loss = 0.3671\n",
      "Iteration 110/145: Train Loss = 0.3568, Valid Loss = 0.3661\n",
      "Iteration 111/145: Train Loss = 0.3557, Valid Loss = 0.3651\n",
      "Iteration 112/145: Train Loss = 0.3547, Valid Loss = 0.3642\n",
      "Iteration 113/145: Train Loss = 0.3538, Valid Loss = 0.3632\n",
      "Iteration 114/145: Train Loss = 0.3528, Valid Loss = 0.3623\n",
      "Iteration 115/145: Train Loss = 0.3519, Valid Loss = 0.3615\n",
      "Iteration 116/145: Train Loss = 0.3509, Valid Loss = 0.3605\n",
      "Iteration 117/145: Train Loss = 0.3500, Valid Loss = 0.3597\n",
      "Iteration 118/145: Train Loss = 0.3491, Valid Loss = 0.3587\n",
      "Iteration 119/145: Train Loss = 0.3481, Valid Loss = 0.3578\n",
      "Iteration 120/145: Train Loss = 0.3472, Valid Loss = 0.3569\n",
      "Iteration 121/145: Train Loss = 0.3463, Valid Loss = 0.3561\n",
      "Iteration 122/145: Train Loss = 0.3454, Valid Loss = 0.3553\n",
      "Iteration 123/145: Train Loss = 0.3445, Valid Loss = 0.3544\n",
      "Iteration 124/145: Train Loss = 0.3437, Valid Loss = 0.3536\n",
      "Iteration 125/145: Train Loss = 0.3428, Valid Loss = 0.3527\n",
      "Iteration 126/145: Train Loss = 0.3420, Valid Loss = 0.3520\n",
      "Iteration 127/145: Train Loss = 0.3411, Valid Loss = 0.3511\n",
      "Iteration 128/145: Train Loss = 0.3402, Valid Loss = 0.3503\n",
      "Iteration 129/145: Train Loss = 0.3394, Valid Loss = 0.3495\n",
      "Iteration 130/145: Train Loss = 0.3385, Valid Loss = 0.3487\n",
      "Iteration 131/145: Train Loss = 0.3377, Valid Loss = 0.3480\n",
      "Iteration 132/145: Train Loss = 0.3369, Valid Loss = 0.3472\n",
      "Iteration 133/145: Train Loss = 0.3361, Valid Loss = 0.3464\n",
      "Iteration 134/145: Train Loss = 0.3354, Valid Loss = 0.3458\n",
      "Iteration 135/145: Train Loss = 0.3346, Valid Loss = 0.3450\n",
      "Iteration 136/145: Train Loss = 0.3339, Valid Loss = 0.3443\n",
      "Iteration 137/145: Train Loss = 0.3331, Valid Loss = 0.3435\n",
      "Iteration 138/145: Train Loss = 0.3324, Valid Loss = 0.3429\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-05 00:52:10,688] Trial 40 finished with value: 0.9560760135585983 and parameters: {'max_depth': 5, 'min_samples_leaf': 14, 'n_estimators': 145, 'learning_rate': 0.04900461631178423, 'subsample': 0.47153096958979973}. Best is trial 27 with value: 0.9657550072635349.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 139/145: Train Loss = 0.3316, Valid Loss = 0.3422\n",
      "Iteration 140/145: Train Loss = 0.3309, Valid Loss = 0.3415\n",
      "Iteration 141/145: Train Loss = 0.3302, Valid Loss = 0.3409\n",
      "Iteration 142/145: Train Loss = 0.3295, Valid Loss = 0.3403\n",
      "Iteration 143/145: Train Loss = 0.3289, Valid Loss = 0.3396\n",
      "Iteration 144/145: Train Loss = 0.3282, Valid Loss = 0.3390\n",
      "Iteration 145/145: Train Loss = 0.3275, Valid Loss = 0.3383\n",
      "Iteration 1/130: Train Loss = 0.6394, Valid Loss = 0.6403\n",
      "Iteration 2/130: Train Loss = 0.5943, Valid Loss = 0.5963\n",
      "Iteration 3/130: Train Loss = 0.5565, Valid Loss = 0.5589\n",
      "Iteration 4/130: Train Loss = 0.5243, Valid Loss = 0.5279\n",
      "Iteration 5/130: Train Loss = 0.4966, Valid Loss = 0.5011\n",
      "Iteration 6/130: Train Loss = 0.4724, Valid Loss = 0.4777\n",
      "Iteration 7/130: Train Loss = 0.4521, Valid Loss = 0.4584\n",
      "Iteration 8/130: Train Loss = 0.4347, Valid Loss = 0.4422\n",
      "Iteration 9/130: Train Loss = 0.4190, Valid Loss = 0.4269\n",
      "Iteration 10/130: Train Loss = 0.4052, Valid Loss = 0.4136\n",
      "Iteration 11/130: Train Loss = 0.3933, Valid Loss = 0.4021\n",
      "Iteration 12/130: Train Loss = 0.3824, Valid Loss = 0.3919\n",
      "Iteration 13/130: Train Loss = 0.3728, Valid Loss = 0.3825\n",
      "Iteration 14/130: Train Loss = 0.3646, Valid Loss = 0.3744\n",
      "Iteration 15/130: Train Loss = 0.3566, Valid Loss = 0.3668\n",
      "Iteration 16/130: Train Loss = 0.3496, Valid Loss = 0.3598\n",
      "Iteration 17/130: Train Loss = 0.3429, Valid Loss = 0.3531\n",
      "Iteration 18/130: Train Loss = 0.3367, Valid Loss = 0.3470\n",
      "Iteration 19/130: Train Loss = 0.3310, Valid Loss = 0.3417\n",
      "Iteration 20/130: Train Loss = 0.3259, Valid Loss = 0.3366\n",
      "Iteration 21/130: Train Loss = 0.3213, Valid Loss = 0.3320\n",
      "Iteration 22/130: Train Loss = 0.3172, Valid Loss = 0.3278\n",
      "Iteration 23/130: Train Loss = 0.3132, Valid Loss = 0.3239\n",
      "Iteration 24/130: Train Loss = 0.3092, Valid Loss = 0.3205\n",
      "Iteration 25/130: Train Loss = 0.3055, Valid Loss = 0.3172\n",
      "Iteration 26/130: Train Loss = 0.3021, Valid Loss = 0.3137\n",
      "Iteration 27/130: Train Loss = 0.2992, Valid Loss = 0.3111\n",
      "Iteration 28/130: Train Loss = 0.2965, Valid Loss = 0.3088\n",
      "Iteration 29/130: Train Loss = 0.2939, Valid Loss = 0.3069\n",
      "Iteration 30/130: Train Loss = 0.2914, Valid Loss = 0.3046\n",
      "Iteration 31/130: Train Loss = 0.2891, Valid Loss = 0.3022\n",
      "Iteration 32/130: Train Loss = 0.2869, Valid Loss = 0.2999\n",
      "Iteration 33/130: Train Loss = 0.2848, Valid Loss = 0.2977\n",
      "Iteration 34/130: Train Loss = 0.2827, Valid Loss = 0.2957\n",
      "Iteration 35/130: Train Loss = 0.2804, Valid Loss = 0.2938\n",
      "Iteration 36/130: Train Loss = 0.2785, Valid Loss = 0.2919\n",
      "Iteration 37/130: Train Loss = 0.2766, Valid Loss = 0.2900\n",
      "Iteration 38/130: Train Loss = 0.2746, Valid Loss = 0.2883\n",
      "Iteration 39/130: Train Loss = 0.2728, Valid Loss = 0.2865\n",
      "Iteration 40/130: Train Loss = 0.2711, Valid Loss = 0.2852\n",
      "Iteration 41/130: Train Loss = 0.2697, Valid Loss = 0.2838\n",
      "Iteration 42/130: Train Loss = 0.2684, Valid Loss = 0.2826\n",
      "Iteration 43/130: Train Loss = 0.2667, Valid Loss = 0.2809\n",
      "Iteration 44/130: Train Loss = 0.2650, Valid Loss = 0.2795\n",
      "Iteration 45/130: Train Loss = 0.2637, Valid Loss = 0.2784\n",
      "Iteration 46/130: Train Loss = 0.2623, Valid Loss = 0.2774\n",
      "Iteration 47/130: Train Loss = 0.2612, Valid Loss = 0.2765\n",
      "Iteration 48/130: Train Loss = 0.2600, Valid Loss = 0.2754\n",
      "Iteration 49/130: Train Loss = 0.2590, Valid Loss = 0.2743\n",
      "Iteration 50/130: Train Loss = 0.2577, Valid Loss = 0.2735\n",
      "Iteration 51/130: Train Loss = 0.2568, Valid Loss = 0.2727\n",
      "Iteration 52/130: Train Loss = 0.2557, Valid Loss = 0.2717\n",
      "Iteration 53/130: Train Loss = 0.2548, Valid Loss = 0.2707\n",
      "Iteration 54/130: Train Loss = 0.2538, Valid Loss = 0.2701\n",
      "Iteration 55/130: Train Loss = 0.2527, Valid Loss = 0.2692\n",
      "Iteration 56/130: Train Loss = 0.2519, Valid Loss = 0.2684\n",
      "Iteration 57/130: Train Loss = 0.2511, Valid Loss = 0.2677\n",
      "Iteration 58/130: Train Loss = 0.2504, Valid Loss = 0.2673\n",
      "Iteration 59/130: Train Loss = 0.2495, Valid Loss = 0.2664\n",
      "Iteration 60/130: Train Loss = 0.2487, Valid Loss = 0.2657\n",
      "Iteration 61/130: Train Loss = 0.2478, Valid Loss = 0.2649\n",
      "Iteration 62/130: Train Loss = 0.2469, Valid Loss = 0.2642\n",
      "Iteration 63/130: Train Loss = 0.2460, Valid Loss = 0.2633\n",
      "Iteration 64/130: Train Loss = 0.2452, Valid Loss = 0.2627\n",
      "Iteration 65/130: Train Loss = 0.2445, Valid Loss = 0.2622\n",
      "Iteration 66/130: Train Loss = 0.2437, Valid Loss = 0.2618\n",
      "Iteration 67/130: Train Loss = 0.2430, Valid Loss = 0.2614\n",
      "Iteration 68/130: Train Loss = 0.2422, Valid Loss = 0.2607\n",
      "Iteration 69/130: Train Loss = 0.2416, Valid Loss = 0.2602\n",
      "Iteration 70/130: Train Loss = 0.2407, Valid Loss = 0.2597\n",
      "Iteration 71/130: Train Loss = 0.2402, Valid Loss = 0.2592\n",
      "Iteration 72/130: Train Loss = 0.2396, Valid Loss = 0.2588\n",
      "Iteration 73/130: Train Loss = 0.2392, Valid Loss = 0.2584\n",
      "Iteration 74/130: Train Loss = 0.2386, Valid Loss = 0.2581\n",
      "Iteration 75/130: Train Loss = 0.2380, Valid Loss = 0.2576\n",
      "Iteration 76/130: Train Loss = 0.2375, Valid Loss = 0.2572\n",
      "Iteration 77/130: Train Loss = 0.2370, Valid Loss = 0.2568\n",
      "Iteration 78/130: Train Loss = 0.2364, Valid Loss = 0.2564\n",
      "Iteration 79/130: Train Loss = 0.2357, Valid Loss = 0.2560\n",
      "Iteration 80/130: Train Loss = 0.2351, Valid Loss = 0.2555\n",
      "Iteration 81/130: Train Loss = 0.2347, Valid Loss = 0.2554\n",
      "Iteration 82/130: Train Loss = 0.2342, Valid Loss = 0.2549\n",
      "Iteration 83/130: Train Loss = 0.2338, Valid Loss = 0.2545\n",
      "Iteration 84/130: Train Loss = 0.2332, Valid Loss = 0.2541\n",
      "Iteration 85/130: Train Loss = 0.2327, Valid Loss = 0.2538\n",
      "Iteration 86/130: Train Loss = 0.2322, Valid Loss = 0.2534\n",
      "Iteration 87/130: Train Loss = 0.2317, Valid Loss = 0.2530\n",
      "Iteration 88/130: Train Loss = 0.2313, Valid Loss = 0.2528\n",
      "Iteration 89/130: Train Loss = 0.2308, Valid Loss = 0.2524\n",
      "Iteration 90/130: Train Loss = 0.2303, Valid Loss = 0.2522\n",
      "Iteration 91/130: Train Loss = 0.2299, Valid Loss = 0.2519\n",
      "Iteration 92/130: Train Loss = 0.2294, Valid Loss = 0.2516\n",
      "Iteration 93/130: Train Loss = 0.2290, Valid Loss = 0.2514\n",
      "Iteration 94/130: Train Loss = 0.2286, Valid Loss = 0.2510\n",
      "Iteration 95/130: Train Loss = 0.2282, Valid Loss = 0.2507\n",
      "Iteration 96/130: Train Loss = 0.2279, Valid Loss = 0.2504\n",
      "Iteration 97/130: Train Loss = 0.2274, Valid Loss = 0.2502\n",
      "Iteration 98/130: Train Loss = 0.2271, Valid Loss = 0.2499\n",
      "Iteration 99/130: Train Loss = 0.2267, Valid Loss = 0.2496\n",
      "Iteration 100/130: Train Loss = 0.2264, Valid Loss = 0.2495\n",
      "Iteration 101/130: Train Loss = 0.2260, Valid Loss = 0.2491\n",
      "Iteration 102/130: Train Loss = 0.2256, Valid Loss = 0.2488\n",
      "Iteration 103/130: Train Loss = 0.2252, Valid Loss = 0.2487\n",
      "Iteration 104/130: Train Loss = 0.2249, Valid Loss = 0.2486\n",
      "Iteration 105/130: Train Loss = 0.2246, Valid Loss = 0.2484\n",
      "Iteration 106/130: Train Loss = 0.2243, Valid Loss = 0.2482\n",
      "Iteration 107/130: Train Loss = 0.2239, Valid Loss = 0.2480\n",
      "Iteration 108/130: Train Loss = 0.2236, Valid Loss = 0.2476\n",
      "Iteration 109/130: Train Loss = 0.2232, Valid Loss = 0.2473\n",
      "Iteration 110/130: Train Loss = 0.2229, Valid Loss = 0.2470\n",
      "Iteration 111/130: Train Loss = 0.2226, Valid Loss = 0.2468\n",
      "Iteration 112/130: Train Loss = 0.2223, Valid Loss = 0.2465\n",
      "Iteration 113/130: Train Loss = 0.2219, Valid Loss = 0.2464\n",
      "Iteration 114/130: Train Loss = 0.2216, Valid Loss = 0.2461\n",
      "Iteration 115/130: Train Loss = 0.2214, Valid Loss = 0.2461\n",
      "Iteration 116/130: Train Loss = 0.2211, Valid Loss = 0.2459\n",
      "Iteration 117/130: Train Loss = 0.2208, Valid Loss = 0.2458\n",
      "Iteration 118/130: Train Loss = 0.2205, Valid Loss = 0.2456\n",
      "Iteration 119/130: Train Loss = 0.2202, Valid Loss = 0.2455\n",
      "Iteration 120/130: Train Loss = 0.2199, Valid Loss = 0.2453\n",
      "Iteration 121/130: Train Loss = 0.2197, Valid Loss = 0.2452\n",
      "Iteration 122/130: Train Loss = 0.2194, Valid Loss = 0.2450\n",
      "Iteration 123/130: Train Loss = 0.2192, Valid Loss = 0.2448\n",
      "Iteration 124/130: Train Loss = 0.2189, Valid Loss = 0.2447\n",
      "Iteration 125/130: Train Loss = 0.2186, Valid Loss = 0.2445\n",
      "Iteration 126/130: Train Loss = 0.2183, Valid Loss = 0.2444\n",
      "Iteration 127/130: Train Loss = 0.2179, Valid Loss = 0.2441\n",
      "Iteration 128/130: Train Loss = 0.2177, Valid Loss = 0.2439\n",
      "Iteration 129/130: Train Loss = 0.2174, Valid Loss = 0.2440\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-05 00:52:15,456] Trial 41 finished with value: 0.9650568690924204 and parameters: {'max_depth': 5, 'min_samples_leaf': 16, 'n_estimators': 130, 'learning_rate': 0.352576964413513, 'subsample': 0.5393649127857448}. Best is trial 27 with value: 0.9657550072635349.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 130/130: Train Loss = 0.2172, Valid Loss = 0.2440\n",
      "Iteration 1/110: Train Loss = 0.6674, Valid Loss = 0.6678\n",
      "Iteration 2/110: Train Loss = 0.6434, Valid Loss = 0.6443\n",
      "Iteration 3/110: Train Loss = 0.6213, Valid Loss = 0.6226\n",
      "Iteration 4/110: Train Loss = 0.6007, Valid Loss = 0.6025\n",
      "Iteration 5/110: Train Loss = 0.5820, Valid Loss = 0.5842\n",
      "Iteration 6/110: Train Loss = 0.5644, Valid Loss = 0.5669\n",
      "Iteration 7/110: Train Loss = 0.5482, Valid Loss = 0.5510\n",
      "Iteration 8/110: Train Loss = 0.5329, Valid Loss = 0.5362\n",
      "Iteration 9/110: Train Loss = 0.5187, Valid Loss = 0.5225\n",
      "Iteration 10/110: Train Loss = 0.5055, Valid Loss = 0.5098\n",
      "Iteration 11/110: Train Loss = 0.4934, Valid Loss = 0.4979\n",
      "Iteration 12/110: Train Loss = 0.4819, Valid Loss = 0.4871\n",
      "Iteration 13/110: Train Loss = 0.4712, Valid Loss = 0.4768\n",
      "Iteration 14/110: Train Loss = 0.4613, Valid Loss = 0.4673\n",
      "Iteration 15/110: Train Loss = 0.4517, Valid Loss = 0.4583\n",
      "Iteration 16/110: Train Loss = 0.4429, Valid Loss = 0.4498\n",
      "Iteration 17/110: Train Loss = 0.4348, Valid Loss = 0.4419\n",
      "Iteration 18/110: Train Loss = 0.4272, Valid Loss = 0.4346\n",
      "Iteration 19/110: Train Loss = 0.4197, Valid Loss = 0.4275\n",
      "Iteration 20/110: Train Loss = 0.4128, Valid Loss = 0.4208\n",
      "Iteration 21/110: Train Loss = 0.4062, Valid Loss = 0.4143\n",
      "Iteration 22/110: Train Loss = 0.4001, Valid Loss = 0.4083\n",
      "Iteration 23/110: Train Loss = 0.3941, Valid Loss = 0.4027\n",
      "Iteration 24/110: Train Loss = 0.3888, Valid Loss = 0.3976\n",
      "Iteration 25/110: Train Loss = 0.3836, Valid Loss = 0.3926\n",
      "Iteration 26/110: Train Loss = 0.3786, Valid Loss = 0.3876\n",
      "Iteration 27/110: Train Loss = 0.3739, Valid Loss = 0.3830\n",
      "Iteration 28/110: Train Loss = 0.3694, Valid Loss = 0.3787\n",
      "Iteration 29/110: Train Loss = 0.3650, Valid Loss = 0.3743\n",
      "Iteration 30/110: Train Loss = 0.3609, Valid Loss = 0.3705\n",
      "Iteration 31/110: Train Loss = 0.3570, Valid Loss = 0.3666\n",
      "Iteration 32/110: Train Loss = 0.3534, Valid Loss = 0.3631\n",
      "Iteration 33/110: Train Loss = 0.3498, Valid Loss = 0.3598\n",
      "Iteration 34/110: Train Loss = 0.3463, Valid Loss = 0.3566\n",
      "Iteration 35/110: Train Loss = 0.3430, Valid Loss = 0.3534\n",
      "Iteration 36/110: Train Loss = 0.3399, Valid Loss = 0.3505\n",
      "Iteration 37/110: Train Loss = 0.3370, Valid Loss = 0.3479\n",
      "Iteration 38/110: Train Loss = 0.3339, Valid Loss = 0.3449\n",
      "Iteration 39/110: Train Loss = 0.3311, Valid Loss = 0.3423\n",
      "Iteration 40/110: Train Loss = 0.3285, Valid Loss = 0.3398\n",
      "Iteration 41/110: Train Loss = 0.3259, Valid Loss = 0.3373\n",
      "Iteration 42/110: Train Loss = 0.3234, Valid Loss = 0.3348\n",
      "Iteration 43/110: Train Loss = 0.3210, Valid Loss = 0.3326\n",
      "Iteration 44/110: Train Loss = 0.3188, Valid Loss = 0.3304\n",
      "Iteration 45/110: Train Loss = 0.3166, Valid Loss = 0.3283\n",
      "Iteration 46/110: Train Loss = 0.3144, Valid Loss = 0.3263\n",
      "Iteration 47/110: Train Loss = 0.3122, Valid Loss = 0.3243\n",
      "Iteration 48/110: Train Loss = 0.3102, Valid Loss = 0.3226\n",
      "Iteration 49/110: Train Loss = 0.3082, Valid Loss = 0.3208\n",
      "Iteration 50/110: Train Loss = 0.3064, Valid Loss = 0.3191\n",
      "Iteration 51/110: Train Loss = 0.3045, Valid Loss = 0.3175\n",
      "Iteration 52/110: Train Loss = 0.3027, Valid Loss = 0.3159\n",
      "Iteration 53/110: Train Loss = 0.3011, Valid Loss = 0.3144\n",
      "Iteration 54/110: Train Loss = 0.2995, Valid Loss = 0.3130\n",
      "Iteration 55/110: Train Loss = 0.2979, Valid Loss = 0.3118\n",
      "Iteration 56/110: Train Loss = 0.2964, Valid Loss = 0.3103\n",
      "Iteration 57/110: Train Loss = 0.2948, Valid Loss = 0.3089\n",
      "Iteration 58/110: Train Loss = 0.2933, Valid Loss = 0.3075\n",
      "Iteration 59/110: Train Loss = 0.2919, Valid Loss = 0.3063\n",
      "Iteration 60/110: Train Loss = 0.2905, Valid Loss = 0.3050\n",
      "Iteration 61/110: Train Loss = 0.2891, Valid Loss = 0.3039\n",
      "Iteration 62/110: Train Loss = 0.2878, Valid Loss = 0.3028\n",
      "Iteration 63/110: Train Loss = 0.2865, Valid Loss = 0.3015\n",
      "Iteration 64/110: Train Loss = 0.2852, Valid Loss = 0.3003\n",
      "Iteration 65/110: Train Loss = 0.2839, Valid Loss = 0.2991\n",
      "Iteration 66/110: Train Loss = 0.2827, Valid Loss = 0.2980\n",
      "Iteration 67/110: Train Loss = 0.2815, Valid Loss = 0.2968\n",
      "Iteration 68/110: Train Loss = 0.2804, Valid Loss = 0.2959\n",
      "Iteration 69/110: Train Loss = 0.2793, Valid Loss = 0.2948\n",
      "Iteration 70/110: Train Loss = 0.2782, Valid Loss = 0.2939\n",
      "Iteration 71/110: Train Loss = 0.2770, Valid Loss = 0.2927\n",
      "Iteration 72/110: Train Loss = 0.2761, Valid Loss = 0.2919\n",
      "Iteration 73/110: Train Loss = 0.2751, Valid Loss = 0.2910\n",
      "Iteration 74/110: Train Loss = 0.2741, Valid Loss = 0.2902\n",
      "Iteration 75/110: Train Loss = 0.2732, Valid Loss = 0.2893\n",
      "Iteration 76/110: Train Loss = 0.2721, Valid Loss = 0.2884\n",
      "Iteration 77/110: Train Loss = 0.2712, Valid Loss = 0.2876\n",
      "Iteration 78/110: Train Loss = 0.2702, Valid Loss = 0.2867\n",
      "Iteration 79/110: Train Loss = 0.2694, Valid Loss = 0.2860\n",
      "Iteration 80/110: Train Loss = 0.2685, Valid Loss = 0.2851\n",
      "Iteration 81/110: Train Loss = 0.2677, Valid Loss = 0.2845\n",
      "Iteration 82/110: Train Loss = 0.2669, Valid Loss = 0.2839\n",
      "Iteration 83/110: Train Loss = 0.2659, Valid Loss = 0.2832\n",
      "Iteration 84/110: Train Loss = 0.2652, Valid Loss = 0.2826\n",
      "Iteration 85/110: Train Loss = 0.2644, Valid Loss = 0.2818\n",
      "Iteration 86/110: Train Loss = 0.2636, Valid Loss = 0.2812\n",
      "Iteration 87/110: Train Loss = 0.2629, Valid Loss = 0.2806\n",
      "Iteration 88/110: Train Loss = 0.2622, Valid Loss = 0.2800\n",
      "Iteration 89/110: Train Loss = 0.2615, Valid Loss = 0.2794\n",
      "Iteration 90/110: Train Loss = 0.2609, Valid Loss = 0.2790\n",
      "Iteration 91/110: Train Loss = 0.2602, Valid Loss = 0.2784\n",
      "Iteration 92/110: Train Loss = 0.2594, Valid Loss = 0.2779\n",
      "Iteration 93/110: Train Loss = 0.2588, Valid Loss = 0.2773\n",
      "Iteration 94/110: Train Loss = 0.2582, Valid Loss = 0.2768\n",
      "Iteration 95/110: Train Loss = 0.2575, Valid Loss = 0.2764\n",
      "Iteration 96/110: Train Loss = 0.2569, Valid Loss = 0.2758\n",
      "Iteration 97/110: Train Loss = 0.2564, Valid Loss = 0.2752\n",
      "Iteration 98/110: Train Loss = 0.2557, Valid Loss = 0.2747\n",
      "Iteration 99/110: Train Loss = 0.2551, Valid Loss = 0.2742\n",
      "Iteration 100/110: Train Loss = 0.2545, Valid Loss = 0.2736\n",
      "Iteration 101/110: Train Loss = 0.2539, Valid Loss = 0.2732\n",
      "Iteration 102/110: Train Loss = 0.2533, Valid Loss = 0.2728\n",
      "Iteration 103/110: Train Loss = 0.2528, Valid Loss = 0.2724\n",
      "Iteration 104/110: Train Loss = 0.2523, Valid Loss = 0.2720\n",
      "Iteration 105/110: Train Loss = 0.2517, Valid Loss = 0.2715\n",
      "Iteration 106/110: Train Loss = 0.2512, Valid Loss = 0.2711\n",
      "Iteration 107/110: Train Loss = 0.2505, Valid Loss = 0.2706\n",
      "Iteration 108/110: Train Loss = 0.2501, Valid Loss = 0.2702\n",
      "Iteration 109/110: Train Loss = 0.2496, Valid Loss = 0.2698\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-05 00:52:19,668] Trial 42 finished with value: 0.9622544029221907 and parameters: {'max_depth': 6, 'min_samples_leaf': 19, 'n_estimators': 110, 'learning_rate': 0.16075249503637187, 'subsample': 0.5434237632208722}. Best is trial 27 with value: 0.9657550072635349.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 110/110: Train Loss = 0.2492, Valid Loss = 0.2693\n",
      "Iteration 1/125: Train Loss = 0.6520, Valid Loss = 0.6532\n",
      "Iteration 2/125: Train Loss = 0.6159, Valid Loss = 0.6182\n",
      "Iteration 3/125: Train Loss = 0.5835, Valid Loss = 0.5870\n",
      "Iteration 4/125: Train Loss = 0.5545, Valid Loss = 0.5587\n",
      "Iteration 5/125: Train Loss = 0.5291, Valid Loss = 0.5339\n",
      "Iteration 6/125: Train Loss = 0.5065, Valid Loss = 0.5122\n",
      "Iteration 7/125: Train Loss = 0.4857, Valid Loss = 0.4924\n",
      "Iteration 8/125: Train Loss = 0.4676, Valid Loss = 0.4750\n",
      "Iteration 9/125: Train Loss = 0.4511, Valid Loss = 0.4592\n",
      "Iteration 10/125: Train Loss = 0.4363, Valid Loss = 0.4448\n",
      "Iteration 11/125: Train Loss = 0.4228, Valid Loss = 0.4319\n",
      "Iteration 12/125: Train Loss = 0.4105, Valid Loss = 0.4204\n",
      "Iteration 13/125: Train Loss = 0.3995, Valid Loss = 0.4098\n",
      "Iteration 14/125: Train Loss = 0.3892, Valid Loss = 0.4000\n",
      "Iteration 15/125: Train Loss = 0.3796, Valid Loss = 0.3912\n",
      "Iteration 16/125: Train Loss = 0.3711, Valid Loss = 0.3830\n",
      "Iteration 17/125: Train Loss = 0.3632, Valid Loss = 0.3755\n",
      "Iteration 18/125: Train Loss = 0.3558, Valid Loss = 0.3688\n",
      "Iteration 19/125: Train Loss = 0.3490, Valid Loss = 0.3628\n",
      "Iteration 20/125: Train Loss = 0.3426, Valid Loss = 0.3571\n",
      "Iteration 21/125: Train Loss = 0.3367, Valid Loss = 0.3516\n",
      "Iteration 22/125: Train Loss = 0.3312, Valid Loss = 0.3465\n",
      "Iteration 23/125: Train Loss = 0.3262, Valid Loss = 0.3417\n",
      "Iteration 24/125: Train Loss = 0.3213, Valid Loss = 0.3373\n",
      "Iteration 25/125: Train Loss = 0.3164, Valid Loss = 0.3330\n",
      "Iteration 26/125: Train Loss = 0.3122, Valid Loss = 0.3293\n",
      "Iteration 27/125: Train Loss = 0.3083, Valid Loss = 0.3256\n",
      "Iteration 28/125: Train Loss = 0.3046, Valid Loss = 0.3225\n",
      "Iteration 29/125: Train Loss = 0.3011, Valid Loss = 0.3194\n",
      "Iteration 30/125: Train Loss = 0.2976, Valid Loss = 0.3163\n",
      "Iteration 31/125: Train Loss = 0.2944, Valid Loss = 0.3136\n",
      "Iteration 32/125: Train Loss = 0.2913, Valid Loss = 0.3108\n",
      "Iteration 33/125: Train Loss = 0.2884, Valid Loss = 0.3083\n",
      "Iteration 34/125: Train Loss = 0.2855, Valid Loss = 0.3055\n",
      "Iteration 35/125: Train Loss = 0.2827, Valid Loss = 0.3032\n",
      "Iteration 36/125: Train Loss = 0.2803, Valid Loss = 0.3010\n",
      "Iteration 37/125: Train Loss = 0.2777, Valid Loss = 0.2985\n",
      "Iteration 38/125: Train Loss = 0.2752, Valid Loss = 0.2965\n",
      "Iteration 39/125: Train Loss = 0.2728, Valid Loss = 0.2948\n",
      "Iteration 40/125: Train Loss = 0.2706, Valid Loss = 0.2930\n",
      "Iteration 41/125: Train Loss = 0.2684, Valid Loss = 0.2913\n",
      "Iteration 42/125: Train Loss = 0.2664, Valid Loss = 0.2898\n",
      "Iteration 43/125: Train Loss = 0.2646, Valid Loss = 0.2882\n",
      "Iteration 44/125: Train Loss = 0.2627, Valid Loss = 0.2867\n",
      "Iteration 45/125: Train Loss = 0.2610, Valid Loss = 0.2851\n",
      "Iteration 46/125: Train Loss = 0.2593, Valid Loss = 0.2837\n",
      "Iteration 47/125: Train Loss = 0.2576, Valid Loss = 0.2824\n",
      "Iteration 48/125: Train Loss = 0.2560, Valid Loss = 0.2812\n",
      "Iteration 49/125: Train Loss = 0.2545, Valid Loss = 0.2800\n",
      "Iteration 50/125: Train Loss = 0.2530, Valid Loss = 0.2788\n",
      "Iteration 51/125: Train Loss = 0.2516, Valid Loss = 0.2780\n",
      "Iteration 52/125: Train Loss = 0.2502, Valid Loss = 0.2767\n",
      "Iteration 53/125: Train Loss = 0.2489, Valid Loss = 0.2756\n",
      "Iteration 54/125: Train Loss = 0.2477, Valid Loss = 0.2745\n",
      "Iteration 55/125: Train Loss = 0.2465, Valid Loss = 0.2736\n",
      "Iteration 56/125: Train Loss = 0.2452, Valid Loss = 0.2727\n",
      "Iteration 57/125: Train Loss = 0.2441, Valid Loss = 0.2715\n",
      "Iteration 58/125: Train Loss = 0.2431, Valid Loss = 0.2708\n",
      "Iteration 59/125: Train Loss = 0.2420, Valid Loss = 0.2700\n",
      "Iteration 60/125: Train Loss = 0.2409, Valid Loss = 0.2690\n",
      "Iteration 61/125: Train Loss = 0.2398, Valid Loss = 0.2678\n",
      "Iteration 62/125: Train Loss = 0.2387, Valid Loss = 0.2671\n",
      "Iteration 63/125: Train Loss = 0.2379, Valid Loss = 0.2665\n",
      "Iteration 64/125: Train Loss = 0.2368, Valid Loss = 0.2658\n",
      "Iteration 65/125: Train Loss = 0.2359, Valid Loss = 0.2651\n",
      "Iteration 66/125: Train Loss = 0.2349, Valid Loss = 0.2646\n",
      "Iteration 67/125: Train Loss = 0.2339, Valid Loss = 0.2641\n",
      "Iteration 68/125: Train Loss = 0.2330, Valid Loss = 0.2629\n",
      "Iteration 69/125: Train Loss = 0.2321, Valid Loss = 0.2621\n",
      "Iteration 70/125: Train Loss = 0.2313, Valid Loss = 0.2614\n",
      "Iteration 71/125: Train Loss = 0.2306, Valid Loss = 0.2609\n",
      "Iteration 72/125: Train Loss = 0.2298, Valid Loss = 0.2603\n",
      "Iteration 73/125: Train Loss = 0.2290, Valid Loss = 0.2599\n",
      "Iteration 74/125: Train Loss = 0.2282, Valid Loss = 0.2594\n",
      "Iteration 75/125: Train Loss = 0.2275, Valid Loss = 0.2588\n",
      "Iteration 76/125: Train Loss = 0.2266, Valid Loss = 0.2582\n",
      "Iteration 77/125: Train Loss = 0.2259, Valid Loss = 0.2579\n",
      "Iteration 78/125: Train Loss = 0.2251, Valid Loss = 0.2576\n",
      "Iteration 79/125: Train Loss = 0.2245, Valid Loss = 0.2571\n",
      "Iteration 80/125: Train Loss = 0.2239, Valid Loss = 0.2568\n",
      "Iteration 81/125: Train Loss = 0.2233, Valid Loss = 0.2563\n",
      "Iteration 82/125: Train Loss = 0.2226, Valid Loss = 0.2557\n",
      "Iteration 83/125: Train Loss = 0.2220, Valid Loss = 0.2552\n",
      "Iteration 84/125: Train Loss = 0.2215, Valid Loss = 0.2547\n",
      "Iteration 85/125: Train Loss = 0.2209, Valid Loss = 0.2543\n",
      "Iteration 86/125: Train Loss = 0.2203, Valid Loss = 0.2539\n",
      "Iteration 87/125: Train Loss = 0.2196, Valid Loss = 0.2537\n",
      "Iteration 88/125: Train Loss = 0.2191, Valid Loss = 0.2532\n",
      "Iteration 89/125: Train Loss = 0.2185, Valid Loss = 0.2530\n",
      "Iteration 90/125: Train Loss = 0.2180, Valid Loss = 0.2526\n",
      "Iteration 91/125: Train Loss = 0.2175, Valid Loss = 0.2524\n",
      "Iteration 92/125: Train Loss = 0.2169, Valid Loss = 0.2520\n",
      "Iteration 93/125: Train Loss = 0.2164, Valid Loss = 0.2516\n",
      "Iteration 94/125: Train Loss = 0.2159, Valid Loss = 0.2513\n",
      "Iteration 95/125: Train Loss = 0.2154, Valid Loss = 0.2510\n",
      "Iteration 96/125: Train Loss = 0.2150, Valid Loss = 0.2509\n",
      "Iteration 97/125: Train Loss = 0.2145, Valid Loss = 0.2505\n",
      "Iteration 98/125: Train Loss = 0.2140, Valid Loss = 0.2502\n",
      "Iteration 99/125: Train Loss = 0.2134, Valid Loss = 0.2498\n",
      "Iteration 100/125: Train Loss = 0.2129, Valid Loss = 0.2495\n",
      "Iteration 101/125: Train Loss = 0.2124, Valid Loss = 0.2491\n",
      "Iteration 102/125: Train Loss = 0.2120, Valid Loss = 0.2489\n",
      "Iteration 103/125: Train Loss = 0.2115, Valid Loss = 0.2486\n",
      "Iteration 104/125: Train Loss = 0.2111, Valid Loss = 0.2483\n",
      "Iteration 105/125: Train Loss = 0.2106, Valid Loss = 0.2480\n",
      "Iteration 106/125: Train Loss = 0.2102, Valid Loss = 0.2478\n",
      "Iteration 107/125: Train Loss = 0.2098, Valid Loss = 0.2476\n",
      "Iteration 108/125: Train Loss = 0.2093, Valid Loss = 0.2474\n",
      "Iteration 109/125: Train Loss = 0.2089, Valid Loss = 0.2472\n",
      "Iteration 110/125: Train Loss = 0.2084, Valid Loss = 0.2469\n",
      "Iteration 111/125: Train Loss = 0.2081, Valid Loss = 0.2467\n",
      "Iteration 112/125: Train Loss = 0.2077, Valid Loss = 0.2466\n",
      "Iteration 113/125: Train Loss = 0.2073, Valid Loss = 0.2463\n",
      "Iteration 114/125: Train Loss = 0.2070, Valid Loss = 0.2460\n",
      "Iteration 115/125: Train Loss = 0.2066, Valid Loss = 0.2457\n",
      "Iteration 116/125: Train Loss = 0.2062, Valid Loss = 0.2456\n",
      "Iteration 117/125: Train Loss = 0.2059, Valid Loss = 0.2455\n",
      "Iteration 118/125: Train Loss = 0.2055, Valid Loss = 0.2454\n",
      "Iteration 119/125: Train Loss = 0.2051, Valid Loss = 0.2452\n",
      "Iteration 120/125: Train Loss = 0.2047, Valid Loss = 0.2450\n",
      "Iteration 121/125: Train Loss = 0.2044, Valid Loss = 0.2451\n",
      "Iteration 122/125: Train Loss = 0.2041, Valid Loss = 0.2450\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-05 00:52:26,604] Trial 43 finished with value: 0.9655536872447754 and parameters: {'max_depth': 8, 'min_samples_leaf': 16, 'n_estimators': 125, 'learning_rate': 0.24765493815280082, 'subsample': 0.6682424955954727}. Best is trial 27 with value: 0.9657550072635349.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 123/125: Train Loss = 0.2039, Valid Loss = 0.2449\n",
      "Iteration 124/125: Train Loss = 0.2035, Valid Loss = 0.2447\n",
      "Iteration 125/125: Train Loss = 0.2032, Valid Loss = 0.2444\n",
      "Iteration 1/150: Train Loss = 0.6580, Valid Loss = 0.6588\n",
      "Iteration 2/150: Train Loss = 0.6268, Valid Loss = 0.6286\n",
      "Iteration 3/150: Train Loss = 0.5984, Valid Loss = 0.6006\n",
      "Iteration 4/150: Train Loss = 0.5731, Valid Loss = 0.5761\n",
      "Iteration 5/150: Train Loss = 0.5499, Valid Loss = 0.5537\n",
      "Iteration 6/150: Train Loss = 0.5293, Valid Loss = 0.5340\n",
      "Iteration 7/150: Train Loss = 0.5099, Valid Loss = 0.5155\n",
      "Iteration 8/150: Train Loss = 0.4927, Valid Loss = 0.4987\n",
      "Iteration 9/150: Train Loss = 0.4773, Valid Loss = 0.4836\n",
      "Iteration 10/150: Train Loss = 0.4633, Valid Loss = 0.4698\n",
      "Iteration 11/150: Train Loss = 0.4503, Valid Loss = 0.4573\n",
      "Iteration 12/150: Train Loss = 0.4382, Valid Loss = 0.4462\n",
      "Iteration 13/150: Train Loss = 0.4272, Valid Loss = 0.4357\n",
      "Iteration 14/150: Train Loss = 0.4173, Valid Loss = 0.4262\n",
      "Iteration 15/150: Train Loss = 0.4079, Valid Loss = 0.4172\n",
      "Iteration 16/150: Train Loss = 0.3993, Valid Loss = 0.4089\n",
      "Iteration 17/150: Train Loss = 0.3915, Valid Loss = 0.4018\n",
      "Iteration 18/150: Train Loss = 0.3841, Valid Loss = 0.3947\n",
      "Iteration 19/150: Train Loss = 0.3773, Valid Loss = 0.3884\n",
      "Iteration 20/150: Train Loss = 0.3709, Valid Loss = 0.3825\n",
      "Iteration 21/150: Train Loss = 0.3648, Valid Loss = 0.3767\n",
      "Iteration 22/150: Train Loss = 0.3588, Valid Loss = 0.3711\n",
      "Iteration 23/150: Train Loss = 0.3535, Valid Loss = 0.3661\n",
      "Iteration 24/150: Train Loss = 0.3482, Valid Loss = 0.3612\n",
      "Iteration 25/150: Train Loss = 0.3435, Valid Loss = 0.3568\n",
      "Iteration 26/150: Train Loss = 0.3390, Valid Loss = 0.3528\n",
      "Iteration 27/150: Train Loss = 0.3348, Valid Loss = 0.3491\n",
      "Iteration 28/150: Train Loss = 0.3305, Valid Loss = 0.3452\n",
      "Iteration 29/150: Train Loss = 0.3269, Valid Loss = 0.3417\n",
      "Iteration 30/150: Train Loss = 0.3233, Valid Loss = 0.3382\n",
      "Iteration 31/150: Train Loss = 0.3200, Valid Loss = 0.3352\n",
      "Iteration 32/150: Train Loss = 0.3168, Valid Loss = 0.3321\n",
      "Iteration 33/150: Train Loss = 0.3137, Valid Loss = 0.3291\n",
      "Iteration 34/150: Train Loss = 0.3108, Valid Loss = 0.3262\n",
      "Iteration 35/150: Train Loss = 0.3081, Valid Loss = 0.3236\n",
      "Iteration 36/150: Train Loss = 0.3052, Valid Loss = 0.3210\n",
      "Iteration 37/150: Train Loss = 0.3026, Valid Loss = 0.3186\n",
      "Iteration 38/150: Train Loss = 0.3001, Valid Loss = 0.3163\n",
      "Iteration 39/150: Train Loss = 0.2977, Valid Loss = 0.3144\n",
      "Iteration 40/150: Train Loss = 0.2953, Valid Loss = 0.3125\n",
      "Iteration 41/150: Train Loss = 0.2932, Valid Loss = 0.3106\n",
      "Iteration 42/150: Train Loss = 0.2912, Valid Loss = 0.3088\n",
      "Iteration 43/150: Train Loss = 0.2893, Valid Loss = 0.3071\n",
      "Iteration 44/150: Train Loss = 0.2874, Valid Loss = 0.3052\n",
      "Iteration 45/150: Train Loss = 0.2856, Valid Loss = 0.3035\n",
      "Iteration 46/150: Train Loss = 0.2838, Valid Loss = 0.3018\n",
      "Iteration 47/150: Train Loss = 0.2821, Valid Loss = 0.3002\n",
      "Iteration 48/150: Train Loss = 0.2804, Valid Loss = 0.2986\n",
      "Iteration 49/150: Train Loss = 0.2788, Valid Loss = 0.2973\n",
      "Iteration 50/150: Train Loss = 0.2773, Valid Loss = 0.2960\n",
      "Iteration 51/150: Train Loss = 0.2758, Valid Loss = 0.2946\n",
      "Iteration 52/150: Train Loss = 0.2743, Valid Loss = 0.2933\n",
      "Iteration 53/150: Train Loss = 0.2729, Valid Loss = 0.2920\n",
      "Iteration 54/150: Train Loss = 0.2715, Valid Loss = 0.2908\n",
      "Iteration 55/150: Train Loss = 0.2703, Valid Loss = 0.2897\n",
      "Iteration 56/150: Train Loss = 0.2690, Valid Loss = 0.2886\n",
      "Iteration 57/150: Train Loss = 0.2676, Valid Loss = 0.2875\n",
      "Iteration 58/150: Train Loss = 0.2664, Valid Loss = 0.2865\n",
      "Iteration 59/150: Train Loss = 0.2653, Valid Loss = 0.2855\n",
      "Iteration 60/150: Train Loss = 0.2642, Valid Loss = 0.2848\n",
      "Iteration 61/150: Train Loss = 0.2631, Valid Loss = 0.2840\n",
      "Iteration 62/150: Train Loss = 0.2620, Valid Loss = 0.2831\n",
      "Iteration 63/150: Train Loss = 0.2610, Valid Loss = 0.2824\n",
      "Iteration 64/150: Train Loss = 0.2600, Valid Loss = 0.2813\n",
      "Iteration 65/150: Train Loss = 0.2589, Valid Loss = 0.2804\n",
      "Iteration 66/150: Train Loss = 0.2578, Valid Loss = 0.2794\n",
      "Iteration 67/150: Train Loss = 0.2568, Valid Loss = 0.2785\n",
      "Iteration 68/150: Train Loss = 0.2558, Valid Loss = 0.2776\n",
      "Iteration 69/150: Train Loss = 0.2547, Valid Loss = 0.2766\n",
      "Iteration 70/150: Train Loss = 0.2539, Valid Loss = 0.2759\n",
      "Iteration 71/150: Train Loss = 0.2529, Valid Loss = 0.2751\n",
      "Iteration 72/150: Train Loss = 0.2518, Valid Loss = 0.2744\n",
      "Iteration 73/150: Train Loss = 0.2510, Valid Loss = 0.2736\n",
      "Iteration 74/150: Train Loss = 0.2502, Valid Loss = 0.2732\n",
      "Iteration 75/150: Train Loss = 0.2494, Valid Loss = 0.2725\n",
      "Iteration 76/150: Train Loss = 0.2485, Valid Loss = 0.2719\n",
      "Iteration 77/150: Train Loss = 0.2477, Valid Loss = 0.2711\n",
      "Iteration 78/150: Train Loss = 0.2471, Valid Loss = 0.2706\n",
      "Iteration 79/150: Train Loss = 0.2464, Valid Loss = 0.2700\n",
      "Iteration 80/150: Train Loss = 0.2455, Valid Loss = 0.2694\n",
      "Iteration 81/150: Train Loss = 0.2448, Valid Loss = 0.2689\n",
      "Iteration 82/150: Train Loss = 0.2440, Valid Loss = 0.2683\n",
      "Iteration 83/150: Train Loss = 0.2433, Valid Loss = 0.2677\n",
      "Iteration 84/150: Train Loss = 0.2426, Valid Loss = 0.2672\n",
      "Iteration 85/150: Train Loss = 0.2420, Valid Loss = 0.2669\n",
      "Iteration 86/150: Train Loss = 0.2414, Valid Loss = 0.2664\n",
      "Iteration 87/150: Train Loss = 0.2408, Valid Loss = 0.2660\n",
      "Iteration 88/150: Train Loss = 0.2403, Valid Loss = 0.2655\n",
      "Iteration 89/150: Train Loss = 0.2395, Valid Loss = 0.2650\n",
      "Iteration 90/150: Train Loss = 0.2390, Valid Loss = 0.2648\n",
      "Iteration 91/150: Train Loss = 0.2384, Valid Loss = 0.2643\n",
      "Iteration 92/150: Train Loss = 0.2379, Valid Loss = 0.2640\n",
      "Iteration 93/150: Train Loss = 0.2375, Valid Loss = 0.2636\n",
      "Iteration 94/150: Train Loss = 0.2370, Valid Loss = 0.2631\n",
      "Iteration 95/150: Train Loss = 0.2364, Valid Loss = 0.2627\n",
      "Iteration 96/150: Train Loss = 0.2358, Valid Loss = 0.2623\n",
      "Iteration 97/150: Train Loss = 0.2352, Valid Loss = 0.2619\n",
      "Iteration 98/150: Train Loss = 0.2348, Valid Loss = 0.2616\n",
      "Iteration 99/150: Train Loss = 0.2343, Valid Loss = 0.2613\n",
      "Iteration 100/150: Train Loss = 0.2338, Valid Loss = 0.2609\n",
      "Iteration 101/150: Train Loss = 0.2332, Valid Loss = 0.2604\n",
      "Iteration 102/150: Train Loss = 0.2328, Valid Loss = 0.2599\n",
      "Iteration 103/150: Train Loss = 0.2323, Valid Loss = 0.2596\n",
      "Iteration 104/150: Train Loss = 0.2318, Valid Loss = 0.2592\n",
      "Iteration 105/150: Train Loss = 0.2314, Valid Loss = 0.2589\n",
      "Iteration 106/150: Train Loss = 0.2309, Valid Loss = 0.2586\n",
      "Iteration 107/150: Train Loss = 0.2305, Valid Loss = 0.2583\n",
      "Iteration 108/150: Train Loss = 0.2301, Valid Loss = 0.2579\n",
      "Iteration 109/150: Train Loss = 0.2297, Valid Loss = 0.2576\n",
      "Iteration 110/150: Train Loss = 0.2293, Valid Loss = 0.2574\n",
      "Iteration 111/150: Train Loss = 0.2290, Valid Loss = 0.2570\n",
      "Iteration 112/150: Train Loss = 0.2286, Valid Loss = 0.2567\n",
      "Iteration 113/150: Train Loss = 0.2283, Valid Loss = 0.2563\n",
      "Iteration 114/150: Train Loss = 0.2278, Valid Loss = 0.2562\n",
      "Iteration 115/150: Train Loss = 0.2275, Valid Loss = 0.2560\n",
      "Iteration 116/150: Train Loss = 0.2270, Valid Loss = 0.2557\n",
      "Iteration 117/150: Train Loss = 0.2267, Valid Loss = 0.2554\n",
      "Iteration 118/150: Train Loss = 0.2263, Valid Loss = 0.2553\n",
      "Iteration 119/150: Train Loss = 0.2259, Valid Loss = 0.2552\n",
      "Iteration 120/150: Train Loss = 0.2256, Valid Loss = 0.2550\n",
      "Iteration 121/150: Train Loss = 0.2252, Valid Loss = 0.2548\n",
      "Iteration 122/150: Train Loss = 0.2248, Valid Loss = 0.2544\n",
      "Iteration 123/150: Train Loss = 0.2245, Valid Loss = 0.2542\n",
      "Iteration 124/150: Train Loss = 0.2241, Valid Loss = 0.2539\n",
      "Iteration 125/150: Train Loss = 0.2238, Valid Loss = 0.2537\n",
      "Iteration 126/150: Train Loss = 0.2234, Valid Loss = 0.2533\n",
      "Iteration 127/150: Train Loss = 0.2232, Valid Loss = 0.2531\n",
      "Iteration 128/150: Train Loss = 0.2228, Valid Loss = 0.2528\n",
      "Iteration 129/150: Train Loss = 0.2224, Valid Loss = 0.2524\n",
      "Iteration 130/150: Train Loss = 0.2221, Valid Loss = 0.2523\n",
      "Iteration 131/150: Train Loss = 0.2218, Valid Loss = 0.2522\n",
      "Iteration 132/150: Train Loss = 0.2215, Valid Loss = 0.2519\n",
      "Iteration 133/150: Train Loss = 0.2211, Valid Loss = 0.2517\n",
      "Iteration 134/150: Train Loss = 0.2208, Valid Loss = 0.2515\n",
      "Iteration 135/150: Train Loss = 0.2205, Valid Loss = 0.2514\n",
      "Iteration 136/150: Train Loss = 0.2202, Valid Loss = 0.2512\n",
      "Iteration 137/150: Train Loss = 0.2199, Valid Loss = 0.2510\n",
      "Iteration 138/150: Train Loss = 0.2195, Valid Loss = 0.2507\n",
      "Iteration 139/150: Train Loss = 0.2192, Valid Loss = 0.2505\n",
      "Iteration 140/150: Train Loss = 0.2189, Valid Loss = 0.2504\n",
      "Iteration 141/150: Train Loss = 0.2186, Valid Loss = 0.2504\n",
      "Iteration 142/150: Train Loss = 0.2183, Valid Loss = 0.2502\n",
      "Iteration 143/150: Train Loss = 0.2180, Valid Loss = 0.2501\n",
      "Iteration 144/150: Train Loss = 0.2177, Valid Loss = 0.2500\n",
      "Iteration 145/150: Train Loss = 0.2175, Valid Loss = 0.2498\n",
      "Iteration 146/150: Train Loss = 0.2172, Valid Loss = 0.2495\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-05 00:52:33,161] Trial 44 finished with value: 0.9643633063762779 and parameters: {'max_depth': 6, 'min_samples_leaf': 14, 'n_estimators': 150, 'learning_rate': 0.2177873760562631, 'subsample': 0.6543962753356145}. Best is trial 27 with value: 0.9657550072635349.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 147/150: Train Loss = 0.2170, Valid Loss = 0.2494\n",
      "Iteration 148/150: Train Loss = 0.2167, Valid Loss = 0.2492\n",
      "Iteration 149/150: Train Loss = 0.2164, Valid Loss = 0.2490\n",
      "Iteration 150/150: Train Loss = 0.2162, Valid Loss = 0.2488\n",
      "Iteration 1/135: Train Loss = 0.6766, Valid Loss = 0.6770\n",
      "Iteration 2/135: Train Loss = 0.6608, Valid Loss = 0.6615\n",
      "Iteration 3/135: Train Loss = 0.6457, Valid Loss = 0.6468\n",
      "Iteration 4/135: Train Loss = 0.6316, Valid Loss = 0.6330\n",
      "Iteration 5/135: Train Loss = 0.6179, Valid Loss = 0.6196\n",
      "Iteration 6/135: Train Loss = 0.6053, Valid Loss = 0.6073\n",
      "Iteration 7/135: Train Loss = 0.5931, Valid Loss = 0.5954\n",
      "Iteration 8/135: Train Loss = 0.5813, Valid Loss = 0.5839\n",
      "Iteration 9/135: Train Loss = 0.5704, Valid Loss = 0.5733\n",
      "Iteration 10/135: Train Loss = 0.5599, Valid Loss = 0.5630\n",
      "Iteration 11/135: Train Loss = 0.5500, Valid Loss = 0.5533\n",
      "Iteration 12/135: Train Loss = 0.5404, Valid Loss = 0.5439\n",
      "Iteration 13/135: Train Loss = 0.5315, Valid Loss = 0.5352\n",
      "Iteration 14/135: Train Loss = 0.5230, Valid Loss = 0.5270\n",
      "Iteration 15/135: Train Loss = 0.5147, Valid Loss = 0.5188\n",
      "Iteration 16/135: Train Loss = 0.5068, Valid Loss = 0.5111\n",
      "Iteration 17/135: Train Loss = 0.4993, Valid Loss = 0.5039\n",
      "Iteration 18/135: Train Loss = 0.4922, Valid Loss = 0.4971\n",
      "Iteration 19/135: Train Loss = 0.4855, Valid Loss = 0.4905\n",
      "Iteration 20/135: Train Loss = 0.4790, Valid Loss = 0.4842\n",
      "Iteration 21/135: Train Loss = 0.4727, Valid Loss = 0.4780\n",
      "Iteration 22/135: Train Loss = 0.4669, Valid Loss = 0.4723\n",
      "Iteration 23/135: Train Loss = 0.4611, Valid Loss = 0.4668\n",
      "Iteration 24/135: Train Loss = 0.4554, Valid Loss = 0.4612\n",
      "Iteration 25/135: Train Loss = 0.4502, Valid Loss = 0.4560\n",
      "Iteration 26/135: Train Loss = 0.4452, Valid Loss = 0.4511\n",
      "Iteration 27/135: Train Loss = 0.4403, Valid Loss = 0.4463\n",
      "Iteration 28/135: Train Loss = 0.4357, Valid Loss = 0.4419\n",
      "Iteration 29/135: Train Loss = 0.4312, Valid Loss = 0.4375\n",
      "Iteration 30/135: Train Loss = 0.4269, Valid Loss = 0.4332\n",
      "Iteration 31/135: Train Loss = 0.4228, Valid Loss = 0.4292\n",
      "Iteration 32/135: Train Loss = 0.4187, Valid Loss = 0.4253\n",
      "Iteration 33/135: Train Loss = 0.4149, Valid Loss = 0.4216\n",
      "Iteration 34/135: Train Loss = 0.4111, Valid Loss = 0.4180\n",
      "Iteration 35/135: Train Loss = 0.4076, Valid Loss = 0.4145\n",
      "Iteration 36/135: Train Loss = 0.4042, Valid Loss = 0.4111\n",
      "Iteration 37/135: Train Loss = 0.4008, Valid Loss = 0.4077\n",
      "Iteration 38/135: Train Loss = 0.3975, Valid Loss = 0.4046\n",
      "Iteration 39/135: Train Loss = 0.3944, Valid Loss = 0.4015\n",
      "Iteration 40/135: Train Loss = 0.3916, Valid Loss = 0.3988\n",
      "Iteration 41/135: Train Loss = 0.3885, Valid Loss = 0.3958\n",
      "Iteration 42/135: Train Loss = 0.3856, Valid Loss = 0.3931\n",
      "Iteration 43/135: Train Loss = 0.3829, Valid Loss = 0.3903\n",
      "Iteration 44/135: Train Loss = 0.3803, Valid Loss = 0.3877\n",
      "Iteration 45/135: Train Loss = 0.3777, Valid Loss = 0.3853\n",
      "Iteration 46/135: Train Loss = 0.3753, Valid Loss = 0.3830\n",
      "Iteration 47/135: Train Loss = 0.3729, Valid Loss = 0.3806\n",
      "Iteration 48/135: Train Loss = 0.3706, Valid Loss = 0.3785\n",
      "Iteration 49/135: Train Loss = 0.3683, Valid Loss = 0.3764\n",
      "Iteration 50/135: Train Loss = 0.3662, Valid Loss = 0.3743\n",
      "Iteration 51/135: Train Loss = 0.3641, Valid Loss = 0.3722\n",
      "Iteration 52/135: Train Loss = 0.3620, Valid Loss = 0.3702\n",
      "Iteration 53/135: Train Loss = 0.3600, Valid Loss = 0.3682\n",
      "Iteration 54/135: Train Loss = 0.3580, Valid Loss = 0.3663\n",
      "Iteration 55/135: Train Loss = 0.3560, Valid Loss = 0.3642\n",
      "Iteration 56/135: Train Loss = 0.3541, Valid Loss = 0.3623\n",
      "Iteration 57/135: Train Loss = 0.3522, Valid Loss = 0.3604\n",
      "Iteration 58/135: Train Loss = 0.3504, Valid Loss = 0.3587\n",
      "Iteration 59/135: Train Loss = 0.3487, Valid Loss = 0.3570\n",
      "Iteration 60/135: Train Loss = 0.3470, Valid Loss = 0.3553\n",
      "Iteration 61/135: Train Loss = 0.3453, Valid Loss = 0.3537\n",
      "Iteration 62/135: Train Loss = 0.3438, Valid Loss = 0.3522\n",
      "Iteration 63/135: Train Loss = 0.3421, Valid Loss = 0.3506\n",
      "Iteration 64/135: Train Loss = 0.3406, Valid Loss = 0.3491\n",
      "Iteration 65/135: Train Loss = 0.3392, Valid Loss = 0.3478\n",
      "Iteration 66/135: Train Loss = 0.3378, Valid Loss = 0.3464\n",
      "Iteration 67/135: Train Loss = 0.3364, Valid Loss = 0.3450\n",
      "Iteration 68/135: Train Loss = 0.3351, Valid Loss = 0.3437\n",
      "Iteration 69/135: Train Loss = 0.3337, Valid Loss = 0.3425\n",
      "Iteration 70/135: Train Loss = 0.3324, Valid Loss = 0.3411\n",
      "Iteration 71/135: Train Loss = 0.3312, Valid Loss = 0.3400\n",
      "Iteration 72/135: Train Loss = 0.3300, Valid Loss = 0.3388\n",
      "Iteration 73/135: Train Loss = 0.3288, Valid Loss = 0.3377\n",
      "Iteration 74/135: Train Loss = 0.3276, Valid Loss = 0.3366\n",
      "Iteration 75/135: Train Loss = 0.3263, Valid Loss = 0.3354\n",
      "Iteration 76/135: Train Loss = 0.3252, Valid Loss = 0.3343\n",
      "Iteration 77/135: Train Loss = 0.3240, Valid Loss = 0.3331\n",
      "Iteration 78/135: Train Loss = 0.3228, Valid Loss = 0.3319\n",
      "Iteration 79/135: Train Loss = 0.3218, Valid Loss = 0.3307\n",
      "Iteration 80/135: Train Loss = 0.3207, Valid Loss = 0.3297\n",
      "Iteration 81/135: Train Loss = 0.3196, Valid Loss = 0.3288\n",
      "Iteration 82/135: Train Loss = 0.3186, Valid Loss = 0.3278\n",
      "Iteration 83/135: Train Loss = 0.3176, Valid Loss = 0.3267\n",
      "Iteration 84/135: Train Loss = 0.3166, Valid Loss = 0.3258\n",
      "Iteration 85/135: Train Loss = 0.3156, Valid Loss = 0.3249\n",
      "Iteration 86/135: Train Loss = 0.3147, Valid Loss = 0.3240\n",
      "Iteration 87/135: Train Loss = 0.3138, Valid Loss = 0.3233\n",
      "Iteration 88/135: Train Loss = 0.3128, Valid Loss = 0.3224\n",
      "Iteration 89/135: Train Loss = 0.3119, Valid Loss = 0.3215\n",
      "Iteration 90/135: Train Loss = 0.3110, Valid Loss = 0.3206\n",
      "Iteration 91/135: Train Loss = 0.3100, Valid Loss = 0.3198\n",
      "Iteration 92/135: Train Loss = 0.3090, Valid Loss = 0.3190\n",
      "Iteration 93/135: Train Loss = 0.3082, Valid Loss = 0.3181\n",
      "Iteration 94/135: Train Loss = 0.3074, Valid Loss = 0.3174\n",
      "Iteration 95/135: Train Loss = 0.3066, Valid Loss = 0.3167\n",
      "Iteration 96/135: Train Loss = 0.3058, Valid Loss = 0.3159\n",
      "Iteration 97/135: Train Loss = 0.3051, Valid Loss = 0.3153\n",
      "Iteration 98/135: Train Loss = 0.3043, Valid Loss = 0.3146\n",
      "Iteration 99/135: Train Loss = 0.3035, Valid Loss = 0.3139\n",
      "Iteration 100/135: Train Loss = 0.3028, Valid Loss = 0.3131\n",
      "Iteration 101/135: Train Loss = 0.3021, Valid Loss = 0.3124\n",
      "Iteration 102/135: Train Loss = 0.3013, Valid Loss = 0.3116\n",
      "Iteration 103/135: Train Loss = 0.3006, Valid Loss = 0.3109\n",
      "Iteration 104/135: Train Loss = 0.2999, Valid Loss = 0.3102\n",
      "Iteration 105/135: Train Loss = 0.2991, Valid Loss = 0.3095\n",
      "Iteration 106/135: Train Loss = 0.2985, Valid Loss = 0.3088\n",
      "Iteration 107/135: Train Loss = 0.2979, Valid Loss = 0.3082\n",
      "Iteration 108/135: Train Loss = 0.2973, Valid Loss = 0.3077\n",
      "Iteration 109/135: Train Loss = 0.2966, Valid Loss = 0.3070\n",
      "Iteration 110/135: Train Loss = 0.2960, Valid Loss = 0.3064\n",
      "Iteration 111/135: Train Loss = 0.2954, Valid Loss = 0.3058\n",
      "Iteration 112/135: Train Loss = 0.2948, Valid Loss = 0.3052\n",
      "Iteration 113/135: Train Loss = 0.2941, Valid Loss = 0.3046\n",
      "Iteration 114/135: Train Loss = 0.2935, Valid Loss = 0.3040\n",
      "Iteration 115/135: Train Loss = 0.2929, Valid Loss = 0.3035\n",
      "Iteration 116/135: Train Loss = 0.2924, Valid Loss = 0.3030\n",
      "Iteration 117/135: Train Loss = 0.2918, Valid Loss = 0.3024\n",
      "Iteration 118/135: Train Loss = 0.2912, Valid Loss = 0.3019\n",
      "Iteration 119/135: Train Loss = 0.2906, Valid Loss = 0.3013\n",
      "Iteration 120/135: Train Loss = 0.2901, Valid Loss = 0.3008\n",
      "Iteration 121/135: Train Loss = 0.2895, Valid Loss = 0.3004\n",
      "Iteration 122/135: Train Loss = 0.2890, Valid Loss = 0.2999\n",
      "Iteration 123/135: Train Loss = 0.2885, Valid Loss = 0.2994\n",
      "Iteration 124/135: Train Loss = 0.2879, Valid Loss = 0.2988\n",
      "Iteration 125/135: Train Loss = 0.2873, Valid Loss = 0.2984\n",
      "Iteration 126/135: Train Loss = 0.2868, Valid Loss = 0.2978\n",
      "Iteration 127/135: Train Loss = 0.2863, Valid Loss = 0.2973\n",
      "Iteration 128/135: Train Loss = 0.2858, Valid Loss = 0.2968\n",
      "Iteration 129/135: Train Loss = 0.2852, Valid Loss = 0.2963\n",
      "Iteration 130/135: Train Loss = 0.2847, Valid Loss = 0.2958\n",
      "Iteration 131/135: Train Loss = 0.2842, Valid Loss = 0.2953\n",
      "Iteration 132/135: Train Loss = 0.2837, Valid Loss = 0.2948\n",
      "Iteration 133/135: Train Loss = 0.2832, Valid Loss = 0.2944\n",
      "Iteration 134/135: Train Loss = 0.2827, Valid Loss = 0.2940\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-05 00:52:37,556] Trial 45 finished with value: 0.9571134979734548 and parameters: {'max_depth': 4, 'min_samples_leaf': 17, 'n_estimators': 135, 'learning_rate': 0.11069822935729773, 'subsample': 0.6736377082178319}. Best is trial 27 with value: 0.9657550072635349.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 135/135: Train Loss = 0.2823, Valid Loss = 0.2936\n",
      "Iteration 1/140: Train Loss = 0.6539, Valid Loss = 0.6549\n",
      "Iteration 2/140: Train Loss = 0.6188, Valid Loss = 0.6211\n",
      "Iteration 3/140: Train Loss = 0.5878, Valid Loss = 0.5914\n",
      "Iteration 4/140: Train Loss = 0.5601, Valid Loss = 0.5646\n",
      "Iteration 5/140: Train Loss = 0.5353, Valid Loss = 0.5404\n",
      "Iteration 6/140: Train Loss = 0.5126, Valid Loss = 0.5186\n",
      "Iteration 7/140: Train Loss = 0.4928, Valid Loss = 0.4991\n",
      "Iteration 8/140: Train Loss = 0.4745, Valid Loss = 0.4813\n",
      "Iteration 9/140: Train Loss = 0.4578, Valid Loss = 0.4655\n",
      "Iteration 10/140: Train Loss = 0.4426, Valid Loss = 0.4512\n",
      "Iteration 11/140: Train Loss = 0.4288, Valid Loss = 0.4384\n",
      "Iteration 12/140: Train Loss = 0.4162, Valid Loss = 0.4263\n",
      "Iteration 13/140: Train Loss = 0.4049, Valid Loss = 0.4152\n",
      "Iteration 14/140: Train Loss = 0.3946, Valid Loss = 0.4054\n",
      "Iteration 15/140: Train Loss = 0.3850, Valid Loss = 0.3961\n",
      "Iteration 16/140: Train Loss = 0.3762, Valid Loss = 0.3881\n",
      "Iteration 17/140: Train Loss = 0.3681, Valid Loss = 0.3809\n",
      "Iteration 18/140: Train Loss = 0.3604, Valid Loss = 0.3738\n",
      "Iteration 19/140: Train Loss = 0.3533, Valid Loss = 0.3673\n",
      "Iteration 20/140: Train Loss = 0.3468, Valid Loss = 0.3616\n",
      "Iteration 21/140: Train Loss = 0.3407, Valid Loss = 0.3561\n",
      "Iteration 22/140: Train Loss = 0.3346, Valid Loss = 0.3506\n",
      "Iteration 23/140: Train Loss = 0.3290, Valid Loss = 0.3453\n",
      "Iteration 24/140: Train Loss = 0.3239, Valid Loss = 0.3409\n",
      "Iteration 25/140: Train Loss = 0.3191, Valid Loss = 0.3370\n",
      "Iteration 26/140: Train Loss = 0.3147, Valid Loss = 0.3328\n",
      "Iteration 27/140: Train Loss = 0.3105, Valid Loss = 0.3293\n",
      "Iteration 28/140: Train Loss = 0.3063, Valid Loss = 0.3255\n",
      "Iteration 29/140: Train Loss = 0.3025, Valid Loss = 0.3223\n",
      "Iteration 30/140: Train Loss = 0.2988, Valid Loss = 0.3191\n",
      "Iteration 31/140: Train Loss = 0.2954, Valid Loss = 0.3161\n",
      "Iteration 32/140: Train Loss = 0.2921, Valid Loss = 0.3133\n",
      "Iteration 33/140: Train Loss = 0.2891, Valid Loss = 0.3108\n",
      "Iteration 34/140: Train Loss = 0.2860, Valid Loss = 0.3082\n",
      "Iteration 35/140: Train Loss = 0.2833, Valid Loss = 0.3058\n",
      "Iteration 36/140: Train Loss = 0.2802, Valid Loss = 0.3035\n",
      "Iteration 37/140: Train Loss = 0.2778, Valid Loss = 0.3013\n",
      "Iteration 38/140: Train Loss = 0.2754, Valid Loss = 0.2995\n",
      "Iteration 39/140: Train Loss = 0.2729, Valid Loss = 0.2975\n",
      "Iteration 40/140: Train Loss = 0.2708, Valid Loss = 0.2956\n",
      "Iteration 41/140: Train Loss = 0.2686, Valid Loss = 0.2938\n",
      "Iteration 42/140: Train Loss = 0.2666, Valid Loss = 0.2923\n",
      "Iteration 43/140: Train Loss = 0.2646, Valid Loss = 0.2906\n",
      "Iteration 44/140: Train Loss = 0.2626, Valid Loss = 0.2892\n",
      "Iteration 45/140: Train Loss = 0.2606, Valid Loss = 0.2877\n",
      "Iteration 46/140: Train Loss = 0.2590, Valid Loss = 0.2862\n",
      "Iteration 47/140: Train Loss = 0.2571, Valid Loss = 0.2850\n",
      "Iteration 48/140: Train Loss = 0.2555, Valid Loss = 0.2837\n",
      "Iteration 49/140: Train Loss = 0.2539, Valid Loss = 0.2823\n",
      "Iteration 50/140: Train Loss = 0.2523, Valid Loss = 0.2812\n",
      "Iteration 51/140: Train Loss = 0.2508, Valid Loss = 0.2801\n",
      "Iteration 52/140: Train Loss = 0.2492, Valid Loss = 0.2786\n",
      "Iteration 53/140: Train Loss = 0.2477, Valid Loss = 0.2775\n",
      "Iteration 54/140: Train Loss = 0.2465, Valid Loss = 0.2765\n",
      "Iteration 55/140: Train Loss = 0.2451, Valid Loss = 0.2756\n",
      "Iteration 56/140: Train Loss = 0.2439, Valid Loss = 0.2747\n",
      "Iteration 57/140: Train Loss = 0.2427, Valid Loss = 0.2738\n",
      "Iteration 58/140: Train Loss = 0.2415, Valid Loss = 0.2729\n",
      "Iteration 59/140: Train Loss = 0.2404, Valid Loss = 0.2720\n",
      "Iteration 60/140: Train Loss = 0.2392, Valid Loss = 0.2710\n",
      "Iteration 61/140: Train Loss = 0.2381, Valid Loss = 0.2703\n",
      "Iteration 62/140: Train Loss = 0.2370, Valid Loss = 0.2695\n",
      "Iteration 63/140: Train Loss = 0.2360, Valid Loss = 0.2686\n",
      "Iteration 64/140: Train Loss = 0.2351, Valid Loss = 0.2677\n",
      "Iteration 65/140: Train Loss = 0.2342, Valid Loss = 0.2669\n",
      "Iteration 66/140: Train Loss = 0.2331, Valid Loss = 0.2662\n",
      "Iteration 67/140: Train Loss = 0.2323, Valid Loss = 0.2655\n",
      "Iteration 68/140: Train Loss = 0.2311, Valid Loss = 0.2649\n",
      "Iteration 69/140: Train Loss = 0.2301, Valid Loss = 0.2642\n",
      "Iteration 70/140: Train Loss = 0.2292, Valid Loss = 0.2637\n",
      "Iteration 71/140: Train Loss = 0.2283, Valid Loss = 0.2629\n",
      "Iteration 72/140: Train Loss = 0.2275, Valid Loss = 0.2623\n",
      "Iteration 73/140: Train Loss = 0.2267, Valid Loss = 0.2616\n",
      "Iteration 74/140: Train Loss = 0.2260, Valid Loss = 0.2610\n",
      "Iteration 75/140: Train Loss = 0.2252, Valid Loss = 0.2604\n",
      "Iteration 76/140: Train Loss = 0.2243, Valid Loss = 0.2598\n",
      "Iteration 77/140: Train Loss = 0.2236, Valid Loss = 0.2595\n",
      "Iteration 78/140: Train Loss = 0.2228, Valid Loss = 0.2590\n",
      "Iteration 79/140: Train Loss = 0.2222, Valid Loss = 0.2586\n",
      "Iteration 80/140: Train Loss = 0.2214, Valid Loss = 0.2582\n",
      "Iteration 81/140: Train Loss = 0.2207, Valid Loss = 0.2579\n",
      "Iteration 82/140: Train Loss = 0.2199, Valid Loss = 0.2575\n",
      "Iteration 83/140: Train Loss = 0.2193, Valid Loss = 0.2569\n",
      "Iteration 84/140: Train Loss = 0.2186, Valid Loss = 0.2566\n",
      "Iteration 85/140: Train Loss = 0.2180, Valid Loss = 0.2560\n",
      "Iteration 86/140: Train Loss = 0.2174, Valid Loss = 0.2556\n",
      "Iteration 87/140: Train Loss = 0.2168, Valid Loss = 0.2555\n",
      "Iteration 88/140: Train Loss = 0.2162, Valid Loss = 0.2552\n",
      "Iteration 89/140: Train Loss = 0.2155, Valid Loss = 0.2549\n",
      "Iteration 90/140: Train Loss = 0.2149, Valid Loss = 0.2546\n",
      "Iteration 91/140: Train Loss = 0.2143, Valid Loss = 0.2543\n",
      "Iteration 92/140: Train Loss = 0.2138, Valid Loss = 0.2539\n",
      "Iteration 93/140: Train Loss = 0.2132, Valid Loss = 0.2534\n",
      "Iteration 94/140: Train Loss = 0.2127, Valid Loss = 0.2529\n",
      "Iteration 95/140: Train Loss = 0.2121, Valid Loss = 0.2523\n",
      "Iteration 96/140: Train Loss = 0.2116, Valid Loss = 0.2520\n",
      "Iteration 97/140: Train Loss = 0.2111, Valid Loss = 0.2514\n",
      "Iteration 98/140: Train Loss = 0.2106, Valid Loss = 0.2513\n",
      "Iteration 99/140: Train Loss = 0.2102, Valid Loss = 0.2509\n",
      "Iteration 100/140: Train Loss = 0.2097, Valid Loss = 0.2507\n",
      "Iteration 101/140: Train Loss = 0.2092, Valid Loss = 0.2505\n",
      "Iteration 102/140: Train Loss = 0.2086, Valid Loss = 0.2502\n",
      "Iteration 103/140: Train Loss = 0.2081, Valid Loss = 0.2501\n",
      "Iteration 104/140: Train Loss = 0.2077, Valid Loss = 0.2499\n",
      "Iteration 105/140: Train Loss = 0.2073, Valid Loss = 0.2497\n",
      "Iteration 106/140: Train Loss = 0.2067, Valid Loss = 0.2495\n",
      "Iteration 107/140: Train Loss = 0.2063, Valid Loss = 0.2493\n",
      "Iteration 108/140: Train Loss = 0.2059, Valid Loss = 0.2491\n",
      "Iteration 109/140: Train Loss = 0.2054, Valid Loss = 0.2490\n",
      "Iteration 110/140: Train Loss = 0.2050, Valid Loss = 0.2486\n",
      "Iteration 111/140: Train Loss = 0.2045, Valid Loss = 0.2483\n",
      "Iteration 112/140: Train Loss = 0.2042, Valid Loss = 0.2482\n",
      "Iteration 113/140: Train Loss = 0.2037, Valid Loss = 0.2479\n",
      "Iteration 114/140: Train Loss = 0.2033, Valid Loss = 0.2478\n",
      "Iteration 115/140: Train Loss = 0.2029, Valid Loss = 0.2474\n",
      "Iteration 116/140: Train Loss = 0.2025, Valid Loss = 0.2472\n",
      "Iteration 117/140: Train Loss = 0.2021, Valid Loss = 0.2470\n",
      "Iteration 118/140: Train Loss = 0.2018, Valid Loss = 0.2467\n",
      "Iteration 119/140: Train Loss = 0.2014, Valid Loss = 0.2466\n",
      "Iteration 120/140: Train Loss = 0.2011, Valid Loss = 0.2464\n",
      "Iteration 121/140: Train Loss = 0.2006, Valid Loss = 0.2461\n",
      "Iteration 122/140: Train Loss = 0.2002, Valid Loss = 0.2459\n",
      "Iteration 123/140: Train Loss = 0.1999, Valid Loss = 0.2458\n",
      "Iteration 124/140: Train Loss = 0.1995, Valid Loss = 0.2458\n",
      "Iteration 125/140: Train Loss = 0.1992, Valid Loss = 0.2456\n",
      "Iteration 126/140: Train Loss = 0.1988, Valid Loss = 0.2453\n",
      "Iteration 127/140: Train Loss = 0.1985, Valid Loss = 0.2452\n",
      "Iteration 128/140: Train Loss = 0.1982, Valid Loss = 0.2449\n",
      "Iteration 129/140: Train Loss = 0.1979, Valid Loss = 0.2448\n",
      "Iteration 130/140: Train Loss = 0.1976, Valid Loss = 0.2447\n",
      "Iteration 131/140: Train Loss = 0.1972, Valid Loss = 0.2444\n",
      "Iteration 132/140: Train Loss = 0.1969, Valid Loss = 0.2442\n",
      "Iteration 133/140: Train Loss = 0.1966, Valid Loss = 0.2439\n",
      "Iteration 134/140: Train Loss = 0.1963, Valid Loss = 0.2437\n",
      "Iteration 135/140: Train Loss = 0.1959, Valid Loss = 0.2434\n",
      "Iteration 136/140: Train Loss = 0.1956, Valid Loss = 0.2432\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-05 00:52:45,611] Trial 46 finished with value: 0.9657184036237603 and parameters: {'max_depth': 9, 'min_samples_leaf': 15, 'n_estimators': 140, 'learning_rate': 0.2322519273008503, 'subsample': 0.5963751114541392}. Best is trial 27 with value: 0.9657550072635349.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 137/140: Train Loss = 0.1952, Valid Loss = 0.2432\n",
      "Iteration 138/140: Train Loss = 0.1950, Valid Loss = 0.2430\n",
      "Iteration 139/140: Train Loss = 0.1946, Valid Loss = 0.2430\n",
      "Iteration 140/140: Train Loss = 0.1944, Valid Loss = 0.2427\n",
      "Iteration 1/145: Train Loss = 0.6921, Valid Loss = 0.6922\n",
      "Iteration 2/145: Train Loss = 0.6911, Valid Loss = 0.6912\n",
      "Iteration 3/145: Train Loss = 0.6901, Valid Loss = 0.6903\n",
      "Iteration 4/145: Train Loss = 0.6891, Valid Loss = 0.6893\n",
      "Iteration 5/145: Train Loss = 0.6881, Valid Loss = 0.6883\n",
      "Iteration 6/145: Train Loss = 0.6871, Valid Loss = 0.6874\n",
      "Iteration 7/145: Train Loss = 0.6861, Valid Loss = 0.6864\n",
      "Iteration 8/145: Train Loss = 0.6851, Valid Loss = 0.6855\n",
      "Iteration 9/145: Train Loss = 0.6841, Valid Loss = 0.6845\n",
      "Iteration 10/145: Train Loss = 0.6831, Valid Loss = 0.6836\n",
      "Iteration 11/145: Train Loss = 0.6821, Valid Loss = 0.6826\n",
      "Iteration 12/145: Train Loss = 0.6812, Valid Loss = 0.6817\n",
      "Iteration 13/145: Train Loss = 0.6802, Valid Loss = 0.6807\n",
      "Iteration 14/145: Train Loss = 0.6792, Valid Loss = 0.6798\n",
      "Iteration 15/145: Train Loss = 0.6782, Valid Loss = 0.6789\n",
      "Iteration 16/145: Train Loss = 0.6772, Valid Loss = 0.6779\n",
      "Iteration 17/145: Train Loss = 0.6763, Valid Loss = 0.6770\n",
      "Iteration 18/145: Train Loss = 0.6753, Valid Loss = 0.6761\n",
      "Iteration 19/145: Train Loss = 0.6743, Valid Loss = 0.6751\n",
      "Iteration 20/145: Train Loss = 0.6734, Valid Loss = 0.6742\n",
      "Iteration 21/145: Train Loss = 0.6724, Valid Loss = 0.6733\n",
      "Iteration 22/145: Train Loss = 0.6715, Valid Loss = 0.6724\n",
      "Iteration 23/145: Train Loss = 0.6705, Valid Loss = 0.6715\n",
      "Iteration 24/145: Train Loss = 0.6696, Valid Loss = 0.6706\n",
      "Iteration 25/145: Train Loss = 0.6686, Valid Loss = 0.6697\n",
      "Iteration 26/145: Train Loss = 0.6677, Valid Loss = 0.6688\n",
      "Iteration 27/145: Train Loss = 0.6667, Valid Loss = 0.6679\n",
      "Iteration 28/145: Train Loss = 0.6658, Valid Loss = 0.6670\n",
      "Iteration 29/145: Train Loss = 0.6648, Valid Loss = 0.6661\n",
      "Iteration 30/145: Train Loss = 0.6639, Valid Loss = 0.6652\n",
      "Iteration 31/145: Train Loss = 0.6630, Valid Loss = 0.6643\n",
      "Iteration 32/145: Train Loss = 0.6620, Valid Loss = 0.6634\n",
      "Iteration 33/145: Train Loss = 0.6611, Valid Loss = 0.6625\n",
      "Iteration 34/145: Train Loss = 0.6602, Valid Loss = 0.6617\n",
      "Iteration 35/145: Train Loss = 0.6593, Valid Loss = 0.6608\n",
      "Iteration 36/145: Train Loss = 0.6583, Valid Loss = 0.6599\n",
      "Iteration 37/145: Train Loss = 0.6574, Valid Loss = 0.6590\n",
      "Iteration 38/145: Train Loss = 0.6565, Valid Loss = 0.6581\n",
      "Iteration 39/145: Train Loss = 0.6556, Valid Loss = 0.6572\n",
      "Iteration 40/145: Train Loss = 0.6547, Valid Loss = 0.6564\n",
      "Iteration 41/145: Train Loss = 0.6538, Valid Loss = 0.6555\n",
      "Iteration 42/145: Train Loss = 0.6528, Valid Loss = 0.6546\n",
      "Iteration 43/145: Train Loss = 0.6520, Valid Loss = 0.6538\n",
      "Iteration 44/145: Train Loss = 0.6511, Valid Loss = 0.6529\n",
      "Iteration 45/145: Train Loss = 0.6501, Valid Loss = 0.6521\n",
      "Iteration 46/145: Train Loss = 0.6492, Valid Loss = 0.6512\n",
      "Iteration 47/145: Train Loss = 0.6484, Valid Loss = 0.6503\n",
      "Iteration 48/145: Train Loss = 0.6475, Valid Loss = 0.6495\n",
      "Iteration 49/145: Train Loss = 0.6466, Valid Loss = 0.6487\n",
      "Iteration 50/145: Train Loss = 0.6457, Valid Loss = 0.6478\n",
      "Iteration 51/145: Train Loss = 0.6448, Valid Loss = 0.6469\n",
      "Iteration 52/145: Train Loss = 0.6439, Valid Loss = 0.6461\n",
      "Iteration 53/145: Train Loss = 0.6430, Valid Loss = 0.6453\n",
      "Iteration 54/145: Train Loss = 0.6422, Valid Loss = 0.6444\n",
      "Iteration 55/145: Train Loss = 0.6413, Valid Loss = 0.6436\n",
      "Iteration 56/145: Train Loss = 0.6404, Valid Loss = 0.6427\n",
      "Iteration 57/145: Train Loss = 0.6395, Valid Loss = 0.6419\n",
      "Iteration 58/145: Train Loss = 0.6387, Valid Loss = 0.6411\n",
      "Iteration 59/145: Train Loss = 0.6378, Valid Loss = 0.6402\n",
      "Iteration 60/145: Train Loss = 0.6369, Valid Loss = 0.6394\n",
      "Iteration 61/145: Train Loss = 0.6361, Valid Loss = 0.6386\n",
      "Iteration 62/145: Train Loss = 0.6352, Valid Loss = 0.6378\n",
      "Iteration 63/145: Train Loss = 0.6344, Valid Loss = 0.6369\n",
      "Iteration 64/145: Train Loss = 0.6335, Valid Loss = 0.6361\n",
      "Iteration 65/145: Train Loss = 0.6326, Valid Loss = 0.6353\n",
      "Iteration 66/145: Train Loss = 0.6318, Valid Loss = 0.6345\n",
      "Iteration 67/145: Train Loss = 0.6310, Valid Loss = 0.6337\n",
      "Iteration 68/145: Train Loss = 0.6301, Valid Loss = 0.6329\n",
      "Iteration 69/145: Train Loss = 0.6293, Valid Loss = 0.6321\n",
      "Iteration 70/145: Train Loss = 0.6284, Valid Loss = 0.6313\n",
      "Iteration 71/145: Train Loss = 0.6276, Valid Loss = 0.6305\n",
      "Iteration 72/145: Train Loss = 0.6268, Valid Loss = 0.6297\n",
      "Iteration 73/145: Train Loss = 0.6259, Valid Loss = 0.6289\n",
      "Iteration 74/145: Train Loss = 0.6251, Valid Loss = 0.6281\n",
      "Iteration 75/145: Train Loss = 0.6242, Valid Loss = 0.6273\n",
      "Iteration 76/145: Train Loss = 0.6234, Valid Loss = 0.6265\n",
      "Iteration 77/145: Train Loss = 0.6226, Valid Loss = 0.6257\n",
      "Iteration 78/145: Train Loss = 0.6218, Valid Loss = 0.6250\n",
      "Iteration 79/145: Train Loss = 0.6210, Valid Loss = 0.6242\n",
      "Iteration 80/145: Train Loss = 0.6201, Valid Loss = 0.6234\n",
      "Iteration 81/145: Train Loss = 0.6193, Valid Loss = 0.6226\n",
      "Iteration 82/145: Train Loss = 0.6185, Valid Loss = 0.6218\n",
      "Iteration 83/145: Train Loss = 0.6177, Valid Loss = 0.6211\n",
      "Iteration 84/145: Train Loss = 0.6169, Valid Loss = 0.6203\n",
      "Iteration 85/145: Train Loss = 0.6161, Valid Loss = 0.6195\n",
      "Iteration 86/145: Train Loss = 0.6153, Valid Loss = 0.6188\n",
      "Iteration 87/145: Train Loss = 0.6145, Valid Loss = 0.6180\n",
      "Iteration 88/145: Train Loss = 0.6137, Valid Loss = 0.6172\n",
      "Iteration 89/145: Train Loss = 0.6129, Valid Loss = 0.6165\n",
      "Iteration 90/145: Train Loss = 0.6121, Valid Loss = 0.6157\n",
      "Iteration 91/145: Train Loss = 0.6113, Valid Loss = 0.6149\n",
      "Iteration 92/145: Train Loss = 0.6105, Valid Loss = 0.6142\n",
      "Iteration 93/145: Train Loss = 0.6097, Valid Loss = 0.6134\n",
      "Iteration 94/145: Train Loss = 0.6089, Valid Loss = 0.6126\n",
      "Iteration 95/145: Train Loss = 0.6081, Valid Loss = 0.6119\n",
      "Iteration 96/145: Train Loss = 0.6073, Valid Loss = 0.6111\n",
      "Iteration 97/145: Train Loss = 0.6066, Valid Loss = 0.6104\n",
      "Iteration 98/145: Train Loss = 0.6058, Valid Loss = 0.6097\n",
      "Iteration 99/145: Train Loss = 0.6050, Valid Loss = 0.6089\n",
      "Iteration 100/145: Train Loss = 0.6042, Valid Loss = 0.6082\n",
      "Iteration 101/145: Train Loss = 0.6034, Valid Loss = 0.6074\n",
      "Iteration 102/145: Train Loss = 0.6027, Valid Loss = 0.6067\n",
      "Iteration 103/145: Train Loss = 0.6019, Valid Loss = 0.6060\n",
      "Iteration 104/145: Train Loss = 0.6011, Valid Loss = 0.6053\n",
      "Iteration 105/145: Train Loss = 0.6003, Valid Loss = 0.6045\n",
      "Iteration 106/145: Train Loss = 0.5996, Valid Loss = 0.6038\n",
      "Iteration 107/145: Train Loss = 0.5988, Valid Loss = 0.6031\n",
      "Iteration 108/145: Train Loss = 0.5980, Valid Loss = 0.6023\n",
      "Iteration 109/145: Train Loss = 0.5973, Valid Loss = 0.6016\n",
      "Iteration 110/145: Train Loss = 0.5965, Valid Loss = 0.6009\n",
      "Iteration 111/145: Train Loss = 0.5958, Valid Loss = 0.6002\n",
      "Iteration 112/145: Train Loss = 0.5950, Valid Loss = 0.5994\n",
      "Iteration 113/145: Train Loss = 0.5942, Valid Loss = 0.5987\n",
      "Iteration 114/145: Train Loss = 0.5935, Valid Loss = 0.5980\n",
      "Iteration 115/145: Train Loss = 0.5927, Valid Loss = 0.5973\n",
      "Iteration 116/145: Train Loss = 0.5920, Valid Loss = 0.5966\n",
      "Iteration 117/145: Train Loss = 0.5912, Valid Loss = 0.5959\n",
      "Iteration 118/145: Train Loss = 0.5905, Valid Loss = 0.5952\n",
      "Iteration 119/145: Train Loss = 0.5898, Valid Loss = 0.5945\n",
      "Iteration 120/145: Train Loss = 0.5890, Valid Loss = 0.5938\n",
      "Iteration 121/145: Train Loss = 0.5883, Valid Loss = 0.5931\n",
      "Iteration 122/145: Train Loss = 0.5876, Valid Loss = 0.5924\n",
      "Iteration 123/145: Train Loss = 0.5868, Valid Loss = 0.5917\n",
      "Iteration 124/145: Train Loss = 0.5861, Valid Loss = 0.5910\n",
      "Iteration 125/145: Train Loss = 0.5854, Valid Loss = 0.5903\n",
      "Iteration 126/145: Train Loss = 0.5847, Valid Loss = 0.5896\n",
      "Iteration 127/145: Train Loss = 0.5839, Valid Loss = 0.5890\n",
      "Iteration 128/145: Train Loss = 0.5832, Valid Loss = 0.5883\n",
      "Iteration 129/145: Train Loss = 0.5825, Valid Loss = 0.5876\n",
      "Iteration 130/145: Train Loss = 0.5818, Valid Loss = 0.5869\n",
      "Iteration 131/145: Train Loss = 0.5811, Valid Loss = 0.5862\n",
      "Iteration 132/145: Train Loss = 0.5803, Valid Loss = 0.5855\n",
      "Iteration 133/145: Train Loss = 0.5796, Valid Loss = 0.5849\n",
      "Iteration 134/145: Train Loss = 0.5789, Valid Loss = 0.5842\n",
      "Iteration 135/145: Train Loss = 0.5782, Valid Loss = 0.5835\n",
      "Iteration 136/145: Train Loss = 0.5775, Valid Loss = 0.5829\n",
      "Iteration 137/145: Train Loss = 0.5768, Valid Loss = 0.5822\n",
      "Iteration 138/145: Train Loss = 0.5761, Valid Loss = 0.5815\n",
      "Iteration 139/145: Train Loss = 0.5754, Valid Loss = 0.5809\n",
      "Iteration 140/145: Train Loss = 0.5747, Valid Loss = 0.5802\n",
      "Iteration 141/145: Train Loss = 0.5740, Valid Loss = 0.5796\n",
      "Iteration 142/145: Train Loss = 0.5733, Valid Loss = 0.5789\n",
      "Iteration 143/145: Train Loss = 0.5726, Valid Loss = 0.5783\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-05 00:52:59,673] Trial 47 finished with value: 0.9615547395994188 and parameters: {'max_depth': 11, 'min_samples_leaf': 10, 'n_estimators': 145, 'learning_rate': 0.00564316548506962, 'subsample': 0.7027446954005794}. Best is trial 27 with value: 0.9657550072635349.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 144/145: Train Loss = 0.5719, Valid Loss = 0.5776\n",
      "Iteration 145/145: Train Loss = 0.5713, Valid Loss = 0.5769\n",
      "Iteration 1/125: Train Loss = 0.6821, Valid Loss = 0.6824\n",
      "Iteration 2/125: Train Loss = 0.6713, Valid Loss = 0.6721\n",
      "Iteration 3/125: Train Loss = 0.6608, Valid Loss = 0.6621\n",
      "Iteration 4/125: Train Loss = 0.6508, Valid Loss = 0.6524\n",
      "Iteration 5/125: Train Loss = 0.6410, Valid Loss = 0.6430\n",
      "Iteration 6/125: Train Loss = 0.6315, Valid Loss = 0.6339\n",
      "Iteration 7/125: Train Loss = 0.6222, Valid Loss = 0.6252\n",
      "Iteration 8/125: Train Loss = 0.6132, Valid Loss = 0.6166\n",
      "Iteration 9/125: Train Loss = 0.6044, Valid Loss = 0.6081\n",
      "Iteration 10/125: Train Loss = 0.5961, Valid Loss = 0.6003\n",
      "Iteration 11/125: Train Loss = 0.5879, Valid Loss = 0.5924\n",
      "Iteration 12/125: Train Loss = 0.5800, Valid Loss = 0.5848\n",
      "Iteration 13/125: Train Loss = 0.5723, Valid Loss = 0.5774\n",
      "Iteration 14/125: Train Loss = 0.5648, Valid Loss = 0.5703\n",
      "Iteration 15/125: Train Loss = 0.5575, Valid Loss = 0.5633\n",
      "Iteration 16/125: Train Loss = 0.5504, Valid Loss = 0.5565\n",
      "Iteration 17/125: Train Loss = 0.5435, Valid Loss = 0.5500\n",
      "Iteration 18/125: Train Loss = 0.5368, Valid Loss = 0.5437\n",
      "Iteration 19/125: Train Loss = 0.5302, Valid Loss = 0.5375\n",
      "Iteration 20/125: Train Loss = 0.5239, Valid Loss = 0.5314\n",
      "Iteration 21/125: Train Loss = 0.5177, Valid Loss = 0.5256\n",
      "Iteration 22/125: Train Loss = 0.5118, Valid Loss = 0.5198\n",
      "Iteration 23/125: Train Loss = 0.5061, Valid Loss = 0.5143\n",
      "Iteration 24/125: Train Loss = 0.5005, Valid Loss = 0.5090\n",
      "Iteration 25/125: Train Loss = 0.4950, Valid Loss = 0.5039\n",
      "Iteration 26/125: Train Loss = 0.4897, Valid Loss = 0.4989\n",
      "Iteration 27/125: Train Loss = 0.4844, Valid Loss = 0.4938\n",
      "Iteration 28/125: Train Loss = 0.4794, Valid Loss = 0.4890\n",
      "Iteration 29/125: Train Loss = 0.4744, Valid Loss = 0.4843\n",
      "Iteration 30/125: Train Loss = 0.4696, Valid Loss = 0.4799\n",
      "Iteration 31/125: Train Loss = 0.4649, Valid Loss = 0.4754\n",
      "Iteration 32/125: Train Loss = 0.4604, Valid Loss = 0.4711\n",
      "Iteration 33/125: Train Loss = 0.4560, Valid Loss = 0.4669\n",
      "Iteration 34/125: Train Loss = 0.4517, Valid Loss = 0.4628\n",
      "Iteration 35/125: Train Loss = 0.4474, Valid Loss = 0.4588\n",
      "Iteration 36/125: Train Loss = 0.4433, Valid Loss = 0.4549\n",
      "Iteration 37/125: Train Loss = 0.4393, Valid Loss = 0.4513\n",
      "Iteration 38/125: Train Loss = 0.4354, Valid Loss = 0.4477\n",
      "Iteration 39/125: Train Loss = 0.4316, Valid Loss = 0.4442\n",
      "Iteration 40/125: Train Loss = 0.4279, Valid Loss = 0.4408\n",
      "Iteration 41/125: Train Loss = 0.4242, Valid Loss = 0.4374\n",
      "Iteration 42/125: Train Loss = 0.4207, Valid Loss = 0.4342\n",
      "Iteration 43/125: Train Loss = 0.4173, Valid Loss = 0.4309\n",
      "Iteration 44/125: Train Loss = 0.4139, Valid Loss = 0.4278\n",
      "Iteration 45/125: Train Loss = 0.4106, Valid Loss = 0.4247\n",
      "Iteration 46/125: Train Loss = 0.4073, Valid Loss = 0.4217\n",
      "Iteration 47/125: Train Loss = 0.4042, Valid Loss = 0.4189\n",
      "Iteration 48/125: Train Loss = 0.4011, Valid Loss = 0.4160\n",
      "Iteration 49/125: Train Loss = 0.3980, Valid Loss = 0.4134\n",
      "Iteration 50/125: Train Loss = 0.3951, Valid Loss = 0.4106\n",
      "Iteration 51/125: Train Loss = 0.3923, Valid Loss = 0.4080\n",
      "Iteration 52/125: Train Loss = 0.3894, Valid Loss = 0.4054\n",
      "Iteration 53/125: Train Loss = 0.3866, Valid Loss = 0.4029\n",
      "Iteration 54/125: Train Loss = 0.3838, Valid Loss = 0.4004\n",
      "Iteration 55/125: Train Loss = 0.3812, Valid Loss = 0.3981\n",
      "Iteration 56/125: Train Loss = 0.3787, Valid Loss = 0.3959\n",
      "Iteration 57/125: Train Loss = 0.3762, Valid Loss = 0.3937\n",
      "Iteration 58/125: Train Loss = 0.3737, Valid Loss = 0.3915\n",
      "Iteration 59/125: Train Loss = 0.3714, Valid Loss = 0.3892\n",
      "Iteration 60/125: Train Loss = 0.3690, Valid Loss = 0.3870\n",
      "Iteration 61/125: Train Loss = 0.3667, Valid Loss = 0.3849\n",
      "Iteration 62/125: Train Loss = 0.3644, Valid Loss = 0.3829\n",
      "Iteration 63/125: Train Loss = 0.3622, Valid Loss = 0.3808\n",
      "Iteration 64/125: Train Loss = 0.3600, Valid Loss = 0.3789\n",
      "Iteration 65/125: Train Loss = 0.3579, Valid Loss = 0.3769\n",
      "Iteration 66/125: Train Loss = 0.3558, Valid Loss = 0.3751\n",
      "Iteration 67/125: Train Loss = 0.3537, Valid Loss = 0.3732\n",
      "Iteration 68/125: Train Loss = 0.3517, Valid Loss = 0.3713\n",
      "Iteration 69/125: Train Loss = 0.3497, Valid Loss = 0.3695\n",
      "Iteration 70/125: Train Loss = 0.3477, Valid Loss = 0.3677\n",
      "Iteration 71/125: Train Loss = 0.3458, Valid Loss = 0.3660\n",
      "Iteration 72/125: Train Loss = 0.3439, Valid Loss = 0.3643\n",
      "Iteration 73/125: Train Loss = 0.3420, Valid Loss = 0.3626\n",
      "Iteration 74/125: Train Loss = 0.3402, Valid Loss = 0.3610\n",
      "Iteration 75/125: Train Loss = 0.3385, Valid Loss = 0.3595\n",
      "Iteration 76/125: Train Loss = 0.3367, Valid Loss = 0.3580\n",
      "Iteration 77/125: Train Loss = 0.3350, Valid Loss = 0.3565\n",
      "Iteration 78/125: Train Loss = 0.3333, Valid Loss = 0.3549\n",
      "Iteration 79/125: Train Loss = 0.3316, Valid Loss = 0.3535\n",
      "Iteration 80/125: Train Loss = 0.3300, Valid Loss = 0.3520\n",
      "Iteration 81/125: Train Loss = 0.3285, Valid Loss = 0.3505\n",
      "Iteration 82/125: Train Loss = 0.3269, Valid Loss = 0.3492\n",
      "Iteration 83/125: Train Loss = 0.3254, Valid Loss = 0.3478\n",
      "Iteration 84/125: Train Loss = 0.3238, Valid Loss = 0.3465\n",
      "Iteration 85/125: Train Loss = 0.3224, Valid Loss = 0.3452\n",
      "Iteration 86/125: Train Loss = 0.3210, Valid Loss = 0.3440\n",
      "Iteration 87/125: Train Loss = 0.3195, Valid Loss = 0.3427\n",
      "Iteration 88/125: Train Loss = 0.3181, Valid Loss = 0.3414\n",
      "Iteration 89/125: Train Loss = 0.3167, Valid Loss = 0.3401\n",
      "Iteration 90/125: Train Loss = 0.3154, Valid Loss = 0.3390\n",
      "Iteration 91/125: Train Loss = 0.3140, Valid Loss = 0.3378\n",
      "Iteration 92/125: Train Loss = 0.3127, Valid Loss = 0.3366\n",
      "Iteration 93/125: Train Loss = 0.3114, Valid Loss = 0.3355\n",
      "Iteration 94/125: Train Loss = 0.3101, Valid Loss = 0.3343\n",
      "Iteration 95/125: Train Loss = 0.3088, Valid Loss = 0.3331\n",
      "Iteration 96/125: Train Loss = 0.3075, Valid Loss = 0.3320\n",
      "Iteration 97/125: Train Loss = 0.3063, Valid Loss = 0.3309\n",
      "Iteration 98/125: Train Loss = 0.3051, Valid Loss = 0.3299\n",
      "Iteration 99/125: Train Loss = 0.3038, Valid Loss = 0.3288\n",
      "Iteration 100/125: Train Loss = 0.3027, Valid Loss = 0.3278\n",
      "Iteration 101/125: Train Loss = 0.3016, Valid Loss = 0.3268\n",
      "Iteration 102/125: Train Loss = 0.3004, Valid Loss = 0.3258\n",
      "Iteration 103/125: Train Loss = 0.2992, Valid Loss = 0.3248\n",
      "Iteration 104/125: Train Loss = 0.2981, Valid Loss = 0.3239\n",
      "Iteration 105/125: Train Loss = 0.2970, Valid Loss = 0.3229\n",
      "Iteration 106/125: Train Loss = 0.2960, Valid Loss = 0.3220\n",
      "Iteration 107/125: Train Loss = 0.2949, Valid Loss = 0.3211\n",
      "Iteration 108/125: Train Loss = 0.2939, Valid Loss = 0.3202\n",
      "Iteration 109/125: Train Loss = 0.2928, Valid Loss = 0.3193\n",
      "Iteration 110/125: Train Loss = 0.2918, Valid Loss = 0.3185\n",
      "Iteration 111/125: Train Loss = 0.2908, Valid Loss = 0.3177\n",
      "Iteration 112/125: Train Loss = 0.2898, Valid Loss = 0.3169\n",
      "Iteration 113/125: Train Loss = 0.2889, Valid Loss = 0.3160\n",
      "Iteration 114/125: Train Loss = 0.2879, Valid Loss = 0.3152\n",
      "Iteration 115/125: Train Loss = 0.2870, Valid Loss = 0.3144\n",
      "Iteration 116/125: Train Loss = 0.2861, Valid Loss = 0.3136\n",
      "Iteration 117/125: Train Loss = 0.2851, Valid Loss = 0.3127\n",
      "Iteration 118/125: Train Loss = 0.2841, Valid Loss = 0.3120\n",
      "Iteration 119/125: Train Loss = 0.2833, Valid Loss = 0.3113\n",
      "Iteration 120/125: Train Loss = 0.2824, Valid Loss = 0.3105\n",
      "Iteration 121/125: Train Loss = 0.2815, Valid Loss = 0.3098\n",
      "Iteration 122/125: Train Loss = 0.2806, Valid Loss = 0.3091\n",
      "Iteration 123/125: Train Loss = 0.2798, Valid Loss = 0.3084\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-05 00:53:10,886] Trial 48 finished with value: 0.9634768119754908 and parameters: {'max_depth': 9, 'min_samples_leaf': 12, 'n_estimators': 125, 'learning_rate': 0.06335204897413477, 'subsample': 0.9518476761163901}. Best is trial 27 with value: 0.9657550072635349.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 124/125: Train Loss = 0.2789, Valid Loss = 0.3078\n",
      "Iteration 125/125: Train Loss = 0.2781, Valid Loss = 0.3071\n",
      "Iteration 1/140: Train Loss = 0.6521, Valid Loss = 0.6537\n",
      "Iteration 2/140: Train Loss = 0.6157, Valid Loss = 0.6189\n",
      "Iteration 3/140: Train Loss = 0.5835, Valid Loss = 0.5877\n",
      "Iteration 4/140: Train Loss = 0.5547, Valid Loss = 0.5600\n",
      "Iteration 5/140: Train Loss = 0.5289, Valid Loss = 0.5351\n",
      "Iteration 6/140: Train Loss = 0.5059, Valid Loss = 0.5130\n",
      "Iteration 7/140: Train Loss = 0.4852, Valid Loss = 0.4936\n",
      "Iteration 8/140: Train Loss = 0.4663, Valid Loss = 0.4757\n",
      "Iteration 9/140: Train Loss = 0.4493, Valid Loss = 0.4599\n",
      "Iteration 10/140: Train Loss = 0.4338, Valid Loss = 0.4455\n",
      "Iteration 11/140: Train Loss = 0.4199, Valid Loss = 0.4325\n",
      "Iteration 12/140: Train Loss = 0.4072, Valid Loss = 0.4207\n",
      "Iteration 13/140: Train Loss = 0.3956, Valid Loss = 0.4098\n",
      "Iteration 14/140: Train Loss = 0.3849, Valid Loss = 0.3998\n",
      "Iteration 15/140: Train Loss = 0.3751, Valid Loss = 0.3908\n",
      "Iteration 16/140: Train Loss = 0.3660, Valid Loss = 0.3829\n",
      "Iteration 17/140: Train Loss = 0.3578, Valid Loss = 0.3758\n",
      "Iteration 18/140: Train Loss = 0.3501, Valid Loss = 0.3687\n",
      "Iteration 19/140: Train Loss = 0.3430, Valid Loss = 0.3625\n",
      "Iteration 20/140: Train Loss = 0.3363, Valid Loss = 0.3569\n",
      "Iteration 21/140: Train Loss = 0.3299, Valid Loss = 0.3513\n",
      "Iteration 22/140: Train Loss = 0.3241, Valid Loss = 0.3462\n",
      "Iteration 23/140: Train Loss = 0.3186, Valid Loss = 0.3415\n",
      "Iteration 24/140: Train Loss = 0.3134, Valid Loss = 0.3367\n",
      "Iteration 25/140: Train Loss = 0.3085, Valid Loss = 0.3326\n",
      "Iteration 26/140: Train Loss = 0.3039, Valid Loss = 0.3286\n",
      "Iteration 27/140: Train Loss = 0.2995, Valid Loss = 0.3247\n",
      "Iteration 28/140: Train Loss = 0.2952, Valid Loss = 0.3211\n",
      "Iteration 29/140: Train Loss = 0.2914, Valid Loss = 0.3176\n",
      "Iteration 30/140: Train Loss = 0.2877, Valid Loss = 0.3145\n",
      "Iteration 31/140: Train Loss = 0.2842, Valid Loss = 0.3117\n",
      "Iteration 32/140: Train Loss = 0.2808, Valid Loss = 0.3085\n",
      "Iteration 33/140: Train Loss = 0.2777, Valid Loss = 0.3062\n",
      "Iteration 34/140: Train Loss = 0.2748, Valid Loss = 0.3040\n",
      "Iteration 35/140: Train Loss = 0.2721, Valid Loss = 0.3018\n",
      "Iteration 36/140: Train Loss = 0.2694, Valid Loss = 0.2995\n",
      "Iteration 37/140: Train Loss = 0.2667, Valid Loss = 0.2971\n",
      "Iteration 38/140: Train Loss = 0.2641, Valid Loss = 0.2953\n",
      "Iteration 39/140: Train Loss = 0.2618, Valid Loss = 0.2931\n",
      "Iteration 40/140: Train Loss = 0.2595, Valid Loss = 0.2913\n",
      "Iteration 41/140: Train Loss = 0.2574, Valid Loss = 0.2897\n",
      "Iteration 42/140: Train Loss = 0.2552, Valid Loss = 0.2880\n",
      "Iteration 43/140: Train Loss = 0.2531, Valid Loss = 0.2863\n",
      "Iteration 44/140: Train Loss = 0.2510, Valid Loss = 0.2848\n",
      "Iteration 45/140: Train Loss = 0.2492, Valid Loss = 0.2834\n",
      "Iteration 46/140: Train Loss = 0.2475, Valid Loss = 0.2820\n",
      "Iteration 47/140: Train Loss = 0.2458, Valid Loss = 0.2810\n",
      "Iteration 48/140: Train Loss = 0.2440, Valid Loss = 0.2795\n",
      "Iteration 49/140: Train Loss = 0.2425, Valid Loss = 0.2784\n",
      "Iteration 50/140: Train Loss = 0.2409, Valid Loss = 0.2772\n",
      "Iteration 51/140: Train Loss = 0.2393, Valid Loss = 0.2762\n",
      "Iteration 52/140: Train Loss = 0.2379, Valid Loss = 0.2750\n",
      "Iteration 53/140: Train Loss = 0.2366, Valid Loss = 0.2741\n",
      "Iteration 54/140: Train Loss = 0.2353, Valid Loss = 0.2732\n",
      "Iteration 55/140: Train Loss = 0.2339, Valid Loss = 0.2724\n",
      "Iteration 56/140: Train Loss = 0.2325, Valid Loss = 0.2714\n",
      "Iteration 57/140: Train Loss = 0.2311, Valid Loss = 0.2705\n",
      "Iteration 58/140: Train Loss = 0.2300, Valid Loss = 0.2697\n",
      "Iteration 59/140: Train Loss = 0.2288, Valid Loss = 0.2687\n",
      "Iteration 60/140: Train Loss = 0.2277, Valid Loss = 0.2680\n",
      "Iteration 61/140: Train Loss = 0.2264, Valid Loss = 0.2669\n",
      "Iteration 62/140: Train Loss = 0.2252, Valid Loss = 0.2662\n",
      "Iteration 63/140: Train Loss = 0.2241, Valid Loss = 0.2654\n",
      "Iteration 64/140: Train Loss = 0.2231, Valid Loss = 0.2648\n",
      "Iteration 65/140: Train Loss = 0.2220, Valid Loss = 0.2641\n",
      "Iteration 66/140: Train Loss = 0.2209, Valid Loss = 0.2632\n",
      "Iteration 67/140: Train Loss = 0.2198, Valid Loss = 0.2627\n",
      "Iteration 68/140: Train Loss = 0.2187, Valid Loss = 0.2621\n",
      "Iteration 69/140: Train Loss = 0.2177, Valid Loss = 0.2612\n",
      "Iteration 70/140: Train Loss = 0.2168, Valid Loss = 0.2607\n",
      "Iteration 71/140: Train Loss = 0.2159, Valid Loss = 0.2603\n",
      "Iteration 72/140: Train Loss = 0.2151, Valid Loss = 0.2599\n",
      "Iteration 73/140: Train Loss = 0.2142, Valid Loss = 0.2594\n",
      "Iteration 74/140: Train Loss = 0.2133, Valid Loss = 0.2588\n",
      "Iteration 75/140: Train Loss = 0.2126, Valid Loss = 0.2581\n",
      "Iteration 76/140: Train Loss = 0.2118, Valid Loss = 0.2577\n",
      "Iteration 77/140: Train Loss = 0.2112, Valid Loss = 0.2572\n",
      "Iteration 78/140: Train Loss = 0.2103, Valid Loss = 0.2567\n",
      "Iteration 79/140: Train Loss = 0.2096, Valid Loss = 0.2563\n",
      "Iteration 80/140: Train Loss = 0.2088, Valid Loss = 0.2559\n",
      "Iteration 81/140: Train Loss = 0.2082, Valid Loss = 0.2557\n",
      "Iteration 82/140: Train Loss = 0.2074, Valid Loss = 0.2553\n",
      "Iteration 83/140: Train Loss = 0.2067, Valid Loss = 0.2550\n",
      "Iteration 84/140: Train Loss = 0.2060, Valid Loss = 0.2546\n",
      "Iteration 85/140: Train Loss = 0.2052, Valid Loss = 0.2541\n",
      "Iteration 86/140: Train Loss = 0.2046, Valid Loss = 0.2537\n",
      "Iteration 87/140: Train Loss = 0.2040, Valid Loss = 0.2532\n",
      "Iteration 88/140: Train Loss = 0.2034, Valid Loss = 0.2531\n",
      "Iteration 89/140: Train Loss = 0.2027, Valid Loss = 0.2527\n",
      "Iteration 90/140: Train Loss = 0.2022, Valid Loss = 0.2524\n",
      "Iteration 91/140: Train Loss = 0.2017, Valid Loss = 0.2523\n",
      "Iteration 92/140: Train Loss = 0.2011, Valid Loss = 0.2518\n",
      "Iteration 93/140: Train Loss = 0.2005, Valid Loss = 0.2514\n",
      "Iteration 94/140: Train Loss = 0.2000, Valid Loss = 0.2513\n",
      "Iteration 95/140: Train Loss = 0.1995, Valid Loss = 0.2511\n",
      "Iteration 96/140: Train Loss = 0.1990, Valid Loss = 0.2508\n",
      "Iteration 97/140: Train Loss = 0.1985, Valid Loss = 0.2504\n",
      "Iteration 98/140: Train Loss = 0.1980, Valid Loss = 0.2500\n",
      "Iteration 99/140: Train Loss = 0.1975, Valid Loss = 0.2496\n",
      "Iteration 100/140: Train Loss = 0.1969, Valid Loss = 0.2494\n",
      "Iteration 101/140: Train Loss = 0.1964, Valid Loss = 0.2492\n",
      "Iteration 102/140: Train Loss = 0.1958, Valid Loss = 0.2491\n",
      "Iteration 103/140: Train Loss = 0.1952, Valid Loss = 0.2489\n",
      "Iteration 104/140: Train Loss = 0.1947, Valid Loss = 0.2486\n",
      "Iteration 105/140: Train Loss = 0.1942, Valid Loss = 0.2484\n",
      "Iteration 106/140: Train Loss = 0.1937, Valid Loss = 0.2484\n",
      "Iteration 107/140: Train Loss = 0.1932, Valid Loss = 0.2481\n",
      "Iteration 108/140: Train Loss = 0.1928, Valid Loss = 0.2480\n",
      "Iteration 109/140: Train Loss = 0.1923, Valid Loss = 0.2478\n",
      "Iteration 110/140: Train Loss = 0.1919, Valid Loss = 0.2476\n",
      "Iteration 111/140: Train Loss = 0.1915, Valid Loss = 0.2475\n",
      "Iteration 112/140: Train Loss = 0.1910, Valid Loss = 0.2473\n",
      "Iteration 113/140: Train Loss = 0.1906, Valid Loss = 0.2470\n",
      "Iteration 114/140: Train Loss = 0.1902, Valid Loss = 0.2469\n",
      "Iteration 115/140: Train Loss = 0.1897, Valid Loss = 0.2467\n",
      "Iteration 116/140: Train Loss = 0.1894, Valid Loss = 0.2465\n",
      "Iteration 117/140: Train Loss = 0.1889, Valid Loss = 0.2464\n",
      "Iteration 118/140: Train Loss = 0.1885, Valid Loss = 0.2462\n",
      "Iteration 119/140: Train Loss = 0.1881, Valid Loss = 0.2461\n",
      "Iteration 120/140: Train Loss = 0.1878, Valid Loss = 0.2461\n",
      "Iteration 121/140: Train Loss = 0.1873, Valid Loss = 0.2461\n",
      "Iteration 122/140: Train Loss = 0.1870, Valid Loss = 0.2461\n",
      "Iteration 123/140: Train Loss = 0.1867, Valid Loss = 0.2459\n",
      "Iteration 124/140: Train Loss = 0.1863, Valid Loss = 0.2458\n",
      "Iteration 125/140: Train Loss = 0.1860, Valid Loss = 0.2457\n",
      "Iteration 126/140: Train Loss = 0.1856, Valid Loss = 0.2456\n",
      "Iteration 127/140: Train Loss = 0.1853, Valid Loss = 0.2454\n",
      "Iteration 128/140: Train Loss = 0.1849, Valid Loss = 0.2454\n",
      "Iteration 129/140: Train Loss = 0.1846, Valid Loss = 0.2454\n",
      "Iteration 130/140: Train Loss = 0.1843, Valid Loss = 0.2454\n",
      "Iteration 131/140: Train Loss = 0.1838, Valid Loss = 0.2454\n",
      "Iteration 132/140: Train Loss = 0.1833, Valid Loss = 0.2453\n",
      "Iteration 133/140: Train Loss = 0.1830, Valid Loss = 0.2452\n",
      "Iteration 134/140: Train Loss = 0.1826, Valid Loss = 0.2450\n",
      "Iteration 135/140: Train Loss = 0.1823, Valid Loss = 0.2449\n",
      "Iteration 136/140: Train Loss = 0.1821, Valid Loss = 0.2449\n",
      "Iteration 137/140: Train Loss = 0.1818, Valid Loss = 0.2448\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-05 00:53:21,911] Trial 49 finished with value: 0.9645203969969764 and parameters: {'max_depth': 11, 'min_samples_leaf': 19, 'n_estimators': 140, 'learning_rate': 0.24027093000604519, 'subsample': 0.7694667263647016}. Best is trial 27 with value: 0.9657550072635349.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 138/140: Train Loss = 0.1815, Valid Loss = 0.2447\n",
      "Iteration 139/140: Train Loss = 0.1812, Valid Loss = 0.2447\n",
      "Iteration 140/140: Train Loss = 0.1810, Valid Loss = 0.2446\n",
      "Best trial:\n",
      "  Value (AUC) = 0.9657550072635349\n",
      "  Params = \n",
      "    max_depth: 7\n",
      "    min_samples_leaf: 11\n",
      "    n_estimators: 140\n",
      "    learning_rate: 0.3219266375247475\n",
      "    subsample: 0.7623886541997188\n"
     ]
    }
   ],
   "source": [
    "### ╰( ͡☉ ͜ʖ ͡☉ )つ──☆*:・ﾟ   ฅ^•ﻌ•^ฅ   ʕ•ᴥ•ʔ\n",
    "\n",
    "import optuna\n",
    "\n",
    "def objective(trial):\n",
    "    max_depth = trial.suggest_int(\"max_depth\", 1, 15)\n",
    "    min_samples_leaf = trial.suggest_int(\"min_samples_leaf\", 1, 20)\n",
    "\n",
    "    n_estimators = trial.suggest_int(\"n_estimators\", 10, 150, step=5)\n",
    "    learning_rate = trial.suggest_float(\"learning_rate\", 1e-3, 1.0, log=True)\n",
    "    subsample = trial.suggest_float(\"subsample\", 0.3, 1.0)\n",
    "\n",
    "    model = Boosting(\n",
    "        base_model_params={\n",
    "            \"max_depth\": max_depth,\n",
    "            \"min_samples_leaf\": min_samples_leaf\n",
    "        },\n",
    "        n_estimators=n_estimators,\n",
    "        learning_rate=learning_rate,\n",
    "        subsample=subsample,\n",
    "        early_stopping_rounds=10,\n",
    "        plot=False\n",
    "    )\n",
    "\n",
    "    model.fit(x_train, y_train, x_valid, y_valid)\n",
    "\n",
    "    valid_auc = model.score(x_valid, y_valid)\n",
    "\n",
    "    return valid_auc\n",
    "\n",
    "study = optuna.create_study(direction=\"maximize\")\n",
    "study.optimize(objective, n_trials=50)\n",
    "\n",
    "print(\"Best trial:\")\n",
    "print(f\"  Value (AUC) = {study.best_trial.value}\")\n",
    "print(\"  Params = \")\n",
    "for key, val in study.best_trial.params.items():\n",
    "    print(f\"    {key}: {val}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hGk-Wt_slWlV",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Задание 4. Интерпретация градиентного бустинга [1 балл]\n",
    "\n",
    "Постройте калибровочную кривую для вашей лучшей модели градиентного бустинга и оцените, насколько точно модель предсказывает вероятности.\n",
    "\n",
    "**Инструкция:**\n",
    "1. Постройте калибровочную кривую для лучшей модели градиентного бустинга.\n",
    "2. Постройте аналогичную кривую для логистической регрессии.\n",
    "3. Сравните полученные результаты и проанализируйте, насколько хорошо каждая модель оценивает вероятности."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "LdJG4bHClWlV",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "### ╰( ͡☉ ͜ʖ ͡☉ )つ──☆*:・ﾟ   ฅ^•ﻌ•^ฅ   ʕ•ᴥ•ʔ"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8O6bjp2MlWlW",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Теперь оценим важность признаков для градиентного бустинга.\n",
    "\n",
    "**Задание:**\n",
    "1. Поскольку базовая модель — дерево из `sklearn`, вычислите важность каждого признака для каждого дерева, используя атрибут `feature_importances_` у `DecisionTreeRegressor`.\n",
    "2. Усредните значения важности по всем деревьям и нормализуйте их так, чтобы сумма была равна единице (убедитесь, что значения неотрицательны).\n",
    "3. Дополните вашу реализацию бустинга, добавив метод `feature_importances_`, который будет возвращать усредненные и нормализованные важности признаков.\n",
    "\n",
    "**Построение графиков:**\n",
    "1. Постройте столбчатую диаграмму важности признаков для градиентного бустинга.\n",
    "2. На соседнем графике изобразите важность признаков для логистической регрессии, используя модули весов.\n",
    "3. Сравните графики и проанализируйте полученные результаты."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "y0JNgBk_lWlW",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "### ╰( ͡☉ ͜ʖ ͡☉ )つ──☆*:・ﾟ   ฅ^•ﻌ•^ฅ   ʕ•ᴥ•ʔ"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xheSi2IolWlW",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Обычно избыточные признаки могут негативно влиять на качество бустинга. Попробуйте следующее:\n",
    "\n",
    "1. **Отфильтруйте неважные признаки:** Используйте построенную диаграмму важности признаков, чтобы отобрать наиболее незначительные признаки.\n",
    "2. **Обучите модель повторно:** Обучите модель на основе оставшихся признаков с теми же гиперпараметрами.\n",
    "3. **Оцените качество модели:** Сравните результаты новой модели с исходной. Улучшилось ли качество после отфильтровывания незначительных признаков?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Rw9W9MEYlWlW",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "### ╰( ͡☉ ͜ʖ ͡☉ )つ──☆*:・ﾟ   ฅ^•ﻌ•^ฅ   ʕ•ᴥ•ʔ"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pH3489RklWlW",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Задание 5 (бонус). Блендинговое [0.5 балла]\n",
    "\n",
    "Реализуйте блендинг над вашей лучшей моделью и логистической регрессией. Улучшилось ли качество?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "FWcDMMVilWlW",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "### ╰( ͡☉ ͜ʖ ͡☉ )つ──☆*:・ﾟ   ฅ^•ﻌ•^ฅ   ʕ•ᴥ•ʔ"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "id": "eEF0yJ4vlWlX",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Задание 6 (бонус). Катбустовое [0.5 балла]\n",
    "\n",
    "Запустите [CatBoost](https://catboost.ai/en/docs/concepts/python-quickstart) на наших данных, сравните с вашей реализацией. Где получилось лучше?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0lYGhc_clWlX",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "### ╰( ͡☉ ͜ʖ ͡☉ )つ──☆*:・ﾟ   ฅ^•ﻌ•^ฅ   ʕ•ᴥ•ʔ"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EqHzTXCllZO8"
   },
   "source": [
    "Оставьте пожалуйста отзыв о курсе!\n",
    "\n",
    "https://forms.gle/LajA3Xrps6u96Q5A8\n",
    "\n",
    "\n",
    "Это очень важно. Благодаря обратной связи мы будем двигаться в сторону антиградиента)\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "nbTranslate": {
   "displayLangs": [
    "*"
   ],
   "hotkey": "alt-t",
   "langInMainMenu": true,
   "sourceLang": "en",
   "targetLang": "fr",
   "useGoogleTranslate": true
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {
    "height": "210px",
    "width": "492px"
   },
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
